[
    {
        "id": "1308.0497",
        "title": "a note on turing's 1936",
        "abstract": "to a close reading of the original turing article of 1936, we can learn it is based on the claim to have defined a number which is not computable, arguing that there can be no machine computing the diagonal on the enumeration of the computable sequences. this article carefully analyses the original 1936 argument, displaying how it cannot be considered a demonstration, and that there is indeed no evidence of such a defined number that is not computable.",
        "doi": "",
        "created": "2013-07-31",
        "url": "https://arxiv.org/abs/1308.0497",
        "authors": [
            "paola cattabriga"
        ]
    },
    {
        "id": "1611.03267",
        "title": "finite satisfiability of the two-variable guarded fragment with   transitive guards and related variants",
        "abstract": "we consider extensions of the two-variable guarded fragment, gf2, where distinguished binary predicates that occur only in guards are required to be interpreted in a special way (as transitive relations, equivalence relations, pre-orders or partial orders). we prove that the only fragment that retains the finite (exponential) model property is gf2 with equivalence guards without equality. for remaining fragments we show that the size of a minimal finite model is at most doubly exponential. to obtain the result we invent a strategy of building finite models that are formed from a number of multidimensional grids placed over a cylindrical surface. the construction yields a 2nexptime-upper bound on the complexity of the finite satisfiability problem for these fragments. we improve the bounds and obtain optimal ones for all the fragments considered, in particular nexptime for gf2 with equivalence guards, and 2exptime for gf2 with transitive guards. to obtain our results we essentially use some results from integer programming.",
        "doi": "10.1145/3174805",
        "created": "2016-11-10",
        "url": "https://arxiv.org/abs/1611.03267",
        "authors": [
            "emanuel kieronski",
            "lidia tendera"
        ]
    },
    {
        "id": "1701.03234",
        "title": "focusing on a probability element: parameter selection of message   importance measure in big data",
        "abstract": "message importance measure (mim) is applicable to characterize the importance of information in the scenario of big data, similar to entropy in information theory. in fact, mim with a variable parameter can make an effect on the characterization of distribution. furthermore, by choosing an appropriate parameter of mim, it is possible to emphasize the message importance of a certain probability element in a distribution. therefore, parametric mim can play a vital role in anomaly detection of big data by focusing on probability of an anomalous event. in this paper, we propose a parameter selection method of mim focusing on a probability element and then present its major properties. in addition, we discuss the parameter selection with prior probability, and investigate the availability in a statistical processing model of big data for anomaly detection problem.",
        "doi": "10.1109/icc.2017.7996803",
        "created": "2017-01-12",
        "url": "https://arxiv.org/abs/1701.03234",
        "authors": [
            "rui she",
            "shanyun liu",
            "yunquan dong",
            "pingyi fan"
        ]
    },
    {
        "id": "1709.03690",
        "title": "amplifying inter-message distance: on information divergence measures in   big data",
        "abstract": "message identification (m-i) divergence is an important measure of the information distance between probability distributions, similar to kullback-leibler (k-l) and renyi divergence. in fact, m-i divergence with a variable parameter can make an effect on characterization of distinction between two distributions. furthermore, by choosing an appropriate parameter of m-i divergence, it is possible to amplify the information distance between adjacent distributions while maintaining enough gap between two nonadjacent ones. therefore, m-i divergence can play a vital role in distinguishing distributions more clearly. in this paper, we first define a parametric m-i divergence in the view of information theory and then present its major properties. in addition, we design a m-i divergence estimation algorithm by means of the ensemble estimator of the proposed weight kernel estimators, which can improve the convergence of mean squared error from ${o(\\vargamma^{-j/d})}$ to ${o(\\vargamma^{-1})}$ $({j\\in (0,d]})$. we also discuss the decision with m-i divergence for clustering or classification, and investigate its performance in a statistical sequence model of big data for the outlier detection problem.",
        "doi": "10.1109/access.2017.2768385",
        "created": "2017-09-12",
        "url": "https://arxiv.org/abs/1709.03690",
        "authors": [
            "rui she",
            "shanyun liu",
            "pingyi fan"
        ]
    },
    {
        "id": "1801.04064",
        "title": "state variation mining: on information divergence with message   importance in big data",
        "abstract": "information transfer which reveals the state variation of variables usually plays a vital role in big data analytics and processing. in fact, the measures for information transfer could reflect the system change by use of the variable distributions, similar to kl divergence and renyi divergence. furthermore, in terms of the information transfer in big data, small probability events usually dominate the importance of the total message to some degree. therefore, it is significant to design an information transfer measure based on the message importance which emphasizes the small probability events. in this paper, we propose a message importance transfer measure (mitm) and investigate its characteristics and applications on three aspects. first, the message importance transfer capacity based on mitm is presented to offer an upper bound for the information transfer process with disturbance. then, we extend the mitm to the continuous case and discuss the robustness by using it to measuring information distance. finally, we utilize the mitm to guide the queue length selection in the caching operation of mobile edge computing.",
        "doi": "10.1109/glocom.2018.8647882",
        "created": "2018-01-12",
        "url": "https://arxiv.org/abs/1801.04064",
        "authors": [
            "rui she",
            "shanyun liu",
            "pingyi fan"
        ]
    },
    {
        "id": "1803.03724",
        "title": "contour parametrization via anisotropic mean curvature flows",
        "abstract": "we present a new implementation of anisotropic mean curvature flow for contour recognition. our procedure couples the mean curvature flow of planar closed smooth curves, with an external field from a potential of point-wise charges. this coupling constrains the motion when the curve matches a picture placed as background. we include a stability criteria for our numerical approximation.",
        "doi": "10.1016/j.amc.2022.127699",
        "created": "2018-03-09",
        "url": "https://arxiv.org/abs/1803.03724",
        "authors": [
            "p. su\u00e1rez-serrato",
            "e. i. vel\u00e1zquez richards"
        ]
    },
    {
        "id": "1808.02933",
        "title": "sequential monte carlo bandits",
        "abstract": "we extend bayesian multi-armed bandit (mab) algorithms beyond their original setting by making use of sequential monte carlo (smc) methods.   a mab is a sequential decision making problem where the goal is to learn a policy that maximizes long term payoff, where only the reward of the executed action is observed. in the stochastic mab, the reward for each action is generated from an unknown distribution, often assumed to be stationary. to decide which action to take next, a mab agent must learn the characteristics of the unknown reward distribution, e.g., compute its sufficient statistics. however, closed-form expressions for these statistics are analytically intractable except for simple, stationary cases.   we here utilize smc for estimation of the statistics bayesian mab agents compute, and devise flexible policies that can address a rich class of bandit problems: i.e., mabs with nonlinear, stateless- and context-dependent reward distributions that evolve over time. we showcase how non-stationary bandits, where time dynamics are modeled via linear dynamical systems, can be successfully addressed by smc-based bayesian bandit agents. we empirically demonstrate good regret performance of the proposed smc-based bandit policies in several mab scenarios that have remained elusive, i.e., in non-stationary bandits with nonlinear rewards.",
        "doi": "",
        "created": "2018-08-08",
        "url": "https://arxiv.org/abs/1808.02933",
        "authors": [
            "i\u00f1igo urteaga",
            "chris h. wiggins"
        ]
    },
    {
        "id": "1902.06634",
        "title": "contextual encoder-decoder network for visual saliency prediction",
        "abstract": "predicting salient regions in natural images requires the detection of objects that are present in a scene. to develop robust representations for this challenging task, high-level visual features at multiple spatial scales must be extracted and augmented with contextual information. however, existing models aimed at explaining human fixation maps do not incorporate such a mechanism explicitly. here we propose an approach based on a convolutional neural network pre-trained on a large-scale image classification task. the architecture forms an encoder-decoder structure and includes a module with multiple convolutional layers at different dilation rates to capture multi-scale features in parallel. moreover, we combine the resulting representations with global scene information for accurately predicting visual saliency. our model achieves competitive and consistent results across multiple evaluation metrics on two public saliency benchmarks and we demonstrate the effectiveness of the suggested approach on five datasets and selected examples. compared to state of the art approaches, the network is based on a lightweight image classification backbone and hence presents a suitable choice for applications with limited computational resources, such as (virtual) robotic systems, to estimate human fixations across complex natural scenes.",
        "doi": "10.1016/j.neunet.2020.05.004",
        "created": "2019-02-18",
        "url": "https://arxiv.org/abs/1902.06634",
        "authors": [
            "alexander kroner",
            "mario senden",
            "kurt driessens",
            "rainer goebel"
        ]
    },
    {
        "id": "1906.04223",
        "title": "accurate low rank approximation at a low computational cost",
        "abstract": "given an algorithm a for computing a crude low rank approximation (lra) of a matrix having fast decaying spectra of singular values, we greatly decreased the spectral norm of its output error matrix at sublinear additional computational cost. furthermore, for a variety of synthetic and real world inputs we tested numerically variants where our entire algorithms run at sublinear cost, and in most cases we still obtained accurate or even near-optimal lras. towards enhancing our progress to a larger class of matrices, we nontrivially extended to lra the popular technique of iterative refinement.",
        "doi": "",
        "created": "2019-06-10",
        "url": "https://arxiv.org/abs/1906.04223",
        "authors": [
            "soo go",
            "qi luan",
            "victor y. pan"
        ]
    },
    {
        "id": "1907.02652",
        "title": "importance of small probability events in big data: information   measures, applications, and challenges",
        "abstract": "in many applications (e.g., anomaly detection and security systems) of smart cities, rare events dominate the importance of the total information of big data collected by internet of things (iots). that is, it is pretty crucial to explore the valuable information associated with the rare events involved in minority subsets of the voluminous amounts of data. to do so, how to effectively measure the information with importance of the small probability events from the perspective of information theory is a fundamental question. this paper first makes a survey of some theories and models with respect to importance measures and investigates the relationship between subjective or semantic importance and rare events in big data. moreover, some applications for message processing and data analysis are discussed in the viewpoint of information measures. in addition, based on rare events detection, some open challenges related to information measures, such as smart cities, autonomous driving, and anomaly detection in iots, are introduced which can be considered as future research directions.",
        "doi": "10.1109/access.2019.2926518",
        "created": "2019-07-04",
        "url": "https://arxiv.org/abs/1907.02652",
        "authors": [
            "rui she",
            "shanyun liu",
            "shuo wan",
            "ke xiong",
            "pingyi fan"
        ]
    },
    {
        "id": "1909.11846",
        "title": "quantum bicyclic hyperbolic codes",
        "abstract": "bicyclic codes are a generalization of the one dimensional (1d) cyclic codes to two dimensions (2d). similar to the 1d case, in some cases, 2d cyclic codes can also be constructed to guarantee a specified minimum distance. many aspects of these codes are yet unexplored. motivated by the problem of constructing quantum codes, in this paper, we study some structural properties of certain bicyclic codes. we show that a primitive narrow-sense bicyclic hyperbolic code of length $n^2$ contains its dual if and only if its design distance is lower than $n-\\delta$, where $\\delta=\\mathcal{o}(\\sqrt{n})$. we extend the sufficiency condition to the non-primitive case as well. we also show that over quadratic extension fields, a primitive bicyclic hyperbolic code of length $n^2$ contains hermitian dual if and only if its design distance is lower than $n-\\delta_h$, where $\\delta_h=\\mathcal{o}(\\sqrt{n})$. our results are analogous to some structural results known for bch and reed-solomon codes. they further our understanding of bicyclic codes. we also give an application of these results by showing that we can construct two classes of quantum bicyclic codes based on our results.",
        "doi": "10.1007/s11128-020-02727-0",
        "created": "2019-09-25",
        "url": "https://arxiv.org/abs/1909.11846",
        "authors": [
            "sankara sai chaithanya rayudu",
            "pradeep kiran sarvepalli"
        ]
    },
    {
        "id": "2003.09948",
        "title": "euclidean tsp in narrow strips",
        "abstract": "we investigate how the complexity of euclidean tsp for point sets $p$ inside the strip $(-\\infty,+\\infty)\\times [0,\\delta]$ depends on the strip width $\\delta$. we obtain two main results. first, for the case where the points have distinct integer $x$-coordinates, we prove that a shortest bitonic tour (which can be computed in $o(n\\log^2 n)$ time using an existing algorithm) is guaranteed to be a shortest tour overall when $\\delta\\leq 2\\sqrt{2}$, a bound which is best possible. second, we present an algorithm that is fixed-parameter tractable with respect to $\\delta$. our algorithm has running time $2^{o(\\sqrt{\\delta})} n + o(\\delta^2 n^2)$ for sparse point sets, where each $1\\times\\delta$ rectangle inside the strip contains $o(1)$ points. for random point sets, where the points are chosen uniformly at random from the rectangle $[0,n]\\times [0,\\delta]$, it has an expected running time of $2^{o(\\sqrt{\\delta})} n$. these results generalise to point sets $p$ inside a hypercylinder of width $\\delta$. in this case, the factors $2^{o(\\sqrt{\\delta})}$ become $2^{o(\\delta^{1-1/d})}$.",
        "doi": "10.1007/s00454-023-00609-7",
        "created": "2020-03-22",
        "url": "https://arxiv.org/abs/2003.09948",
        "authors": [
            "henk alkema",
            "mark de berg",
            "remco van der hofstad",
            "s\u00e1ndor kisfaludi-bak"
        ]
    },
    {
        "id": "2012.09561",
        "title": "estimating mixed-memberships using the symmetric laplacian inverse   matrix",
        "abstract": "mixed membership community detection is a challenging problem. in this paper, to detect mixed memberships, we propose a new method mixed-slim which is a spectral clustering method on the symmetrized laplacian inverse matrix under the degree-corrected mixed membership model. we provide theoretical bounds for the estimation error on the proposed algorithm and its regularized version under mild conditions. meanwhile, we provide some extensions of the proposed method to deal with large networks in practice. these mixed-slim methods outperform state-of-art methods in simulations and substantial empirical datasets for both community detection and mixed membership community detection problems.",
        "doi": "",
        "created": "2020-12-17",
        "url": "https://arxiv.org/abs/2012.09561",
        "authors": [
            "huan qing",
            "jingli wang"
        ]
    },
    {
        "id": "2012.10142",
        "title": "learning and balancing unknown loads in large-scale systems",
        "abstract": "consider a system of identical server pools where tasks with exponentially distributed service times arrive as a time-inhomogenenous poisson process. an admission threshold is used in an inner control loop to assign incoming tasks to server pools while, in an outer control loop, a learning scheme adjusts this threshold over time to keep it aligned with the unknown offered load of the system. in a many-server regime, we prove that the learning scheme reaches an equilibrium along intervals of time where the normalized offered load per server pool is suitably bounded, and that this results in a balanced distribution of the load. furthermore, we establish a similar result when tasks with coxian distributed service times arrive at a constant rate and the threshold is adjusted using only the total number of tasks in the system. the novel proof technique developed in this paper, which differs from a traditional fluid limit analysis, allows to handle rapid variations of the first learning scheme, triggered by excursions of the occupancy process that have vanishing size. moreover, our approach allows to characterize the asymptotic behavior of the system with coxian distributed service times without relying on a fluid limit of a detailed state descriptor.",
        "doi": "",
        "created": "2020-12-18",
        "url": "https://arxiv.org/abs/2012.10142",
        "authors": [
            "diego goldsztajn",
            "sem c. borst",
            "johan s. h. van leeuwaarden"
        ]
    },
    {
        "id": "2102.05984",
        "title": "modeling 3d surface manifolds with a locally conditioned atlas",
        "abstract": "recently proposed 3d object reconstruction methods represent a mesh with an atlas - a set of planar patches approximating the surface. however, their application in a real-world scenario is limited since the surfaces of reconstructed objects contain discontinuities, which degrades the quality of the final mesh. this is mainly caused by independent processing of individual patches, and in this work, we postulate to mitigate this limitation by preserving local consistency around patch vertices. to that end, we introduce a locally conditioned atlas (loconda), a framework for representing a 3d object hierarchically in a generative model. firstly, the model maps a point cloud of an object into a sphere. secondly, by leveraging a spherical prior, we enforce the mapping to be locally consistent on the sphere and on the target object. this way, we can sample a mesh quad on that sphere and project it back onto the object's manifold. with loconda, we can produce topologically diverse objects while maintaining quads to be stitched together. we show that the proposed approach provides structurally coherent reconstructions while producing meshes of quality comparable to the competitors.",
        "doi": "",
        "created": "2021-02-11",
        "url": "https://arxiv.org/abs/2102.05984",
        "authors": [
            "przemys\u0142aw spurek",
            "sebastian winczowski",
            "maciej zi\u0119ba",
            "tomasz trzci\u0144ski",
            "kacper kania",
            "marcin mazur"
        ]
    },
    {
        "id": "2107.14554",
        "title": "international trade network: country centrality and covid-19 pandemic",
        "abstract": "international trade is based on a set of complex relationships between different countries that can be modelled as an extremely dense network of interconnected agents. on the one hand, this network might favour the economic growth of countries, but on the other, it can also favour the diffusion of diseases, like the covid-19. in this paper, we study whether, and to what extent, the topology of the trade network can explain the rate of covid-19 diffusion and mortality across countries. we compute the countries' centrality measures and we apply the community detection methodology based on communicability distance. then, we use these measures as focal regressors in a negative binomial regression framework. in doing so, we also compare the effect of different measures of centrality. our results show that the number of infections and fatalities are larger in countries with a higher centrality in the global trade network.",
        "doi": "10.1007/s41109-022-00452-4",
        "created": "2021-07-30",
        "url": "https://arxiv.org/abs/2107.14554",
        "authors": [
            "roberto antonietti",
            "paolo falbo",
            "fulvio fontini",
            "rosanna grassi",
            "giorgio rizzini"
        ]
    },
    {
        "id": "2108.07445",
        "title": "encirclement guaranteed cooperative pursuit with robust model predictive   control",
        "abstract": "this paper studies a novel encirclement guaranteed cooperative pursuit problem involving $n$ pursuers and a single evader in an unbounded two-dimensional game domain. throughout the game, the pursuers are required to maintain encirclement of the evader, i.e., the evader should always stay inside the convex hull generated by all the pursuers, in addition to achieving the classical capture condition. to tackle this challenging cooperative pursuit problem, a robust model predictive control (rmpc) based formulation framework is first introduced, which simultaneously accounts for the encirclement and capture requirements under the assumption that the evader's action is unavailable to all pursuers. despite the reformulation, the resulting rmpc problem involves a bilinear constraint due to the encirclement requirement. to further handle such a bilinear constraint, a novel encirclement guaranteed partitioning scheme is devised that simplifies the original bilinear rmpc problem to a number of linear tube mpc (tmpc) problems solvable in a decentralized manner. simulation experiments demonstrate the effectiveness of the proposed solution framework. furthermore, comparisons with existing approaches show that the explicit consideration of the encirclement condition significantly improves the chance of successful capture of the evader in various scenarios.",
        "doi": "10.1109/iros51168.2021.9636127",
        "created": "2021-08-17",
        "url": "https://arxiv.org/abs/2108.07445",
        "authors": [
            "chen wang",
            "hua chen",
            "jia pan",
            "wei zhang"
        ]
    },
    {
        "id": "2110.02678",
        "title": "one-dimensional fragment over words and trees",
        "abstract": "one-dimensional fragment of first-order logic is obtained by restricting quantification to blocks of existential (universal) quantifiers that leave at most one variable free. we investigate this fragment over words and trees, presenting a complete classification of the complexity of its satisfiability problem for various navigational signatures, and comparing its expressive power with other important formalisms. these include the two-variable fragment with counting and the unary negation fragment.",
        "doi": "10.1093/logcom/exac002",
        "created": "2021-10-06",
        "url": "https://arxiv.org/abs/2110.02678",
        "authors": [
            "emanuel kieronski",
            "antti kuusisto"
        ]
    },
    {
        "id": "2111.05778",
        "title": "theoretical and empirical analysis of a fast algorithm for extracting   polygons from signed distance bounds",
        "abstract": "recently there has been renewed interest in signed distance bound representations due to their unique properties for 3d shape modelling. this is especially the case for deep learning-based bounds. however, it is beneficial to work with polygons in most computer-graphics applications. thus, in this paper we introduce and investigate an asymptotically fast method for transforming signed distance bounds into polygon meshes. this is achieved by combining the principles of sphere tracing (or ray marching) with traditional polygonization techniques, such as marching cubes. we provide theoretical and experimental evidence that this approach is of the $o(n^2\\log n)$ computational complexity for a polygonization grid with $n^3$ cells. the algorithm is tested on both a set of primitive shapes as well as signed distance bounds generated from point clouds by machine learning (and represented as neural networks). given its speed, implementation simplicity and portability, we argue that it could prove useful during the modelling stage as well as in shape compression for storage.   the code is available here: https://github.com/nenadmarkus/gridhopping",
        "doi": "10.3390/a17040137",
        "created": "2021-11-10",
        "url": "https://arxiv.org/abs/2111.05778",
        "authors": [
            "nenad marku\u0161",
            "mirko su\u017enjevi\u0107"
        ]
    },
    {
        "id": "2111.10553",
        "title": "degree-corrected distribution-free model for community detection in   weighted networks",
        "abstract": "a degree-corrected distribution-free model is proposed for weighted social networks with latent structural information. the model extends the previous distribution-free models by considering variation in node degree to fit real-world weighted networks, and it also extends the classical degree-corrected stochastic block model from un-weighted network to weighted network. we design an algorithm based on the idea of spectral clustering to fit the model. theoretical framework on consistent estimation for the algorithm is developed under the model. theoretical results when edge weights are generated from different distributions are analyzed. we also propose a general modularity as an extension of newman's modularity from un-weighted network to weighted network. using experiments with simulated and real-world networks, we show that our method significantly outperforms the uncorrected one, and the general modularity is effective.",
        "doi": "",
        "created": "2021-11-20",
        "url": "https://arxiv.org/abs/2111.10553",
        "authors": [
            "huan qing"
        ]
    },
    {
        "id": "2112.04389",
        "title": "mixed membership distribution-free model",
        "abstract": "we consider the problem of community detection in overlapping weighted networks, where nodes can belong to multiple communities and edge weights can be finite real numbers. to model such complex networks, we propose a general framework - the mixed membership distribution-free (mmdf) model. mmdf has no distribution constraints of edge weights and can be viewed as generalizations of some previous models, including the well-known mixed membership stochastic blockmodels. especially, overlapping signed networks with latent community structures can also be generated from our model. we use an efficient spectral algorithm with a theoretical guarantee of convergence rate to estimate community memberships under the model. we also propose the fuzzy weighted modularity to evaluate the quality of community detection for overlapping weighted networks with positive and negative edge weights. we then provide a method to determine the number of communities for weighted networks by taking advantage of our fuzzy weighted modularity. numerical simulations and real data applications are carried out to demonstrate the usefulness of our mixed membership distribution-free model and our fuzzy weighted modularity.",
        "doi": "",
        "created": "2021-12-04",
        "url": "https://arxiv.org/abs/2112.04389",
        "authors": [
            "huan qing",
            "jingli wang"
        ]
    },
    {
        "id": "2112.11002",
        "title": "efficient quantum network communication using optimized   entanglement-swapping trees",
        "abstract": "quantum network communication is challenging, as the no-cloning theorem in quantum regime makes many classical techniques inapplicable. for long-distance communication, the only viable communication approach is teleportation of quantum states, which requires a prior distribution of entangled pairs (eps) of qubits. establishment of eps across remote nodes can incur significant latency due to the low probability of success of the underlying physical processes.   the focus of our work is to develop efficient techniques that minimize ep generation latency. prior works have focused on selecting entanglement paths; in contrast, we select entanglement swapping trees--a more accurate representation of the entanglement generation structure. we develop a dynamic programming algorithm to select an optimal swapping-tree for a single pair of nodes, under the given capacity and fidelity constraints. for the general setting, we develop an efficient iterative algorithm to compute a set of swapping trees. we present simulation results which show that our solutions outperform the prior approaches by an order of magnitude and are viable for long-distance entanglement generation.",
        "doi": "10.1109/tqe.2022.3168784",
        "created": "2021-12-21",
        "url": "https://arxiv.org/abs/2112.11002",
        "authors": [
            "mohammad ghaderibaneh",
            "caitao zhan",
            "himanshu gupta",
            "c. r. ramakrishnan"
        ]
    },
    {
        "id": "2201.07762",
        "title": "deepalloc: cnn-based approach to efficient spectrum allocation in shared   spectrum systems",
        "abstract": "shared spectrum systems facilitate spectrum allocation to unlicensed users without harming the licensed users; they offer great promise in optimizing spectrum utility, but their management (in particular, efficient spectrum allocation to unlicensed users) is challenging. a significant shortcoming of current allocation methods is that they are either done very conservatively to ensure correctness, or are based on imperfect propagation models and/or spectrum sensing with poor spatial granularity. this leads to poor spectrum utilization, the fundamental objective of shared spectrum systems.   to allocate spectrum near-optimally to secondary users in general scenarios, we fundamentally need to have knowledge of the signal path-loss function. in practice, however, even the best known path-loss models have unsatisfactory accuracy, and conducting extensive surveys to gather path-loss values is infeasible. to circumvent this challenge, we propose to learn the spectrum allocation function directly using supervised learning techniques. we particularly address the scenarios when the primary users' information may not be available; for such settings, we make use of a crowdsourced sensing architecture and use the spectrum sensor readings as features. we develop an efficient cnn-based approach (called deepalloc) and address various challenges that arise in its application to the learning the spectrum allocation function. via extensive large-scale simulation and a small testbed, we demonstrate the effectiveness of our developed techniques; in particular, we observe that our approach improves the accuracy of standard learning techniques and prior work by up to 60%.",
        "doi": "10.1109/access.2024.3352034",
        "created": "2022-01-19",
        "url": "https://arxiv.org/abs/2201.07762",
        "authors": [
            "mohammad ghaderibaneh",
            "caitao zhan",
            "himanshu gupta"
        ]
    },
    {
        "id": "2201.12900",
        "title": "learning optimal topology for ad-hoc robot networks",
        "abstract": "in this paper, we synthesize a data-driven method to predict the optimal topology of an ad-hoc robot network. this problem is technically a multi-task classification problem. however, we divide it into a class of multi-class classification problems that can be more efficiently solved. for this purpose, we first compose an algorithm to create ground-truth optimal topologies associated with various configurations of a robot network. this algorithm incorporates a complex collection of optimality criteria that our learning model successfully manages to learn. this model is an stacked ensemble whose output is the topology prediction for a particular robot. each stacked ensemble instance constitutes three low-level estimators whose outputs will be aggregated by a high-level boosting blender. applying our model to a network of 10 robots displays over 80% accuracy in the prediction of optimal topologies corresponding to various configurations of the cited network.",
        "doi": "10.1109/lra.2023.3246845",
        "created": "2022-01-30",
        "url": "https://arxiv.org/abs/2201.12900",
        "authors": [
            "matin macktoobian",
            "zhan shu",
            "qing zhao"
        ]
    },
    {
        "id": "2202.10105",
        "title": "on the limiting amplitude principle for the wave equation with variable   coefficients",
        "abstract": "in this paper, we prove new results on the validity of the limiting amplitude principle (lap) for the wave equation with nonconstant coefficients, not necessarily in divergence form. under suitable assumptions on the coefficients and on the source term, we establish the lap for space dimensions 2 and 3. this result is extended to one space dimension with an appropriate modification. we also quantify the lap and thus provide estimates for the convergence of the time-domain solution to the frequency-domain solution. our proofs are based on time-decay results of solutions of some auxiliary problems. the obtained results are illustrated numerically on radially symmetric problems in dimensions 1, 2 and 3.",
        "doi": "",
        "created": "2022-02-21",
        "url": "https://arxiv.org/abs/2202.10105",
        "authors": [
            "anton arnold",
            "sjoerd geevers",
            "ilaria perugia",
            "dmitry ponomarev"
        ]
    },
    {
        "id": "2203.13464",
        "title": "from mim-based gan to anomaly detection:event probability influence on   generative adversarial networks",
        "abstract": "in order to introduce deep learning technologies into anomaly detection, generative adversarial networks (gans) are considered as important roles in the algorithm design and realistic applications. in terms of gans, event probability reflected in the objective function, has an impact on the event generation which plays a crucial part in gan-based anomaly detection. the information metric, e.g. kullback-leibler divergence in the original gan, makes the objective function have different sensitivity on different event probability, which provides an opportunity to refine gan-based anomaly detection by influencing data generation. in this paper, we introduce the exponential information metric into the gan, referred to as mim-based gan, whose superior characteristics on data generation are discussed in theory. furthermore, we propose an anomaly detection method with mim-based gan, as well as explain its principle for the unsupervised learning case from the viewpoint of probability event generation. since this method is promising to detect anomalies in internet of things (iot), such as environmental, medical and biochemical outliers, we make use of several datasets from the online odds repository to evaluate its performance and compare it with other methods.",
        "doi": "10.1109/jiot.2022.3161630",
        "created": "2022-03-25",
        "url": "https://arxiv.org/abs/2203.13464",
        "authors": [
            "rui she",
            "pingyi fan"
        ]
    },
    {
        "id": "2205.00684",
        "title": "rational social distancing policy during epidemics with limited   healthcare capacity",
        "abstract": "epidemics of infectious diseases posing a serious risk to human health have occurred throughout history. during recent epidemics there has been much debate about policy, including how and when to impose restrictions on behaviour. policymakers must balance a complex spectrum of objectives, suggesting a need for quantitative tools. whether health services might be `overwhelmed' has emerged as a key consideration. here we show how costly interventions, such as taxes or subsidies on behaviour, can be used to exactly align individuals' decision making with government preferences even when these are not aligned. in order to achieve this, we develop a nested optimisation algorithm of both the government intervention strategy and the resulting equilibrium behaviour of individuals. we focus on a situation in which the capacity of the healthcare system to treat patients is limited and identify conditions under which the disease dynamics respect the capacity limit. we find an extremely sharp drop in peak infections at a critical maximum infection cost in the government's objective function. this is in marked contrast to the gradual reduction of infections if individuals make decisions without government intervention. we find optimal interventions vary less strongly in time when interventions are costly to the government and that the critical cost of the policy switch depends on how costly interventions are.",
        "doi": "10.1371/journal.pcbi.1011533",
        "created": "2022-05-02",
        "url": "https://arxiv.org/abs/2205.00684",
        "authors": [
            "simon k. schnyder",
            "john j. molina",
            "ryoichi yamamoto",
            "matthew s. turner"
        ]
    },
    {
        "id": "2207.01414",
        "title": "controlling the cascade: kinematic planning for n-ball toss juggling",
        "abstract": "dynamic movements are ubiquitous in human motor behavior as they tend to be more efficient and can solve a broader range of skill domains than their quasi-static counterparts. for decades, robotic juggling tasks have been among the most frequently studied dynamic manipulation problems since the required dynamic dexterity can be scaled to arbitrarily high difficulty. however, successful approaches have been limited to basic juggling skills, indicating a lack of understanding of the required constraints for dexterous toss juggling. we present a detailed analysis of the toss juggling task, identifying the key challenges and formalizing it as a trajectory optimization problem. building on our state-of-the-art, real-world toss juggling platform, we reach the theoretical limits of toss juggling in simulation, evaluate a resulting real-time controller in environments of varying difficulty and achieve robust toss juggling of up to 17 balls on two anthropomorphic manipulators.",
        "doi": "",
        "created": "2022-07-04",
        "url": "https://arxiv.org/abs/2207.01414",
        "authors": [
            "kai ploeger",
            "jan peters"
        ]
    },
    {
        "id": "2207.08061",
        "title": "optimal computation in anonymous dynamic networks",
        "abstract": "we give a simple characterization of which functions can be computed deterministically by anonymous processes in dynamic networks, depending on the number of leaders in the network. in addition, we provide efficient distributed algorithms for computing all such functions assuming minimal or no knowledge about the network. each of our algorithms comes in two versions: one that terminates with the correct output and a faster one that stabilizes on the correct output without explicit termination. notably, these are the first deterministic algorithms whose running times scale linearly with both the number of processes and a parameter of the network which we call \"dynamic disconnectivity\" (meaning that our dynamic networks do not necessarily have to be connected at all times). we also provide matching lower bounds, showing that all our algorithms are asymptotically optimal for any fixed number of leaders.   while most of the existing literature on anonymous dynamic networks relies on classic mass-distribution techniques, our work makes use of a novel combinatorial structure called \"history tree\", which is of independent interest. among other contributions, our results make conclusive progress on two popular fundamental problems for anonymous dynamic networks: leaderless average consensus (i.e., computing the mean value of input numbers distributed among the processes) and multi-leader counting (i.e., determining the exact number of processes in the network).   our contribution not only opens a promising line of research on applications of history trees, but also demonstrates that computation in anonymous dynamic networks is practically feasible and far less demanding than previously conjectured.",
        "doi": "",
        "created": "2022-07-16",
        "url": "https://arxiv.org/abs/2207.08061",
        "authors": [
            "giuseppe a. di luna",
            "giovanni viglietta"
        ]
    },
    {
        "id": "2207.14800",
        "title": "contrastive ucb: provably efficient contrastive self-supervised learning   in online reinforcement learning",
        "abstract": "in view of its power in extracting feature representation, contrastive self-supervised learning has been successfully integrated into the practice of (deep) reinforcement learning (rl), leading to efficient policy learning in various applications. despite its tremendous empirical successes, the understanding of contrastive learning for rl remains elusive. to narrow such a gap, we study how rl can be empowered by contrastive learning in a class of markov decision processes (mdps) and markov games (mgs) with low-rank transitions. for both models, we propose to extract the correct feature representations of the low-rank model by minimizing a contrastive loss. moreover, under the online setting, we propose novel upper confidence bound (ucb)-type algorithms that incorporate such a contrastive loss with online rl algorithms for mdps or mgs. we further theoretically prove that our algorithm recovers the true representations and simultaneously achieves sample efficiency in learning the optimal policy and nash equilibrium in mdps and mgs. we also provide empirical studies to demonstrate the efficacy of the ucb-based contrastive learning method for rl. to the best of our knowledge, we provide the first provably efficient online rl algorithm that incorporates contrastive learning for representation learning. our codes are available at https://github.com/baichenjia/contrastive-ucb.",
        "doi": "",
        "created": "2022-07-29",
        "url": "https://arxiv.org/abs/2207.14800",
        "authors": [
            "shuang qiu",
            "lingxiao wang",
            "chenjia bai",
            "zhuoran yang",
            "zhaoran wang"
        ]
    },
    {
        "id": "2208.03378",
        "title": "autonomous rapid exploration in close-proximity of an asteroid",
        "abstract": "the increasing number of space missions may overwhelm ground support infrastructure, prompting the need for autonomous deep-space guidance, navigation, and control (gn\\&c) systems. these systems offer sustainable and cost-effective solutions, particularly for asteroid missions that deal with uncertain environments. this study proposes a paradigm shift from the proposals currently found in the literature for autonomous asteroid exploration, which inherit the conservative architecture from the ground-in-the-loop approach that relies heavily on reducing uncertainties before close-proximity operations. instead, it advocates for robust guidance and control to handle uncertainties directly, without extensive navigation campaigns. from a series of conservative assumptions, we demonstrate the feasibility of this autonomous gn\\&c for robotic spacecraft by using existing technology. it is shown that a bolder operational approach enables autonomous spacecraft to significantly reduce exploration time by weeks or months. this paradigm shift holds great potential for reducing costs and saving time in autonomous missions of the future.",
        "doi": "10.2514/1.g007186",
        "created": "2022-08-05",
        "url": "https://arxiv.org/abs/2208.03378",
        "authors": [
            "rodolfo batista negri",
            "ant\u00f4nio fernando bertachini de almeida prado",
            "ronan arraes jardim chagas",
            "rodolpho vilhena de moraes"
        ]
    },
    {
        "id": "2209.01710",
        "title": "perception simplex: verifiable collision avoidance in autonomous   vehicles amidst obstacle detection faults",
        "abstract": "advances in deep learning have revolutionized cyber-physical applications, including the development of autonomous vehicles. however, real-world collisions involving autonomous control of vehicles have raised significant safety concerns regarding the use of deep neural networks (dnn) in safety-critical tasks, particularly perception. the inherent unverifiability of dnns poses a key challenge in ensuring their safe and reliable operation.   in this work, we propose perception simplex (ps), a fault-tolerant application architecture designed for obstacle detection and collision avoidance. we analyze an existing lidar-based classical obstacle detection algorithm to establish strict bounds on its capabilities and limitations. such analysis and verification have not been possible for deep learning-based perception systems yet. by employing verifiable obstacle detection algorithms, ps identifies obstacle existence detection faults in the output of unverifiable dnn-based object detectors. when faults with potential collision risks are detected, appropriate corrective actions are initiated. through extensive analysis and software-in-the-loop simulations, we demonstrate that ps provides predictable and deterministic fault tolerance against obstacle existence detection faults, establishing a robust safety guarantee.",
        "doi": "",
        "created": "2022-09-04",
        "url": "https://arxiv.org/abs/2209.01710",
        "authors": [
            "ayoosh bansal",
            "hunmin kim",
            "simon yu",
            "bo li",
            "naira hovakimyan",
            "marco caccamo",
            "lui sha"
        ]
    },
    {
        "id": "2209.14089",
        "title": "combining reinforcement learning and tensor networks, with an   application to dynamical large deviations",
        "abstract": "we present a framework to integrate tensor network (tn) methods with reinforcement learning (rl) for solving dynamical optimisation tasks. we consider the rl actor-critic method, a model-free approach for solving rl problems, and introduce tns as the approximators for its policy and value functions. our \"actor-critic with tensor networks\" (acten) method is especially well suited to problems with large and factorisable state and action spaces. as an illustration of the applicability of acten we solve the exponentially hard task of sampling rare trajectories in two paradigmatic stochastic models, the east model of glasses and the asymmetric simple exclusion process (asep), the latter being particularly challenging to other methods due to the absence of detailed balance. with substantial potential for further integration with the vast array of existing rl methods, the approach introduced here is promising both for applications in physics and to multi-agent rl problems more generally.",
        "doi": "",
        "created": "2022-09-28",
        "url": "https://arxiv.org/abs/2209.14089",
        "authors": [
            "edward gillman",
            "dominic c. rose",
            "juan p. garrahan"
        ]
    },
    {
        "id": "2210.01954",
        "title": "ruler rolling",
        "abstract": "at cccg '21 o'rourke proposed a variant of hopcroft, josephs and whitesides' (1985) np-complete problem {\\sc ruler folding}, which he called {\\sc ruler wrapping} and for which all folds must be 180 degrees in the same direction. gagie, saeidi and sapucaia (2023) noted that if the last straight section of the ruler must be longest, then {\\sc ruler wrapping} is equivalent to partitioning a string of positive integers into substrings whose sums are increasing such that the last substring sums to at most a given amount. they gave linear-time algorithms for the versions of {\\sc ruler wrapping} both with and without this assumption. in real life we cannot repeatedly fold a carpenter's ruler 180 degrees in the same direction. in this paper we propose the more realistic problem of {\\sc ruler rolling}, in which we repeatedly fold the segments 90 degrees in the same direction and thus fold the ruler into a rectangle instead of into an interval. we should report all the pareto-optimal rollings. we note that if the last straight section of the ruler must be longer than the third to last -- analogously to gagie et al.'s assumption -- then {\\sc ruler rolling} is equivalent to partitioning a string of positive integers into substrings such that the sums of the even substrings are increasing, as are the sums of the odd substrings. we give a simple dynamic-programming algorithm that reports all the pareto-optimal rollings in quadratic time under this assumption. our algorithm still works even without the assumption, but then we are left with a quadratic number of two-dimensional feasible solutions, so finding the pareto-optimal ones and increases our running time by a logarithmic factor. if we have a nice objective function, however, we still use quadratic time.",
        "doi": "",
        "created": "2022-10-04",
        "url": "https://arxiv.org/abs/2210.01954",
        "authors": [
            "xing lyu",
            "travis gagie",
            "meng he"
        ]
    },
    {
        "id": "2211.00912",
        "title": "bipartite mixed membership distribution-free model. a novel model for   community detection in overlapping bipartite weighted networks",
        "abstract": "modeling and estimating mixed memberships for overlapping unipartite un-weighted networks has been well studied in recent years. however, to our knowledge, there is no model for a more general case, the overlapping bipartite weighted networks. to close this gap, we introduce a novel model, the bipartite mixed membership distribution-free (bimmdf) model. our model allows an adjacency matrix to follow any distribution as long as its expectation has a block structure related to node membership. in particular, bimmdf can model overlapping bipartite signed networks and it is an extension of many previous models, including the popular mixed membership stochastic blcokmodels. an efficient algorithm with a theoretical guarantee of consistent estimation is applied to fit bimmdf. we then obtain the separation conditions of bimmdf for different distributions. furthermore, we also consider missing edges for sparse networks. the advantage of bimmdf is demonstrated in extensive synthetic networks and eight real-world networks.",
        "doi": "",
        "created": "2022-11-02",
        "url": "https://arxiv.org/abs/2211.00912",
        "authors": [
            "huan qing",
            "jingli wang"
        ]
    },
    {
        "id": "2211.04732",
        "title": "directed acyclic outerplanar graphs have constant stack number",
        "abstract": "the stack number of a directed acyclic graph $g$ is the minimum $k$ for which there is a topological ordering of $g$ and a $k$-coloring of the edges such that no two edges of the same color cross, i.e., have alternating endpoints along the topological ordering. we prove that the stack number of directed acyclic outerplanar graphs is bounded by a constant, which gives a positive answer to a conjecture by heath, pemmaraju and trenk [siam j. computing, 1999]. as an immediate consequence, this shows that all upward outerplanar graphs have constant stack number, answering a question by bhore et al. [eur. j. comb., 2023] and thereby making significant progress towards the problem for general upward planar graphs originating from nowakowski and parker [order, 1989]. as our main tool we develop the novel technique of directed $h$-partitions, which might be of independent interest. we complement the bounded stack number for directed acyclic outerplanar graphs by constructing a family of directed acyclic 2-trees that have unbounded stack number, thereby refuting a conjecture by n\\\"ollenburg and pupyrev [gd 2023].",
        "doi": "10.1109/focs57990.2023.00118",
        "created": "2022-11-09",
        "url": "https://arxiv.org/abs/2211.04732",
        "authors": [
            "paul jungeblut",
            "laura merker",
            "torsten ueckerdt"
        ]
    },
    {
        "id": "2211.09129",
        "title": "characterizing 4-string contact interaction using machine learning",
        "abstract": "the geometry of 4-string contact interaction of closed string field theory is characterized using machine learning. we obtain strebel quadratic differentials on 4-punctured spheres as a neural network by performing unsupervised learning with a custom-built loss function. this allows us to solve for local coordinates and compute their associated mapping radii numerically. we also train a neural network distinguishing vertex from feynman region. as a check, 4-tachyon contact term in the tachyon potential is computed and a good agreement with the results in the literature is observed. we argue that our algorithm is manifestly independent of number of punctures and scaling it to characterize the geometry of $n$-string contact interaction is feasible.",
        "doi": "10.1007/jhep04(2024)016",
        "created": "2022-11-16",
        "url": "https://arxiv.org/abs/2211.09129",
        "authors": [
            "harold erbin",
            "atakan hilmi f\u0131rat"
        ]
    },
    {
        "id": "2211.10583",
        "title": "an information-state based approach to linear time varying system   identification and control",
        "abstract": "this paper considers the problem of system identification for linear time varying systems. we propose a new system realization approach that uses an \"information-state\" as the state vector, where the \"information-state\" is composed of a finite number of past inputs and outputs. the system identification algorithm uses input-output data to fit an autoregressive moving average model (arma) to represent the current output in terms of finite past inputs and outputs. this information-state-based approach allows us to directly realize a state-space model using the estimated time varying arma paramters linear time varying (ltv) systems. the paper develops the theoretical foundation for using arma parameters-based system representation using only the concept of linear observability, details the reasoning for exact output modeling using only the finite history, and shows that there is no need to separate the free and the forced response for identification. the paper also discusses the implications of using the information-state system for optimal output feedback control and shows that the solution obtained using a suitably posed information state problem is optimal for the original problem. the proposed approach is tested on various different systems, and the performance is compared with state-of-the-art ltv system identification techniques.",
        "doi": "",
        "created": "2022-11-18",
        "url": "https://arxiv.org/abs/2211.10583",
        "authors": [
            "mohamed naveed gul mohamed",
            "raman goyal",
            "suman chakravorty",
            "ran wang"
        ]
    },
    {
        "id": "2212.03822",
        "title": "anisotropic weakly over-penalised symmetric interior penalty method for   the stokes equation",
        "abstract": "in this study, we investigate an anisotropic weakly over-penalised symmetric interior penalty method for the stokes equation {on convex domains}. our approach is a simple discontinuous galerkin method similar to the crouzeix--raviart finite element method. as our primary contribution, we show a new proof for the consistency term, which allows us to obtain an estimate of the anisotropic consistency error. the key idea of the proof is to apply the relation between the raviart--thomas finite element space and a discontinuous space. while inf-sup stable schemes of the discontinuous galerkin method on shape-regular mesh partitions have been widely discussed, our results show that the stokes element satisfies the inf-sup condition on anisotropic meshes. furthermore, we provide an error estimate in an energy norm on anisotropic meshes. in numerical experiments, we compare calculation results for standard and anisotropic mesh partitions.",
        "doi": "",
        "created": "2022-12-07",
        "url": "https://arxiv.org/abs/2212.03822",
        "authors": [
            "hiroki ishizaka"
        ]
    },
    {
        "id": "2212.13847",
        "title": "heterogeneous graph contrastive learning with meta-path contexts and   adaptively weighted negative samples",
        "abstract": "heterogeneous graph contrastive learning has received wide attention recently. some existing methods use meta-paths, which are sequences of object types that capture semantic relationships between objects, to construct contrastive views. however, most of them ignore the rich meta-path context information that describes how two objects are connected by meta-paths. further, they fail to distinguish negative samples, which could adversely affect the model performance. to address the problems, we propose meow, which considers both meta-path contexts and weighted negative samples. specifically, meow constructs a coarse view and a fine-grained view for contrast. the former reflects which objects are connected by meta-paths, while the latter uses meta-path contexts and characterizes details on how the objects are connected. then, we theoretically analyze the infonce loss and recognize its limitations for computing gradients of negative samples. to better distinguish negative samples, we learn hard-valued weights for them based on node clustering and use prototypical contrastive learning to pull close embeddings of nodes in the same cluster. in addition, we propose a variant model adameow that adaptively learns soft-valued weights of negative samples to further improve node representation. finally, we conduct extensive experiments to show the superiority of meow and adameow against other state-of-the-art methods.",
        "doi": "10.1109/tkde.2024.3377431",
        "created": "2022-12-28",
        "url": "https://arxiv.org/abs/2212.13847",
        "authors": [
            "jianxiang yu",
            "qingqing ge",
            "xiang li",
            "aoying zhou"
        ]
    },
    {
        "id": "2301.07002",
        "title": "opti-cam: optimizing saliency maps for interpretability",
        "abstract": "methods based on class activation maps (cam) provide a simple mechanism to interpret predictions of convolutional neural networks by using linear combinations of feature maps as saliency maps. by contrast, masking-based methods optimize a saliency map directly in the image space or learn it by training another network on additional data.   in this work we introduce opti-cam, combining ideas from cam-based and masking-based approaches. our saliency map is a linear combination of feature maps, where weights are optimized per image such that the logit of the masked image for a given class is maximized. we also fix a fundamental flaw in two of the most common evaluation metrics of attribution methods. on several datasets, opti-cam largely outperforms other cam-based approaches according to the most relevant classification metrics. we provide empirical evidence supporting that localization and classifier interpretability are not necessarily aligned.",
        "doi": "",
        "created": "2023-01-17",
        "url": "https://arxiv.org/abs/2301.07002",
        "authors": [
            "hanwei zhang",
            "felipe torres",
            "ronan sicre",
            "yannis avrithis",
            "stephane ayache"
        ]
    },
    {
        "id": "2301.08965",
        "title": "raw or cooked? object detection on raw images",
        "abstract": "images fed to a deep neural network have in general undergone several handcrafted image signal processing (isp) operations, all of which have been optimized to produce visually pleasing images. in this work, we investigate the hypothesis that the intermediate representation of visually pleasing images is sub-optimal for downstream computer vision tasks compared to the raw image representation. we suggest that the operations of the isp instead should be optimized towards the end task, by learning the parameters of the operations jointly during training. we extend previous works on this topic and propose a new learnable operation that enables an object detector to achieve superior performance when compared to both previous works and traditional rgb images. in experiments on the open pascalraw dataset, we empirically confirm our hypothesis.",
        "doi": "10.1007/978-3-031-31435-3_25",
        "created": "2023-01-21",
        "url": "https://arxiv.org/abs/2301.08965",
        "authors": [
            "william ljungbergh",
            "joakim johnander",
            "christoffer petersson",
            "michael felsberg"
        ]
    },
    {
        "id": "2301.13452",
        "title": "distribution of the number of pivots needed using gaussian elimination   with partial pivoting on random matrices",
        "abstract": "gaussian elimination with partial pivoting (gepp) is a widely used method to solve dense linear systems. each gepp step uses a row transposition pivot movement if needed to ensure the leading pivot entry is maximal in magnitude for the leading column of the remaining untriangularized subsystem. we will use theoretical and numerical approaches to study how often this pivot movement is needed. we provide full distributional descriptions for the number of pivot movements needed using gepp using particular haar random ensembles, as well as compare these models to other common transformations from randomized numerical linear algebra. additionally, we introduce new random ensembles with fixed pivot movement counts and fixed sparsity, $\\alpha$. experiments estimating the empirical spectral density (esd) of these random ensembles leads to a new conjecture on a universality class of random matrices with fixed sparsity whose scaled esd converges to a measure on the complex unit disk that depends on $\\alpha$ and is an interpolation of the uniform measure on the unit disk and the dirac measure at the origin.",
        "doi": "10.1214/23-aap2023",
        "created": "2023-01-31",
        "url": "https://arxiv.org/abs/2301.13452",
        "authors": [
            "john peca-medlin"
        ]
    },
    {
        "id": "2302.01892",
        "title": "nonconvex distributed feedback optimization for aggregative cooperative   robotics",
        "abstract": "distributed aggregative optimization is a recently emerged framework in which the agents of a network want to minimize the sum of local objective functions, each one depending on the agent decision variable (e.g., the local position of a team of robots) and an aggregation of all the agents' variables (e.g., the team barycentre). in this paper, we address a distributed feedback optimization framework in which agents implement a local (distributed) policy to reach a steady-state minimizing an aggregative cost function. we propose aggregative tracking feedback, i.e., a novel distributed feedback optimization law in which each agent combines a closed-loop gradient flow with a consensus-based dynamic compensator reconstructing the missing global information. by using tools from system theory, we prove that aggregative tracking feedback steers the network to a stationary point of an aggregative optimization problem with (possibly) nonconvex objective function. the effectiveness of the proposed method is validated through numerical simulations on a multi-robot surveillance scenario.",
        "doi": "",
        "created": "2023-02-03",
        "url": "https://arxiv.org/abs/2302.01892",
        "authors": [
            "guido carnevale",
            "nicola mimmo",
            "giuseppe notarstefano"
        ]
    },
    {
        "id": "2302.02568",
        "title": "less is more: understanding word-level textual adversarial attack via   n-gram frequency descend",
        "abstract": "word-level textual adversarial attacks have demonstrated notable efficacy in misleading natural language processing (nlp) models. despite their success, the underlying reasons for their effectiveness and the fundamental characteristics of adversarial examples (aes) remain obscure. this work aims to interpret word-level attacks by examining their $n$-gram frequency patterns. our comprehensive experiments reveal that in approximately 90\\% of cases, word-level attacks lead to the generation of examples where the frequency of $n$-grams decreases, a tendency we term as the $n$-gram frequency descend ($n$-fd). this finding suggests a straightforward strategy to enhance model robustness: training models using examples with $n$-fd. to examine the feasibility of this strategy, we employed the $n$-gram frequency information, as an alternative to conventional loss gradients, to generate perturbed examples in adversarial training. the experiment results indicate that the frequency-based approach performs comparably with the gradient-based approach in improving model robustness. our research offers a novel and more intuitive perspective for understanding word-level textual adversarial attacks and proposes a new direction to improve model robustness.",
        "doi": "",
        "created": "2023-02-06",
        "url": "https://arxiv.org/abs/2302.02568",
        "authors": [
            "ning lu",
            "shengcai liu",
            "zhirui zhang",
            "qi wang",
            "haifeng liu",
            "ke tang"
        ]
    },
    {
        "id": "2302.08984",
        "title": "deter: design for trust utilizing rareness reduction",
        "abstract": "increasing design complexity and reduced time-to-market have motivated manufacturers to outsource some parts of the system-on-chip (soc) design flow to third-party vendors. this provides an opportunity for attackers to introduce hardware trojans by constructing stealthy triggers consisting of rare events (e.g., rare signals, states, and transitions). there are promising test generation-based hardware trojan detection techniques that rely on the activation of rare events. in this paper, we investigate rareness reduction as a design-for-trust solution to make it harder for an adversary to hide trojans (easier for trojan detection). specifically, we analyze different avenues to reduce the potential rare trigger cases, including design diversity and area optimization. while there is a good understanding of the relationship between area, power, energy, and performance, this research provides a better insight into the dependency between area and security. our experimental evaluation demonstrates that area reduction leads to a reduction in rareness. it also reveals that reducing rareness leads to faster trojan detection as well as improved coverage by trojan detection methods.",
        "doi": "10.1109/vlsid60093.2024.00079",
        "created": "2023-02-17",
        "url": "https://arxiv.org/abs/2302.08984",
        "authors": [
            "aruna jayasena",
            "prabhat mishra"
        ]
    },
    {
        "id": "2302.13051",
        "title": "suspension analysis and selective continuation-passing style for   universal probabilistic programming languages",
        "abstract": "universal probabilistic programming languages (ppls) make it relatively easy to encode and automatically solve statistical inference problems. to solve inference problems, ppl implementations often apply monte carlo inference algorithms that rely on execution suspension. state-of-the-art solutions enable execution suspension either through (i) continuation-passing style (cps) transformations or (ii) efficient, but comparatively complex, low-level solutions that are often not available in high-level languages. cps transformations introduce overhead due to unnecessary closure allocations -- a problem the ppl community has generally overlooked. to reduce overhead, we develop a new efficient selective cps approach for ppls. specifically, we design a novel static suspension analysis technique that determines parts of programs that require suspension, given a particular inference algorithm. the analysis allows selectively cps transforming the program only where necessary. we formally prove the correctness of the analysis and implement the analysis and transformation in the miking coreppl compiler. we evaluate the implementation for a large number of monte carlo inference algorithms on real-world models from phylogenetics, epidemiology, and topic modeling. the evaluation results demonstrate significant improvements across all models and inference algorithms.",
        "doi": "10.1007/978-3-031-57267-8_12",
        "created": "2023-02-25",
        "url": "https://arxiv.org/abs/2302.13051",
        "authors": [
            "daniel lund\u00e9n",
            "lars hummelgren",
            "jan kudlicka",
            "oscar eriksson",
            "david broman"
        ]
    },
    {
        "id": "2303.01440",
        "title": "programmatic imitation learning from unlabeled and noisy demonstrations",
        "abstract": "imitation learning (il) is a promising paradigm for teaching robots to perform novel tasks using demonstrations. most existing approaches for il utilize neural networks (nn), however, these methods suffer from several well-known limitations: they 1) require large amounts of training data, 2) are hard to interpret, and 3) are hard to repair and adapt. there is an emerging interest in programmatic imitation learning (pil), which offers significant promise in addressing the above limitations. in pil, the learned policy is represented in a programming language, making it amenable to interpretation and repair. however, state-of-the-art pil algorithms assume access to action labels and struggle to learn from noisy real-world demonstrations. in this paper, we propose plunder, a novel pil algorithm that integrates a probabilistic program synthesizer in an iterative expectation-maximization (em) framework to address these shortcomings. unlike existing pil approaches, plunder synthesizes probabilistic programmatic policies that are particularly well-suited for modeling the uncertainties inherent in real-world demonstrations. our approach leverages an em loop to simultaneously infer the missing action labels and the most likely probabilistic policy. we benchmark plunder against several established il techniques, and demonstrate its superiority across five challenging imitation learning tasks under noise. plunder policies achieve 95% accuracy in matching the given demonstrations, outperforming the next best baseline by 19%. additionally, policies generated by plunder successfully complete the tasks 17% more frequently than the nearest baseline.",
        "doi": "10.1109/lra.2024.3385691",
        "created": "2023-03-02",
        "url": "https://arxiv.org/abs/2303.01440",
        "authors": [
            "jimmy xin",
            "linus zheng",
            "kia rahmani",
            "jiayi wei",
            "jarrett holtz",
            "isil dillig",
            "joydeep biswas"
        ]
    },
    {
        "id": "2303.01826",
        "title": "topspark: a timestep optimization methodology for energy-efficient   spiking neural networks on autonomous mobile agents",
        "abstract": "autonomous mobile agents require low-power/energy-efficient machine learning (ml) algorithms to complete their ml-based tasks while adapting to diverse environments, as mobile agents are usually powered by batteries. these requirements can be fulfilled by spiking neural networks (snns) as they offer low power/energy processing due to their sparse computations and efficient online learning with bio-inspired learning mechanisms for adapting to different environments. recent works studied that the energy consumption of snns can be optimized by reducing the computation time of each neuron for processing a sequence of spikes (timestep). however, state-of-the-art techniques rely on intensive design searches to determine fixed timestep settings for only inference, thereby hindering the snns from achieving further energy efficiency gains in both training and inference. these techniques also restrict the snns from performing efficient online learning at run time. toward this, we propose topspark, a novel methodology that leverages adaptive timestep reduction to enable energy-efficient snn processing in both training and inference, while keeping its accuracy close to the accuracy of snns without timestep reduction. the ideas of topspark include: analyzing the impact of different timesteps on the accuracy; identifying neuron parameters that have a significant impact on accuracy in different timesteps; employing parameter enhancements that make snns effectively perform learning and inference using less spiking activity; and developing a strategy to trade-off accuracy, latency, and energy to meet the design requirements. the results show that, topspark saves the snn latency by 3.9x as well as energy consumption by 3.5x (training) and 3.3x (inference) on average, across different network sizes, learning rules, and workloads, while maintaining the accuracy within 2% of snns without timestep reduction.",
        "doi": "10.1109/iros55552.2023.10342499",
        "created": "2023-03-03",
        "url": "https://arxiv.org/abs/2303.01826",
        "authors": [
            "rachmad vidya wicaksana putra",
            "muhammad shafique"
        ]
    },
    {
        "id": "2303.16611",
        "title": "4d facial expression diffusion model",
        "abstract": "facial expression generation is one of the most challenging and long-sought aspects of character animation, with many interesting applications. the challenging task, traditionally having relied heavily on digital craftspersons, remains yet to be explored. in this paper, we introduce a generative framework for generating 3d facial expression sequences (i.e. 4d faces) that can be conditioned on different inputs to animate an arbitrary 3d face mesh. it is composed of two tasks: (1) learning the generative model that is trained over a set of 3d landmark sequences, and (2) generating 3d mesh sequences of an input facial mesh driven by the generated landmark sequences. the generative model is based on a denoising diffusion probabilistic model (ddpm), which has achieved remarkable success in generative tasks of other domains. while it can be trained unconditionally, its reverse process can still be conditioned by various condition signals. this allows us to efficiently develop several downstream tasks involving various conditional generation, by using expression labels, text, partial sequences, or simply a facial geometry. to obtain the full mesh deformation, we then develop a landmark-guided encoder-decoder to apply the geometrical deformation embedded in landmarks on a given facial mesh. experiments show that our model has learned to generate realistic, quality expressions solely from the dataset of relatively small size, improving over the state-of-the-art methods. videos and qualitative comparisons with other methods can be found at https://github.com/zoukaifeng/4dfm. code and models will be made available upon acceptance.",
        "doi": "10.1145/3653455",
        "created": "2023-03-29",
        "url": "https://arxiv.org/abs/2303.16611",
        "authors": [
            "kaifeng zou",
            "sylvain faisan",
            "boyang yu",
            "s\u00e9bastien valette",
            "hyewon seo"
        ]
    },
    {
        "id": "2303.16854",
        "title": "annollm: making large language models to be better crowdsourced   annotators",
        "abstract": "many natural language processing (nlp) tasks rely on labeled data to train machine learning models with high performance. however, data annotation is time-consuming and expensive, especially when the task involves a large amount of data or requires specialized domains. recently, gpt-3.5 series models have demonstrated remarkable few-shot and zero-shot ability across various nlp tasks. in this paper, we first claim that large language models (llms), such as gpt-3.5, can serve as an excellent crowdsourced annotator when provided with sufficient guidance and demonstrated examples. accordingly, we propose annollm, an annotation system powered by llms, which adopts a two-step approach, explain-then-annotate. concretely, we first prompt llms to provide explanations for why the specific ground truth answer/label was assigned for a given example. then, we construct the few-shot chain-of-thought prompt with the self-generated explanation and employ it to annotate the unlabeled data with llms. our experiment results on three tasks, including user input and keyword relevance assessment, boolq, and wic, demonstrate that annollm surpasses or performs on par with crowdsourced annotators. furthermore, we build the first conversation-based information retrieval dataset employing annollm. this dataset is designed to facilitate the development of retrieval models capable of retrieving pertinent documents for conversational text. human evaluation has validated the dataset's high quality.",
        "doi": "",
        "created": "2023-03-29",
        "url": "https://arxiv.org/abs/2303.16854",
        "authors": [
            "xingwei he",
            "zhenghao lin",
            "yeyun gong",
            "a-long jin",
            "hang zhang",
            "chen lin",
            "jian jiao",
            "siu ming yiu",
            "nan duan",
            "weizhu chen"
        ]
    },
    {
        "id": "2303.18086",
        "title": "differentially private stream processing at scale",
        "abstract": "we design, to the best of our knowledge, the first differentially private (dp) stream aggregation processing system at scale. our system -- differential privacy sql pipelines (dp-sqlp) -- is built using a streaming framework similar to spark streaming, and is built on top of the spanner database and the f1 query engine from google.   towards designing dp-sqlp we make both algorithmic and systemic advances, namely, we (i) design a novel (user-level) dp key selection algorithm that can operate on an unbounded set of possible keys, and can scale to one billion keys that users have contributed, (ii) design a preemptive execution scheme for dp key selection that avoids enumerating all the keys at each triggering time, and (iii) use algorithmic techniques from dp continual observation to release a continual dp histogram of user contributions to different keys over the stream length. we empirically demonstrate the efficacy by obtaining at least $16\\times$ reduction in error over meaningful baselines we consider. we implemented a streaming differentially private user impressions for google shopping with dp-sqlp. the streaming dp algorithms are further applied to google trends.",
        "doi": "",
        "created": "2023-03-31",
        "url": "https://arxiv.org/abs/2303.18086",
        "authors": [
            "bing zhang",
            "vadym doroshenko",
            "peter kairouz",
            "thomas steinke",
            "abhradeep thakurta",
            "ziyin ma",
            "eidan cohen",
            "himani apte",
            "jodi spacek"
        ]
    },
    {
        "id": "2304.01834",
        "title": "neural field convolutions by repeated differentiation",
        "abstract": "neural fields are evolving towards a general-purpose continuous representation for visual computing. yet, despite their numerous appealing properties, they are hardly amenable to signal processing. as a remedy, we present a method to perform general continuous convolutions with general continuous signals such as neural fields. observing that piecewise polynomial kernels reduce to a sparse set of dirac deltas after repeated differentiation, we leverage convolution identities and train a repeated integral field to efficiently execute large-scale convolutions. we demonstrate our approach on a variety of data modalities and spatially-varying kernels.",
        "doi": "10.1145/3618340",
        "created": "2023-04-04",
        "url": "https://arxiv.org/abs/2304.01834",
        "authors": [
            "ntumba elie nsampi",
            "adarsh djeacoumar",
            "hans-peter seidel",
            "tobias ritschel",
            "thomas leimk\u00fchler"
        ]
    },
    {
        "id": "2304.03560",
        "title": "dualrefine: self-supervised depth and pose estimation through iterative   epipolar sampling and refinement toward equilibrium",
        "abstract": "self-supervised multi-frame depth estimation achieves high accuracy by computing matching costs of pixel correspondences between adjacent frames, injecting geometric information into the network. these pixel-correspondence candidates are computed based on the relative pose estimates between the frames. accurate pose predictions are essential for precise matching cost computation as they influence the epipolar geometry. furthermore, improved depth estimates can, in turn, be used to align pose estimates.   inspired by traditional structure-from-motion (sfm) principles, we propose the dualrefine model, which tightly couples depth and pose estimation through a feedback loop. our novel update pipeline uses a deep equilibrium model framework to iteratively refine depth estimates and a hidden state of feature maps by computing local matching costs based on epipolar geometry. importantly, we used the refined depth estimates and feature maps to compute pose updates at each step. this update in the pose estimates slowly alters the epipolar geometry during the refinement process. experimental results on the kitti dataset demonstrate competitive depth prediction and odometry prediction performance surpassing published self-supervised baselines.",
        "doi": "",
        "created": "2023-04-07",
        "url": "https://arxiv.org/abs/2304.03560",
        "authors": [
            "antyanta bangunharcana",
            "ahmed magd",
            "kyung-soo kim"
        ]
    },
    {
        "id": "2304.07188",
        "title": "plant-inspired behavior-based controller to enable reaching in redundant   continuum robot arms",
        "abstract": "enabling reaching capabilities in highly redundant continuum robot arms is an active area of research. existing solutions comprise of task-space controllers, whose proper functioning is still limited to laboratory environments. in contrast, this work proposes a novel plant-inspired behaviour-based controller that exploits information obtained from proximity sensing embedded near the end-effector to move towards a desired spatial target. the controller is tested on a 9-dof modular cable-driven continuum arm for reaching multiple setpoints in space. the results are promising for the deployability of these systems into unstructured environments.",
        "doi": "10.1109/robosoft55895.2023.10122017",
        "created": "2023-04-14",
        "url": "https://arxiv.org/abs/2304.07188",
        "authors": [
            "enrico donato",
            "yasmin tauqeer ansari",
            "cecilia laschi",
            "egidio falotico"
        ]
    },
    {
        "id": "2304.07456",
        "title": "unifying privacy measures via maximal $(\\alpha,\\beta)$-leakage   (m$\\alpha$bel)",
        "abstract": "we introduce a family of information leakage measures called maximal $(\\alpha,\\beta)$-leakage (m$\\alpha$bel), parameterized by real numbers $\\alpha$ and $\\beta$ greater than or equal to 1. the measure is formalized via an operational definition involving an adversary guessing an unknown (randomized) function of the data given the released data. we obtain a simplified computable expression for the measure and show that it satisfies several basic properties such as monotonicity in $\\beta$ for a fixed $\\alpha$, non-negativity, data processing inequalities, and additivity over independent releases. we highlight the relevance of this family by showing that it bridges several known leakage measures, including maximal $\\alpha$-leakage $(\\beta=1)$, maximal leakage $(\\alpha=\\infty,\\beta=1)$, local differential privacy (ldp) $(\\alpha=\\infty,\\beta=\\infty)$, and local renyi differential privacy (lrdp) $(\\alpha=\\beta)$, thereby giving an operational interpretation to local renyi differential privacy. we also study a conditional version of m$\\alpha$bel on leveraging which we recover differential privacy and renyi differential privacy. a new variant of lrdp, which we call maximal renyi leakage, appears as a special case of m$\\alpha$bel for $\\alpha=\\infty$ that smoothly tunes between maximal leakage ($\\beta=1$) and ldp ($\\beta=\\infty$). finally, we show that a vector form of the maximal renyi leakage relaxes differential privacy under gaussian and laplacian mechanisms.",
        "doi": "",
        "created": "2023-04-14",
        "url": "https://arxiv.org/abs/2304.07456",
        "authors": [
            "atefeh gilani",
            "gowtham r. kurri",
            "oliver kosut",
            "lalitha sankar"
        ]
    },
    {
        "id": "2305.00434",
        "title": "evreal: towards a comprehensive benchmark and analysis suite for   event-based video reconstruction",
        "abstract": "event cameras are a new type of vision sensor that incorporates asynchronous and independent pixels, offering advantages over traditional frame-based cameras such as high dynamic range and minimal motion blur. however, their output is not easily understandable by humans, making the reconstruction of intensity images from event streams a fundamental task in event-based vision. while recent deep learning-based methods have shown promise in video reconstruction from events, this problem is not completely solved yet. to facilitate comparison between different approaches, standardized evaluation protocols and diverse test datasets are essential. this paper proposes a unified evaluation methodology and introduces an open-source framework called evreal to comprehensively benchmark and analyze various event-based video reconstruction methods from the literature. using evreal, we give a detailed analysis of the state-of-the-art methods for event-based video reconstruction, and provide valuable insights into the performance of these methods under varying settings, challenging scenarios, and downstream tasks.",
        "doi": "10.1109/cvprw59228.2023.00410",
        "created": "2023-04-30",
        "url": "https://arxiv.org/abs/2305.00434",
        "authors": [
            "burak ercan",
            "onur eker",
            "aykut erdem",
            "erkut erdem"
        ]
    },
    {
        "id": "2305.04311",
        "title": "egglog python: a pythonic library for e-graphs",
        "abstract": "e-graphs have emerged as a versatile data structure with applications in synthesis, optimization, and verification through techniques such as equality saturation. this paper introduces python bindings for the experimental egglog library (previously called egg-smol), which aims to bring the benefits of e-graphs to the python ecosystem. the bindings offer a high-level, pythonic api providing an accessible and familiar interface for python users. by integrating e-graph techniques with python, we hope to enable collaboration and innovation across various domains in the scientific computing and machine learning communities. we discuss the advantages of using python bindings for both python and existing egg-smol users, as well as possible future directions for development.",
        "doi": "",
        "created": "2023-05-07",
        "url": "https://arxiv.org/abs/2305.04311",
        "authors": [
            "saul shanabrook"
        ]
    },
    {
        "id": "2305.04615",
        "title": "performance analysis of in-band-full-duplex multi-cell wideband iab   networks",
        "abstract": "this paper analyzes the performance of the 3rd generation partnership project (3gpp)-inspired multi-cell wideband single-hop backhaul millimeter-wave-in-band-full-duplex (ibfd)-integrated access and backhaul (iab) networks by using stochastic geometry. we model the wired-connected next generation nodebs (gnbs) as the mat\\'ern hard-core point process (mhcpp) to meet the real-world deployment requirement and reduce the cost caused by wired connection in the network. we first derive association probabilities that reflect how likely the typical user-equipment is served by a gnb or an iab-node based on the maximum long-term averaged biased-received-desired-signal power criteria. further, by leveraging the composite gamma-lognormal distribution, we derive the closed-form signal to interference plus noise ratio coverage, capacity with outage, and ergodic capacity of the network. in order to avoid underestimating the noise, we consider the sidelobe gain on inter-cell interference links and the analog to digital converter quantization noise. compared with the half-duplex transmission, numerical results show an enhanced capacity with outage and ergodic capacity provided by ibfd under successful self-interference cancellation. we also study how the power bias and density ratio of the iab-node to gnb, and the hard-core distance can affect system performances.",
        "doi": "10.1109/access.2024.3382719",
        "created": "2023-05-08",
        "url": "https://arxiv.org/abs/2305.04615",
        "authors": [
            "junkai zhang",
            "tharmalingam ratnarajah"
        ]
    },
    {
        "id": "2305.05006",
        "title": "synthesis of annotated colorectal cancer tissue images from gland layout",
        "abstract": "generating realistic tissue images with annotations is a challenging task that is important in many computational histopathology applications. synthetically generated images and annotations are valuable for training and evaluating algorithms in this domain. to address this, we propose an interactive framework generating pairs of realistic colorectal cancer histology images with corresponding glandular masks from glandular structure layouts. the framework accurately captures vital features like stroma, goblet cells, and glandular lumen. users can control gland appearance by adjusting parameters such as the number of glands, their locations, and sizes. the generated images exhibit good frechet inception distance (fid) scores compared to the state-of-the-art image-to-image translation model. additionally, we demonstrate the utility of our synthetic annotations for evaluating gland segmentation algorithms. furthermore, we present a methodology for constructing glandular masks using advanced deep generative models, such as latent diffusion models. these masks enable tissue image generation through a residual encoder-decoder network.",
        "doi": "",
        "created": "2023-05-08",
        "url": "https://arxiv.org/abs/2305.05006",
        "authors": [
            "srijay deshpande",
            "fayyaz minhas",
            "nasir rajpoot"
        ]
    },
    {
        "id": "2305.07490",
        "title": "artgpt-4: towards artistic-understanding large vision-language models   with enhanced adapter",
        "abstract": "the success of large language models (llms) has inspired an emerging research field of multimodal learning. however, a grand challenge of exploiting llms for multimodal learning is the size of pre-trained llms which are always with billions of parameters. to tackle this challenge, models such as minigpt-4 and llava have been developed to fine-tune the pre-trained models using fewer parameters. despite their promising performance, these models remain limited in their understanding of artistic imagery. to facilitate better artistic-understanding, in this paper, we propose artgpt-4, a pioneering large vision-language model tailored to address the limitations of existing models in artistic comprehension. the key innovation of artgpt-4 lies in its craft for the sophisticated challenge of artistic image comprehension, setting it apart from other models that overlook fine details for broader themes. specifically, it works by integrating some specialized adapter layers into the llm, enabling the model to more efficiently and effectively parse and interpret complex visual tokens, instead of fine-tuning the whole llm as in the existing method. artgpt-4 has demonstrated its outstanding performance on the efficiency: utilizing a tesla a100 device, its training can be completed in mere 2 hours with an image-text pair dataset comprising approximately 0.52m entries. additionally, artgpt-4 has also achieved state-of-the-art performance on the artemis and artemis-v2.0 datasets as well as the benchmarks established in this work, lagging behind professional artists' descriptions by a negligible 0.15 points on a 6-point scale. the outstanding performance of artgpt-4 shows that it can render images with an artistic-understanding and convey the emotions they inspire, mirroring human interpretation. the code and the pre-trained model are accessible in \\url{https://github.com/dlyuangod/artgpt-4}.",
        "doi": "",
        "created": "2023-05-12",
        "url": "https://arxiv.org/abs/2305.07490",
        "authors": [
            "zhengqing yuan",
            "yunhong he",
            "kun wang",
            "yanfang ye",
            "lichao sun"
        ]
    },
    {
        "id": "2305.11046",
        "title": "difference of submodular minimization via dc programming",
        "abstract": "minimizing the difference of two submodular (ds) functions is a problem that naturally occurs in various machine learning problems. although it is well known that a ds problem can be equivalently formulated as the minimization of the difference of two convex (dc) functions, existing algorithms do not fully exploit this connection. a classical algorithm for dc problems is called the dc algorithm (dca). we introduce variants of dca and its complete form (cdca) that we apply to the dc program corresponding to ds minimization. we extend existing convergence properties of dca, and connect them to convergence properties on the ds problem. our results on dca match the theoretical guarantees satisfied by existing ds algorithms, while providing a more complete characterization of convergence properties. in the case of cdca, we obtain a stronger local minimality guarantee. our numerical results show that our proposed algorithms outperform existing baselines on two applications: speech corpus selection and feature selection.",
        "doi": "",
        "created": "2023-05-18",
        "url": "https://arxiv.org/abs/2305.11046",
        "authors": [
            "marwa el halabi",
            "george orfanides",
            "tim hoheisel"
        ]
    },
    {
        "id": "2305.12173",
        "title": "cryptovampire: automated reasoning for the complete symbolic attacker   cryptographic model",
        "abstract": "cryptographic protocols are hard to design and prove correct, as witnessed by the ever-growing list of attacks even on protocol standards. symbolic models of cryptography enable automated formal security proofs of such protocols against an idealized model, which abstracts away from the algebraic properties of cryptographic schemes and thus misses attacks. computational models yield rigorous guarantees but support at present only interactive proofs and/or restricted classes of protocols. a promising approach is given by the computationally complete symbolic attacker (ccsa), formalized in the bc logic, which aims at bridging and getting the best of the two worlds, obtaining cryptographic guarantees by symbolic analysis. the bc logic is supported by a recently developed interactive theorem prover, squirrel, which enables machine-checked interactive security proofs, as opposed to automated ones, thus requiring expert knowledge.   we introduce the cryptovampire cryptographic protocol verifier, which for the first time fully automates proofs of trace properties in the bc logic. the key technical contribution is a first-order (fo) formalization of protocol properties with tailored handling of subterm relations. we overcome the burden of interactive proving in higher-order (ho) logic and automatically establish soundness of cryptographic protocols using only fo reasoning. on the theoretical side, we restrict full fo logic with cryptographic axioms to ensure that, by losing the expressivity of the ho bc logic, we do not lose soundness. on the practical side, cryptovampire integrates dedicated proof techniques using fo saturation algorithms and heuristics, which enable leveraging the state-of-the-art vampire fo theorem prover as the underlying proving engine. our experimental results show cryptovampire's effectiveness of as a standalone verifier and in terms of automation support for squirrel.",
        "doi": "",
        "created": "2023-05-20",
        "url": "https://arxiv.org/abs/2305.12173",
        "authors": [
            "simon jeanteur",
            "laura kov\u00e1cs",
            "matteo maffei",
            "michael rawson"
        ]
    },
    {
        "id": "2305.13409",
        "title": "efficient learning of quantum states prepared with few non-clifford   gates",
        "abstract": "we give a pair of algorithms that efficiently learn a quantum state prepared by clifford gates and $o(\\log n)$ non-clifford gates. specifically, for an $n$-qubit state $|\\psi\\rangle$ prepared with at most $t$ non-clifford gates, our algorithms use $\\mathsf{poly}(n,2^t,1/\\varepsilon)$ time and copies of $|\\psi\\rangle$ to learn $|\\psi\\rangle$ to trace distance at most $\\varepsilon$.   the first algorithm for this task is more efficient, but requires entangled measurements across two copies of $|\\psi\\rangle$. the second algorithm uses only single-copy measurements at the cost of polynomial factors in runtime and sample complexity. our algorithms more generally learn any state with sufficiently large stabilizer dimension, where a quantum state has stabilizer dimension $k$ if it is stabilized by an abelian group of $2^k$ pauli operators. we also develop an efficient property testing algorithm for stabilizer dimension, which may be of independent interest.",
        "doi": "",
        "created": "2023-05-22",
        "url": "https://arxiv.org/abs/2305.13409",
        "authors": [
            "sabee grewal",
            "vishnu iyer",
            "william kretschmer",
            "daniel liang"
        ]
    },
    {
        "id": "2305.14912",
        "title": "svdinstn: a tensor network paradigm for efficient structure search from   regularized modeling perspective",
        "abstract": "tensor network (tn) representation is a powerful technique for computer vision and machine learning. tn structure search (tn-ss) aims to search for a customized structure to achieve a compact representation, which is a challenging np-hard problem. recent \"sampling-evaluation\"-based methods require sampling an extensive collection of structures and evaluating them one by one, resulting in prohibitively high computational costs. to address this issue, we propose a novel tn paradigm, named svd-inspired tn decomposition (svdinstn), which allows us to efficiently solve the tn-ss problem from a regularized modeling perspective, eliminating the repeated structure evaluations. to be specific, by inserting a diagonal factor for each edge of the fully-connected tn, svdinstn allows us to calculate tn cores and diagonal factors simultaneously, with the factor sparsity revealing a compact tn structure. in theory, we prove a convergence guarantee for the proposed method. experimental results demonstrate that the proposed method achieves approximately 100 to 1000 times acceleration compared to the state-of-the-art tn-ss methods while maintaining a comparable level of representation ability.",
        "doi": "",
        "created": "2023-05-24",
        "url": "https://arxiv.org/abs/2305.14912",
        "authors": [
            "yu-bang zheng",
            "xi-le zhao",
            "junhua zeng",
            "chao li",
            "qibin zhao",
            "heng-chao li",
            "ting-zhu huang"
        ]
    },
    {
        "id": "2306.00003",
        "title": "detecting heart disease from multi-view ultrasound images via supervised   attention multiple instance learning",
        "abstract": "aortic stenosis (as) is a degenerative valve condition that causes substantial morbidity and mortality. this condition is under-diagnosed and under-treated. in clinical practice, as is diagnosed with expert review of transthoracic echocardiography, which produces dozens of ultrasound images of the heart. only some of these views show the aortic valve. to automate screening for as, deep networks must learn to mimic a human expert's ability to identify views of the aortic valve then aggregate across these relevant images to produce a study-level diagnosis. we find previous approaches to as detection yield insufficient accuracy due to relying on inflexible averages across images. we further find that off-the-shelf attention-based multiple instance learning (mil) performs poorly. we contribute a new end-to-end mil approach with two key methodological innovations. first, a supervised attention technique guides the learned attention mechanism to favor relevant views. second, a novel self-supervised pretraining strategy applies contrastive learning on the representation of the whole study instead of individual images as commonly done in prior literature. experiments on an open-access dataset and an external validation set show that our approach yields higher accuracy while reducing model size.",
        "doi": "",
        "created": "2023-05-25",
        "url": "https://arxiv.org/abs/2306.00003",
        "authors": [
            "zhe huang",
            "benjamin s. wessler",
            "michael c. hughes"
        ]
    },
    {
        "id": "2306.04429",
        "title": "balancing of competitive two-player game levels with reinforcement   learning",
        "abstract": "the balancing process for game levels in a competitive two-player context involves a lot of manual work and testing, particularly in non-symmetrical game levels. in this paper, we propose an architecture for automated balancing of tile-based levels within the recently introduced pcgrl framework (procedural content generation via reinforcement learning). our architecture is divided into three parts: (1) a level generator, (2) a balancing agent and, (3) a reward modeling simulation. by playing the level in a simulation repeatedly, the balancing agent is rewarded for modifying it towards the same win rates for all players. to this end, we introduce a novel family of swap-based representations to increase robustness towards playability. we show that this approach is capable to teach an agent how to alter a level for balancing better and faster than plain pcgrl. in addition, by analyzing the agent's swapping behavior, we can draw conclusions about which tile types influence the balancing most. we test and show our results using the neural mmo (nmmo) environment in a competitive two-player setting.",
        "doi": "10.1109/cog57401.2023.10333248",
        "created": "2023-06-07",
        "url": "https://arxiv.org/abs/2306.04429",
        "authors": [
            "florian rupp",
            "manuel eberhardinger",
            "kai eckert"
        ]
    },
    {
        "id": "2306.12722",
        "title": "analysis of divergence-preserving unfitted finite element methods for   the mixed poisson problem",
        "abstract": "in this paper we present a new h(div)-conforming unfitted finite element method for the mixed poisson problem which is robust in the cut configuration and preserves conservation properties of body-fitted finite element methods. the key is to formulate the divergence-constraint on the active mesh, instead of the physical domain, in order to obtain robustness with respect to cut configurations without the need for a stabilization that pollutes the mass balance. this change in the formulation results in a slight inconsistency, but does not affect the accuracy of the flux variable. by applying post-processings for the scalar variable, in virtue of classical local post-processings in body-fitted methods, we retain optimal convergence rates for both variables and even the superconvergence after post-processing of the scalar variable. we present the method and perform a rigorous a-priori error analysis of the method and discuss several variants and extensions. numerical experiments confirm the theoretical results.",
        "doi": "",
        "created": "2023-06-22",
        "url": "https://arxiv.org/abs/2306.12722",
        "authors": [
            "christoph lehrenfeld",
            "tim van beeck",
            "igor voulis"
        ]
    },
    {
        "id": "2306.14055",
        "title": "transforming a quadruped into a guide robot for the visually impaired:   formalizing wayfinding, interaction modeling, and safety mechanism",
        "abstract": "this paper explores the principles for transforming a quadrupedal robot into a guide robot for individuals with visual impairments. a guide robot has great potential to resolve the limited availability of guide animals that are accessible to only two to three percent of the potential blind or visually impaired (bvi) users. to build a successful guide robot, our paper explores three key topics: (1) formalizing the navigation mechanism of a guide dog and a human, (2) developing a data-driven model of their interaction, and (3) improving user safety. first, we formalize the wayfinding task of the human-guide robot team using markov decision processes based on the literature and interviews. then we collect real human-robot interaction data from three visually impaired and six sighted people and develop an interaction model called the ``delayed harness'' to effectively simulate the navigation behaviors of the team. additionally, we introduce an action shielding mechanism to enhance user safety by predicting and filtering out dangerous actions. we evaluate the developed interaction model and the safety mechanism in simulation, which greatly reduce the prediction errors and the number of collisions, respectively. we also demonstrate the integrated system on a quadrupedal robot with a rigid harness, by guiding users over $100+$~m trajectories.",
        "doi": "",
        "created": "2023-06-24",
        "url": "https://arxiv.org/abs/2306.14055",
        "authors": [
            "j. taery kim",
            "wenhao yu",
            "yash kothari",
            "jie tan",
            "greg turk",
            "sehoon ha"
        ]
    },
    {
        "id": "2306.14975",
        "title": "the underlying scaling laws and universal statistical structure of   complex datasets",
        "abstract": "we study universal traits which emerge both in real-world complex datasets, as well as in artificially generated ones. our approach is to analogize data to a physical system and employ tools from statistical physics and random matrix theory (rmt) to reveal their underlying structure. we focus on the feature-feature covariance matrix, analyzing both its local and global eigenvalue statistics. our main observations are: (i) the power-law scalings that the bulk of its eigenvalues exhibit are vastly different for uncorrelated normally distributed data compared to real-world data, (ii) this scaling behavior can be completely modeled by generating gaussian data with long range correlations, (iii) both generated and real-world datasets lie in the same universality class from the rmt perspective, as chaotic rather than integrable systems, (iv) the expected rmt statistical behavior already manifests for empirical covariance matrices at dataset sizes significantly smaller than those conventionally used for real-world training, and can be related to the number of samples required to approximate the population power-law scaling behavior, (v) the shannon entropy is correlated with local rmt structure and eigenvalues scaling, is substantially smaller in strongly correlated datasets compared to uncorrelated ones, and requires fewer samples to reach the distribution entropy. these findings show that with sufficient sample size, the gram matrix of natural image datasets can be well approximated by a wishart random matrix with a simple covariance structure, opening the door to rigorous studies of neural network dynamics and generalization which rely on the data gram matrix.",
        "doi": "",
        "created": "2023-06-26",
        "url": "https://arxiv.org/abs/2306.14975",
        "authors": [
            "noam levi",
            "yaron oz"
        ]
    },
    {
        "id": "2307.00040",
        "title": "disco: disentangled control for realistic human dance generation",
        "abstract": "generative ai has made significant strides in computer vision, particularly in text-driven image/video synthesis (t2i/t2v). despite the notable advancements, it remains challenging in human-centric content synthesis such as realistic dance generation. current methodologies, primarily tailored for human motion transfer, encounter difficulties when confronted with real-world dance scenarios (e.g., social media dance), which require to generalize across a wide spectrum of poses and intricate human details. in this paper, we depart from the traditional paradigm of human motion transfer and emphasize two additional critical attributes for the synthesis of human dance content in social media contexts: (i) generalizability: the model should be able to generalize beyond generic human viewpoints as well as unseen human subjects, backgrounds, and poses; (ii) compositionality: it should allow for the seamless composition of seen/unseen subjects, backgrounds, and poses from different sources. to address these challenges, we introduce disco, which includes a novel model architecture with disentangled control to improve the compositionality of dance synthesis, and an effective human attribute pre-training for better generalizability to unseen humans. extensive qualitative and quantitative results demonstrate that discc can generate high-quality human dance images and videos with diverse appearances and flexible motions. code is available at https://disco-dance.github.io/.",
        "doi": "",
        "created": "2023-06-30",
        "url": "https://arxiv.org/abs/2307.00040",
        "authors": [
            "tan wang",
            "linjie li",
            "kevin lin",
            "yuanhao zhai",
            "chung-ching lin",
            "zhengyuan yang",
            "hanwang zhang",
            "zicheng liu",
            "lijuan wang"
        ]
    },
    {
        "id": "2307.04195",
        "title": "natural language instructions for intuitive human interaction with   robotic assistants in field construction work",
        "abstract": "the introduction of robots is widely considered to have significant potential of alleviating the issues of worker shortage and stagnant productivity that afflict the construction industry. however, it is challenging to use fully automated robots in complex and unstructured construction sites. human-robot collaboration (hrc) has shown promise of combining human workers' flexibility and robot assistants' physical abilities to jointly address the uncertainties inherent in construction work. when introducing hrc in construction, it is critical to recognize the importance of teamwork and supervision in field construction and establish a natural and intuitive communication system for the human workers and robotic assistants. natural language-based interaction can enable intuitive and familiar communication with robots for human workers who are non-experts in robot programming. however, limited research has been conducted on this topic in construction. this paper proposes a framework to allow human workers to interact with construction robots based on natural language instructions. the proposed method consists of three stages: natural language understanding (nlu), information mapping (im), and robot control (rc). natural language instructions are input to a language model to predict a tag for each word in the nlu module. the im module uses the result of the nlu module and building component information to generate the final instructional output essential for a robot to acknowledge and perform the construction task. a case study for drywall installation is conducted to evaluate the proposed approach. the obtained results highlight the potential of using natural language-based interaction to replicate the communication that occurs between human workers within the context of human-robot teams.",
        "doi": "10.1016/j.autcon.2024.105345",
        "created": "2023-07-09",
        "url": "https://arxiv.org/abs/2307.04195",
        "authors": [
            "somin park",
            "xi wang",
            "carol c. menassa",
            "vineet r. kamat",
            "joyce y. chai"
        ]
    },
    {
        "id": "2307.09915",
        "title": "embedded heterogeneous attention transformer for cross-lingual image   captioning",
        "abstract": "cross-lingual image captioning is a challenging task that requires addressing both cross-lingual and cross-modal obstacles in multimedia analysis. the crucial issue in this task is to model the global and the local matching between the image and different languages. existing cross-modal embedding methods based on the transformer architecture oversee the local matching between the image region and monolingual words, especially when dealing with diverse languages. to overcome these limitations, we propose an embedded heterogeneous attention transformer (ehat) to establish cross-domain relationships and local correspondences between images and different languages by using a heterogeneous network. ehat comprises masked heterogeneous cross-attention (mhca), heterogeneous attention reasoning network (harn), and heterogeneous co-attention (hca). the harn serves as the core network and it captures cross-domain relationships by leveraging visual bounding box representation features to connect word features from two languages and to learn heterogeneous maps. mhca and hca facilitate cross-domain integration in the encoder through specialized heterogeneous attention mechanisms, enabling a single model to generate captions in two languages. we evaluate our approach on the mscoco dataset to generate captions in english and chinese, two languages that exhibit significant differences in their language families. the experimental results demonstrate the superior performance of our method compared to existing advanced monolingual methods. our proposed ehat framework effectively addresses the challenges of cross-lingual image captioning, paving the way for improved multilingual image analysis and understanding.",
        "doi": "10.1109/tmm.2024.3384678",
        "created": "2023-07-19",
        "url": "https://arxiv.org/abs/2307.09915",
        "authors": [
            "zijie song",
            "zhenzhen hu",
            "yuanen zhou",
            "ye zhao",
            "richang hong",
            "meng wang"
        ]
    },
    {
        "id": "2307.10560",
        "title": "post-variational quantum neural networks",
        "abstract": "hybrid quantum-classical computing in the noisy intermediate-scale quantum (nisq) era with variational algorithms can exhibit barren plateau issues, causing difficult convergence of gradient-based optimization techniques. in this paper, we discuss \"post-variational strategies\", which shift tunable parameters from the quantum computer to the classical computer, opting for ensemble strategies when optimizing quantum models. we discuss various strategies and design principles for constructing individual quantum circuits, where the resulting ensembles can be optimized with convex programming. further, we discuss architectural designs of post-variational quantum neural networks and analyze the propagation of estimation errors throughout such neural networks. finally, we show that empirically, post-variational quantum neural networks using our architectural designs can potentially provide better results than variational algorithms and performance comparable to that of two-layer neural networks.",
        "doi": "",
        "created": "2023-07-19",
        "url": "https://arxiv.org/abs/2307.10560",
        "authors": [
            "po-wei huang",
            "patrick rebentrost"
        ]
    },
    {
        "id": "2307.14437",
        "title": "a grid-overlay finite difference method for the fractional laplacian on   arbitrary bounded domains",
        "abstract": "a grid-overlay finite difference method is proposed for the numerical approximation of the fractional laplacian on arbitrary bounded domains. the method uses an unstructured simplicial mesh and an overlay uniform grid for the underlying domain and constructs the approximation based on a uniform-grid finite difference approximation and a data transfer from the unstructured mesh to the uniform grid. the method takes full advantages of both uniform-grid finite difference approximation in efficient matrix-vector multiplication via the fast fourier transform and unstructured meshes for complex geometries and mesh adaptation. it is shown that its stiffness matrix is similar to a symmetric and positive definite matrix and thus invertible if the data transfer has full column rank and positive column sums. piecewise linear interpolation is studied as a special example for the data transfer. it is proved that the full column rank and positive column sums of linear interpolation is guaranteed if the spacing of the uniform grid is smaller than or equal to a positive bound proportional to the minimum element height of the unstructured mesh. moreover, a sparse preconditioner is proposed for the iterative solution of the resulting linear system for the homogeneous dirichlet problem of the fractional laplacian. numerical examples demonstrate that the new method has similar convergence behavior as existing finite difference and finite element methods and that the sparse preconditioning is effective. furthermore, the new method can readily be incorporated with existing mesh adaptation strategies. numerical results obtained by combining with the so-called mmpde moving mesh method are also presented.",
        "doi": "10.1137/23m1558562",
        "created": "2023-07-26",
        "url": "https://arxiv.org/abs/2307.14437",
        "authors": [
            "weizhang huang",
            "jinye shen"
        ]
    },
    {
        "id": "2308.04613",
        "title": "shallow encounters' impact on asteroid deflection prediction and   implications on trajectory design",
        "abstract": "analytical approximations are commonly employed in the initial trajectory design phase of a mission to rapidly explore a broad design space. in the context of an asteroid deflection mission, accurately predicting deflection is crucial to determining the spacecraft's trajectory that will produce the desired outcome. however, the dynamics involved are intricate, and simplistic models may not fully capture the system's complexity. this study assesses the precision and limitations of analytical models in predicting deflection, comparing them to more accurate numerical simulations. the findings reveal that encounters with perturbing bodies, even at significant distances (a dozen times the radii of the sphere of influence of the perturbing planet), can markedly disturb the deflected asteroid's trajectory, resulting in notable disparities between analytical and numerical predictions. the underlying reasons for this phenomenon are explained, and provisional general guidelines are provided to assist mission analysts in addressing such occurrences. by comprehending the impact of shallow encounters on deflection, this study equips designers with the knowledge to make informed decisions throughout the trajectory planning process, enhancing the efficiency and effectiveness of asteroid deflection missions.",
        "doi": "10.2514/1.g007890",
        "created": "2023-08-08",
        "url": "https://arxiv.org/abs/2308.04613",
        "authors": [
            "rodolfo batista negri",
            "ant\u00f4nio fernando bertachini de almeida prado"
        ]
    },
    {
        "id": "2308.04853",
        "title": "aggregated demand flexibility prediction of residential thermostatically   controlled loads and participation in electricity balance markets",
        "abstract": "the aggregate demand flexibility of a set of thermostatically controlled residential loads (tcls) can be represented by a virtual battery (vb) in order to manage their participation in the electricity markets. for this purpose, it is necessary to know in advance and with a high level of reliability the maximum power that can be supplied by the aggregation of tcls. a probability function of the power that can be supplied by a vb is introduced. this probability function is used to predict the demand flexibility using a new experimental probabilistic method based on a combination of monte carlo simulation and extremum search by bisection algorithm (mc&esb). as a result, the maximum flexibility power that a vb can provide with a certain guaranteed probability is obtained. the performance and validity of the proposed method are demonstrated in three different case studies where a vb bids its aggregate power in the spanish electricity balancing markets (sebm).",
        "doi": "",
        "created": "2023-08-09",
        "url": "https://arxiv.org/abs/2308.04853",
        "authors": [
            "alejandro mart\u00edn-crespo",
            "enrique baeyens",
            "sergio saludes-rodil",
            "fernando frechoso-escudero"
        ]
    },
    {
        "id": "2308.04868",
        "title": "instantavatar: efficient 3d head reconstruction via surface rendering",
        "abstract": "recent advances in full-head reconstruction have been obtained by optimizing a neural field through differentiable surface or volume rendering to represent a single scene. while these techniques achieve an unprecedented accuracy, they take several minutes, or even hours, due to the expensive optimization process required. in this work, we introduce instantavatar, a method that recovers full-head avatars from few images (down to just one) in a few seconds on commodity hardware. in order to speed up the reconstruction process, we propose a system that combines, for the first time, a voxel-grid neural field representation with a surface renderer. notably, a naive combination of these two techniques leads to unstable optimizations that do not converge to valid solutions. in order to overcome this limitation, we present a novel statistical model that learns a prior distribution over 3d head signed distance functions using a voxel-grid based architecture. the use of this prior model, in combination with other design choices, results into a system that achieves 3d head reconstructions with comparable accuracy as the state-of-the-art with a 100x speed-up.",
        "doi": "",
        "created": "2023-08-09",
        "url": "https://arxiv.org/abs/2308.04868",
        "authors": [
            "antonio canela",
            "pol caselles",
            "ibrar malik",
            "eduard ramon",
            "jaime garc\u00eda",
            "jordi s\u00e1nchez-riera",
            "gil triginer",
            "francesc moreno-noguer"
        ]
    },
    {
        "id": "2308.05194",
        "title": "evaluating pedestrian trajectory prediction methods with respect to   autonomous driving",
        "abstract": "in this paper, we assess the state of the art in pedestrian trajectory prediction within the context of generating single trajectories, a critical aspect aligning with the requirements in autonomous systems. the evaluation is conducted on the widely-used eth/ucy dataset where the average displacement error (ade) and the final displacement error (fde) are reported. alongside this, we perform an ablation study to investigate the impact of the observed motion history on prediction performance. to evaluate the scalability of each approach when confronted with varying amounts of agents, the inference time of each model is measured. following a quantitative analysis, the resulting predictions are compared in a qualitative manner, giving insight into the strengths and weaknesses of current approaches. the results demonstrate that although a constant velocity model (cvm) provides a good approximation of the overall dynamics in the majority of cases, additional features need to be incorporated to reflect common pedestrian behavior observed. therefore, this study presents a data-driven analysis with the intent to guide the future development of pedestrian trajectory prediction algorithms.",
        "doi": "10.1109/tits.2024.3386195",
        "created": "2023-08-09",
        "url": "https://arxiv.org/abs/2308.05194",
        "authors": [
            "nico uhlemann",
            "felix fent",
            "markus lienkamp"
        ]
    },
    {
        "id": "2308.07061",
        "title": "machine unlearning: solutions and challenges",
        "abstract": "machine learning models may inadvertently memorize sensitive, unauthorized, or malicious data, posing risks of privacy breaches, security vulnerabilities, and performance degradation. to address these issues, machine unlearning has emerged as a critical technique to selectively remove specific training data points' influence on trained models. this paper provides a comprehensive taxonomy and analysis of the solutions in machine unlearning. we categorize existing solutions into exact unlearning approaches that remove data influence thoroughly and approximate unlearning approaches that efficiently minimize data influence. by comprehensively reviewing solutions, we identify and discuss their strengths and limitations. furthermore, we propose future directions to advance machine unlearning and establish it as an essential capability for trustworthy and adaptive machine learning models. this paper provides researchers with a roadmap of open problems, encouraging impactful contributions to address real-world needs for selective data removal.",
        "doi": "10.1109/tetci.2024.3379240",
        "created": "2023-08-14",
        "url": "https://arxiv.org/abs/2308.07061",
        "authors": [
            "jie xu",
            "zihan wu",
            "cong wang",
            "xiaohua jia"
        ]
    },
    {
        "id": "2308.07175",
        "title": "efficient learning of quantum states prepared with few non-clifford   gates ii: single-copy measurements",
        "abstract": "recent work has shown that $n$-qubit quantum states output by circuits with at most $t$ single-qubit non-clifford gates can be learned to trace distance $\\epsilon$ using $\\mathsf{poly}(n,2^t,1/\\epsilon)$ time and samples. all prior algorithms achieving this runtime use entangled measurements across two copies of the input state. in this work, we give a similarly efficient algorithm that learns the same class of states using only single-copy measurements.",
        "doi": "",
        "created": "2023-08-14",
        "url": "https://arxiv.org/abs/2308.07175",
        "authors": [
            "sabee grewal",
            "vishnu iyer",
            "william kretschmer",
            "daniel liang"
        ]
    },
    {
        "id": "2308.10783",
        "title": "zero- and few-shot prompting with llms: a comparative study with   fine-tuned models for bangla sentiment analysis",
        "abstract": "the rapid expansion of the digital world has propelled sentiment analysis into a critical tool across diverse sectors such as marketing, politics, customer service, and healthcare. while there have been significant advancements in sentiment analysis for widely spoken languages, low-resource languages, such as bangla, remain largely under-researched due to resource constraints. furthermore, the recent unprecedented performance of large language models (llms) in various applications highlights the need to evaluate them in the context of low-resource languages. in this study, we present a sizeable manually annotated dataset encompassing 33,606 bangla news tweets and facebook comments. we also investigate zero- and few-shot in-context learning with several language models, including flan-t5, gpt-4, and bloomz, offering a comparative analysis against fine-tuned models. our findings suggest that monolingual transformer-based models consistently outperform other models, even in zero and few-shot scenarios. to foster continued exploration, we intend to make this dataset and our research tools publicly available to the broader research community.",
        "doi": "",
        "created": "2023-08-21",
        "url": "https://arxiv.org/abs/2308.10783",
        "authors": [
            "md. arid hasan",
            "shudipta das",
            "afiyat anjum",
            "firoj alam",
            "anika anjum",
            "avijit sarker",
            "sheak rashed haider noori"
        ]
    },
    {
        "id": "2308.11066",
        "title": "csm-h-r: a context modeling framework in supporting reasoning automation   for interoperable intelligent systems and privacy protection",
        "abstract": "the automation of high-level context (hlc) reasoning across intelligent systems at scale is imperative because of the unceasing accumulation of contextual data, the trend of the fusion of data from multiple sources (e.g., sensors, intelligent systems), and the intrinsic complexity and dynamism of context-based decision-making processes. to mitigate the challenges posed by these issues, we propose a novel hierarchical ontology-state modeling (hosm) framework csm-h-r, which programmatically combines ontologies and states at the modeling phase and runtime phase for attaining the ability to recognize meaningful hlc. it builds on the model of our prior work on the context state machine (csm) engine by incorporating the h (hierarchy) and r (relationship and transition) dimensions to take care of the dynamic aspects of context. the design of the framework supports the sharing and interoperation of context among intelligent systems and the components for handling csms and the management of hierarchy, relationship, and transition. case studies are developed for intellelevator and intellrestaurant, two intelligent applications in a smart campus setting. the prototype implementation of the framework experiments on translating the hlc reasoning into vector and matrix computing and presents the potential of using advanced probabilistic models to reach the next level of automation in integrating intelligent systems; meanwhile, privacy protection support is achieved in the application domain by anonymization through indexing and reducing information correlation. an implementation of the framework is available at https://github.com/songhui01/csm-h-r.",
        "doi": "",
        "created": "2023-08-21",
        "url": "https://arxiv.org/abs/2308.11066",
        "authors": [
            "songhui yue",
            "xiaoyan hong",
            "randy k. smith"
        ]
    },
    {
        "id": "2309.03138",
        "title": "fmplex: exploring a bridge between fourier-motzkin and simplex",
        "abstract": "in this paper we present a quantifier elimination method for conjunctions of linear real arithmetic constraints. our algorithm is based on the fourier-motzkin variable elimination procedure, but by case splitting we are able to reduce the worst-case complexity from doubly to singly exponential. the adaption of the procedure for smt solving has strong correspondence to the simplex algorithm, therefore we name it fmplex. besides the theoretical foundations, we provide an experimental evaluation in the context of smt solving. this is an extended version of the authors' work previously published at the fourteenth international symposium on games, automata, logics, and formal verification (gandalf 2023).",
        "doi": "",
        "created": "2023-09-06",
        "url": "https://arxiv.org/abs/2309.03138",
        "authors": [
            "jasper nalbach",
            "valentin promies",
            "erika \u00e1brah\u00e1m",
            "paul kobialka"
        ]
    },
    {
        "id": "2309.03842",
        "title": "early warning indicators via latent stochastic dynamical systems",
        "abstract": "detecting early warning indicators for abrupt dynamical transitions in complex systems or high-dimensional observation data is essential in many real-world applications, such as brain diseases, natural disasters, and engineering reliability. to this end, we develop a novel approach: the directed anisotropic diffusion map that captures the latent evolutionary dynamics in the low-dimensional manifold. then three effective warning signals (onsager-machlup indicator, sample entropy indicator, and transition probability indicator) are derived through the latent coordinates and the latent stochastic dynamical systems. to validate our framework, we apply this methodology to authentic electroencephalogram (eeg) data. we find that our early warning indicators are capable of detecting the tipping point during state transition. this framework not only bridges the latent dynamics with real-world data but also shows the potential ability for automatic labeling on complex high-dimensional time series.",
        "doi": "10.1063/5.0195042",
        "created": "2023-09-07",
        "url": "https://arxiv.org/abs/2309.03842",
        "authors": [
            "lingyu feng",
            "ting gao",
            "wang xiao",
            "jinqiao duan"
        ]
    },
    {
        "id": "2309.05871",
        "title": "generalized rainbow differential privacy",
        "abstract": "we study a new framework for designing differentially private (dp) mechanisms via randomized graph colorings, called rainbow differential privacy. in this framework, datasets are nodes in a graph, and two neighboring datasets are connected by an edge. each dataset in the graph has a preferential ordering for the possible outputs of the mechanism, and these orderings are called rainbows. different rainbows partition the graph of connected datasets into different regions. we show that if a dp mechanism at the boundary of such regions is fixed and it behaves identically for all same-rainbow boundary datasets, then a unique optimal $(\\epsilon,\\delta)$-dp mechanism exists (as long as the boundary condition is valid) and can be expressed in closed-form. our proof technique is based on an interesting relationship between dominance ordering and dp, which applies to any finite number of colors and for $(\\epsilon,\\delta)$-dp, improving upon previous results that only apply to at most three colors and for $\\epsilon$-dp. we justify the homogeneous boundary condition assumption by giving an example with non-homogeneous boundary condition, for which there exists no optimal dp mechanism.",
        "doi": "",
        "created": "2023-09-11",
        "url": "https://arxiv.org/abs/2309.05871",
        "authors": [
            "yuzhou gu",
            "ziqi zhou",
            "onur g\u00fcnl\u00fc",
            "rafael g. l. d'oliveira",
            "parastoo sadeghi",
            "muriel m\u00e9dard",
            "rafael f. schaefer"
        ]
    },
    {
        "id": "2309.06629",
        "title": "the relational bottleneck as an inductive bias for efficient abstraction",
        "abstract": "a central challenge for cognitive science is to explain how abstract concepts are acquired from limited experience. this has often been framed in terms of a dichotomy between connectionist and symbolic cognitive models. here, we highlight a recently emerging line of work that suggests a novel reconciliation of these approaches, by exploiting an inductive bias that we term the relational bottleneck. in that approach, neural networks are constrained via their architecture to focus on relations between perceptual inputs, rather than the attributes of individual inputs. we review a family of models that employ this approach to induce abstractions in a data-efficient manner, emphasizing their potential as candidate models for the acquisition of abstract concepts in the human mind and brain.",
        "doi": "",
        "created": "2023-09-12",
        "url": "https://arxiv.org/abs/2309.06629",
        "authors": [
            "taylor w. webb",
            "steven m. frankland",
            "awni altabaa",
            "simon segert",
            "kamesh krishnamurthy",
            "declan campbell",
            "jacob russin",
            "tyler giallanza",
            "zack dulberg",
            "randall o'reilly",
            "john lafferty",
            "jonathan d. cohen"
        ]
    },
    {
        "id": "2309.06862",
        "title": "domain decomposition method for poisson--boltzmann equations based on   solvent excluded surface",
        "abstract": "in this paper, we develop a domain decomposition method for the nonlinear poisson-boltzmann equation based on a solvent-excluded surface widely used in computational chemistry. the model relies on a nonlinear equation defined in $\\mathbb{r}^3$ with a space-dependent dielectric permittivity and an ion-exclusion function that accounts for steric effects. potential theory arguments transform the nonlinear equation into two coupled equations defined in a bounded domain. then, the schwarz decomposition method is used to formulate local problems by decomposing the cavity into overlapping balls and only solving a set of coupled sub-equations in each ball. the main novelty of the proposed method is the introduction of a hybrid linear-nonlinear solver used to solve the equation. a series of numerical experiments are presented to test the method and show the importance of the nonlinear model.",
        "doi": "",
        "created": "2023-09-13",
        "url": "https://arxiv.org/abs/2309.06862",
        "authors": [
            "abhinav jha",
            "benjamin stamm"
        ]
    },
    {
        "id": "2309.07759",
        "title": "prograsp: pragmatic human-robot communication for object grasping",
        "abstract": "interactive object grasping (iog) is the task of identifying and grasping the desired object via human-robot natural language interaction. current iog systems assume that a human user initially specifies the target object's category (e.g., bottle). inspired by pragmatics, where humans often convey their intentions by relying on context to achieve goals, we introduce a new iog task, pragmatic-iog, and the corresponding dataset, intention-oriented multi-modal dialogue (im-dial). in our proposed task scenario, an intention-oriented utterance (e.g., \"i am thirsty\") is initially given to the robot. the robot should then identify the target object by interacting with a human user. based on the task setup, we propose a new robotic system that can interpret the user's intention and pick up the target object, pragmatic object grasping (prograsp). prograsp performs pragmatic-iog by incorporating modules for visual grounding, question asking, object grasping, and most importantly, answer interpretation for pragmatic inference. experimental results show that prograsp is effective in offline (i.e., target object discovery) and online (i.e., iog with a physical robot arm) settings. code and data are available at https://github.com/gicheonkang/prograsp.",
        "doi": "",
        "created": "2023-09-14",
        "url": "https://arxiv.org/abs/2309.07759",
        "authors": [
            "gi-cheon kang",
            "junghyun kim",
            "jaein kim",
            "byoung-tak zhang"
        ]
    },
    {
        "id": "2309.08395",
        "title": "learning by self-explaining",
        "abstract": "current ai research mainly treats explanations as a means for model inspection. yet, this neglects findings from human psychology that describe the benefit of self-explanations in an agent's learning process. motivated by this, we introduce a novel approach in the context of image classification, termed learning by self-explaining (lsx). lsx utilizes aspects of self-refining ai and human-guided explanatory machine learning. the underlying idea is that a learner model, in addition to optimizing for the original predictive task, is further optimized based on explanatory feedback from an internal critic model. intuitively, a learner's explanations are considered \"useful\" if the internal critic can perform the same task given these explanations. we provide an overview of important components of lsx and, based on this, perform extensive experimental evaluations via three different example instantiations. our results indicate improvements via learning by self-explaining on several levels: in terms of model generalization, reducing the influence of confounding factors, and providing more task-relevant and faithful model explanations. overall, our work provides evidence for the potential of self-explaining within the learning phase of an ai model.",
        "doi": "",
        "created": "2023-09-15",
        "url": "https://arxiv.org/abs/2309.08395",
        "authors": [
            "wolfgang stammer",
            "felix friedrich",
            "david steinmann",
            "manuel brack",
            "hikaru shindo",
            "kristian kersting"
        ]
    },
    {
        "id": "2309.08963",
        "title": "struc-bench: are large language models really good at generating complex   structured data?",
        "abstract": "despite the remarkable capabilities of large language models (llms) like gpt-4, producing complex, structured tabular data remains challenging. our study assesses llms' proficiency in structuring tables and introduces a novel fine-tuning method, cognizant of data structures, to bolster their performance. we unveil struc-bench, a comprehensive benchmark featuring prominent llms (gpt-neox-20b, gpt-3.5, gpt-4, and vicuna), which spans text tables, html, and latex formats. our proposed formatcot aids in crafting format-specific instructions from the intended outputs to populate this benchmark. addressing the gap in task-centered evaluation, we propose two innovative metrics, p-score (prompting score) and h-score (heuristical score), to more accurately gauge llm performance. our experiments show that applying our structure-aware fine-tuning to llama-7b leads to substantial performance gains, outshining its llm counterparts across most measures. in-depth error analysis and creating an ability map across six dimensions -- coverage, formatting, reasoning, comprehension, pragmatics, and hallucination -- highlight areas for future enhancements and suggest forthcoming research trajectories. our code and models can be found at https://github.com/gersteinlab/struc-bench.",
        "doi": "",
        "created": "2023-09-16",
        "url": "https://arxiv.org/abs/2309.08963",
        "authors": [
            "xiangru tang",
            "yiming zong",
            "jason phang",
            "yilun zhao",
            "wangchunshu zhou",
            "arman cohan",
            "mark gerstein"
        ]
    },
    {
        "id": "2309.12288",
        "title": "the reversal curse: llms trained on \"a is b\" fail to learn \"b is a\"",
        "abstract": "we expose a surprising failure of generalization in auto-regressive large language models (llms). if a model is trained on a sentence of the form \"a is b\", it will not automatically generalize to the reverse direction \"b is a\". this is the reversal curse. for instance, if a model is trained on \"valentina tereshkova was the first woman to travel to space\", it will not automatically be able to answer the question, \"who was the first woman to travel to space?\". moreover, the likelihood of the correct answer (\"valentina tershkova\") will not be higher than for a random name. thus, models do not generalize a prevalent pattern in their training set: if \"a is b\" occurs, \"b is a\" is more likely to occur. it is worth noting, however, that if \"a is b\" appears in-context, models can deduce the reverse relationship. we provide evidence for the reversal curse by finetuning gpt-3 and llama-1 on fictitious statements such as \"uriah hawthorne is the composer of abyssal melodies\" and showing that they fail to correctly answer \"who composed abyssal melodies?\". the reversal curse is robust across model sizes and model families and is not alleviated by data augmentation. we also evaluate chatgpt (gpt-3.5 and gpt-4) on questions about real-world celebrities, such as \"who is tom cruise's mother? [a: mary lee pfeiffer]\" and the reverse \"who is mary lee pfeiffer's son?\". gpt-4 correctly answers questions like the former 79% of the time, compared to 33% for the latter.   code available at: https://github.com/lukasberglund/reversal_curse.",
        "doi": "",
        "created": "2023-09-21",
        "url": "https://arxiv.org/abs/2309.12288",
        "authors": [
            "lukas berglund",
            "meg tong",
            "max kaufmann",
            "mikita balesni",
            "asa cooper stickland",
            "tomasz korbak",
            "owain evans"
        ]
    },
    {
        "id": "2309.15685",
        "title": "improving autonomous driving safety with pop: a framework for accurate   partially observed trajectory predictions",
        "abstract": "accurate trajectory prediction is crucial for safe and efficient autonomous driving, but handling partial observations presents significant challenges. to address this, we propose a novel trajectory prediction framework called partial observations prediction (pop) for congested urban road scenarios. the framework consists of two key stages: self-supervised learning (ssl) and feature distillation. pop first employs sll to help the model learn to reconstruct history representations, and then utilizes feature distillation as the fine-tuning task to transfer knowledge from the teacher model, which has been pre-trained with complete observations, to the student model, which has only few observations. pop achieves comparable results to top-performing methods in open-loop experiments and outperforms the baseline method in closed-loop simulations, including safety metrics. qualitative results illustrate the superiority of pop in providing reasonable and safe trajectory predictions.",
        "doi": "",
        "created": "2023-09-27",
        "url": "https://arxiv.org/abs/2309.15685",
        "authors": [
            "sheng wang",
            "yingbing chen",
            "jie cheng",
            "xiaodong mei",
            "ren xin",
            "yongkang song",
            "ming liu"
        ]
    },
    {
        "id": "2309.17157",
        "title": "latticegen: a cooperative framework which hides generated text in a   lattice for privacy-aware generation on cloud",
        "abstract": "in the current user-server interaction paradigm of prompted generation with large language models (llm) on cloud, the server fully controls the generation process, which leaves zero options for users who want to keep the generated text to themselves. we propose latticegen, a cooperative framework in which the server still handles most of the computation while the user controls the sampling operation. the key idea is that the true generated sequence is mixed with noise tokens by the user and hidden in a noised lattice. considering potential attacks from a hypothetically malicious server and how the user can defend against it, we propose the repeated beam-search attack and the mixing noise scheme. in our experiments we apply latticegen to protect both prompt and generation. it is shown that while the noised lattice degrades generation quality, latticegen successfully protects the true generation to a remarkable degree under strong attacks (more than 50% of the semantic remains hidden as measured by bertscore).",
        "doi": "",
        "created": "2023-09-29",
        "url": "https://arxiv.org/abs/2309.17157",
        "authors": [
            "mengke zhang",
            "tianxing he",
            "tianle wang",
            "lu mi",
            "fatemehsadat mireshghallah",
            "binyi chen",
            "hao wang",
            "yulia tsvetkov"
        ]
    },
    {
        "id": "2310.01566",
        "title": "how do software engineering researchers use github? an empirical study   of artifacts & impact",
        "abstract": "millions of developers share their code on open-source platforms like github, which offer social coding opportunities such as distributed collaboration and popularity-based ranking. software engineering researchers have joined in as well, hosting their research artifacts (tools, replication package & datasets) in repositories, an action often marked as part of the publications contribution. yet a decade after the first such paper-with-github-link, little is known about the fate of such repositories in practice. do research repositories ever gain the interest of the developer community, or other researchers? if so, how often and why (not)? does effort invested on github pay off with research impact? in short: we ask whether and how authors engage in social coding related to their research. we conduct a broad empirical investigation of repositories from published work, starting with ten thousand papers in top se research venues, hand-annotating their 3449 github (and zenodo) links, and studying 309 paper-related repositories in detail. we find a wide distribution in popularity and impact, some strongly correlated with publication venue. these were often heavily informed by the authors investment in terms of timely responsiveness and upkeep, which was often remarkably subpar by githubs standards, if not absent altogether. yet we also offer hope: popular repositories often go hand-in-hand with well-citepd papers and achieve broad impact. our findings suggest the need to rethink the research incentives and reward structure around research products requiring such sustained contributions.",
        "doi": "",
        "created": "2023-10-02",
        "url": "https://arxiv.org/abs/2310.01566",
        "authors": [
            "kamel alrashedy",
            "ahmed binjahlan"
        ]
    },
    {
        "id": "2310.05041",
        "title": "an anomaly behavior analysis framework for securing autonomous vehicle   perception",
        "abstract": "as a rapidly growing cyber-physical platform, autonomous vehicles (avs) are encountering more security challenges as their capabilities continue to expand. in recent years, adversaries are actively targeting the perception sensors of autonomous vehicles with sophisticated attacks that are not easily detected by the vehicles' control systems. this work proposes an anomaly behavior analysis approach to detect a perception sensor attack against an autonomous vehicle. the framework relies on temporal features extracted from a physics-based autonomous vehicle behavior model to capture the normal behavior of vehicular perception in autonomous driving. by employing a combination of model-based techniques and machine learning algorithms, the proposed framework distinguishes between normal and abnormal vehicular perception behavior. to demonstrate the application of the framework in practice, we performed a depth camera attack experiment on an autonomous vehicle testbed and generated an extensive dataset. we validated the effectiveness of the proposed framework using this real-world data and released the dataset for public access. to our knowledge, this dataset is the first of its kind and will serve as a valuable resource for the research community in evaluating their intrusion detection techniques effectively.",
        "doi": "",
        "created": "2023-10-08",
        "url": "https://arxiv.org/abs/2310.05041",
        "authors": [
            "murad mehrab abrar",
            "salim hariri"
        ]
    },
    {
        "id": "2310.05452",
        "title": "parrot mind: towards explaining the complex task reasoning of pretrained   large language models with template-content structure",
        "abstract": "the pre-trained large language models (llms) have shown their extraordinary capacity to solve reasoning tasks, even on tasks that require a complex process involving multiple sub-steps. however, given the vast possible generation space of all the tasks, how the pretrained model learns the reasoning ability remains an open question. we firstly propose that an intrinsic structural constraint on the generated sequence of language-based reasoning -- we called it template-content structure (t-c structure) -- is the key to explain why llms can solve a large number of complex reasoning problems with limited training data by showing this structure can reduce the possible space from exponential level to linear level. furthermore, by generalizing this structure to the hierarchical case, we demonstrate that models can achieve task composition, further reducing the space needed to learn from linear to logarithmic, thereby effectively learning on complex reasoning involving multiple steps. we provide both examples and formal theory of our t-c structure. we also experimentally validate the existence of the t-c structure in some current llms and its effectiveness for reasoning.",
        "doi": "",
        "created": "2023-10-09",
        "url": "https://arxiv.org/abs/2310.05452",
        "authors": [
            "haotong yang",
            "fanxu meng",
            "zhouchen lin",
            "muhan zhang"
        ]
    },
    {
        "id": "2310.08517",
        "title": "a linear proof language for second-order intuitionistic linear logic",
        "abstract": "we present a polymorphic linear lambda-calculus as a proof language for second-order intuitionistic linear logic. the calculus includes addition and scalar multiplication, enabling the proof of a linearity result at the syntactic level.",
        "doi": "",
        "created": "2023-10-12",
        "url": "https://arxiv.org/abs/2310.08517",
        "authors": [
            "alejandro d\u00edaz-caro",
            "gilles dowek",
            "malena ivnisky",
            "octavio malherbe"
        ]
    },
    {
        "id": "2310.12729",
        "title": "advancements in radar odometry",
        "abstract": "radar odometry estimation has emerged as a critical technique in the field of autonomous navigation, providing robust and reliable motion estimation under various environmental conditions. despite its potential, the complex nature of radar signals and the inherent challenges associated with processing these signals have limited the widespread adoption of this technology. this paper aims to address these challenges by proposing novel improvements to an existing method for radar odometry estimation, designed to enhance accuracy and reliability in diverse scenarios. our pipeline consists of filtering, motion compensation, oriented surface points computation, smoothing, one-to-many radar scan registration, and pose refinement. the developed method enforces local understanding of the scene, by adding additional information through smoothing techniques, and alignment of consecutive scans, as a refinement posterior to the one-to-many registration. we present an in-depth investigation of the contribution of each improvement to the localization accuracy, and we benchmark our system on the sequences of the main datasets for radar understanding, i.e., the oxford radar robotcar, mulran, and boreas datasets. the proposed pipeline is able to achieve superior results, on all scenarios considered and under harsh environmental constraints.",
        "doi": "",
        "created": "2023-10-19",
        "url": "https://arxiv.org/abs/2310.12729",
        "authors": [
            "matteo frosi",
            "mirko usuelli",
            "matteo matteucci"
        ]
    },
    {
        "id": "2310.17170",
        "title": "mo-yolo: end-to-end multiple-object tracking method with yolo and   decoder",
        "abstract": "in the field of multi-object tracking (mot), recent transformer based end-to-end models like motr have demonstrated exceptional performance on datasets such as dancetracker. however, the computational demands of these models present challenges in training and deployment. drawing inspiration from successful models like gpt, we present mo-yolo, an efficient and computationally frugal end-to-end mot model. mo-yolo integrates principles from you only look once (yolo) and rt-detr, adopting a decoder-only approach. by leveraging the decoder from rt-detr and architectural components from yolov8, mo-yolo achieves high speed, shorter training times, and proficient mot performance. on the dancetrack, mo-yolo not only matches motr's performance but also surpasses it, achieving over twice the frames per second (motr 9.5 fps, mo-yolo 19.6 fps). furthermore, mo-yolo demonstrates significantly reduced training times and lower hardware requirements compared to motr. this research introduces a promising paradigm for efficient end-to-end mot, emphasizing enhanced performance and resource efficiency.",
        "doi": "",
        "created": "2023-10-26",
        "url": "https://arxiv.org/abs/2310.17170",
        "authors": [
            "liao pan",
            "yang feng",
            "wu di",
            "liu bo",
            "zhang xingle"
        ]
    },
    {
        "id": "2310.17496",
        "title": "tackling interference induced by data training loops in a/b tests: a   weighted training approach",
        "abstract": "in modern recommendation systems, the standard pipeline involves training machine learning models on historical data to predict user behaviors and improve recommendations continuously. however, these data training loops can introduce interference in a/b tests, where data generated by control and treatment algorithms, potentially with different distributions, are combined. to address these challenges, we introduce a novel approach called weighted training. this approach entails training a model to predict the probability of each data point appearing in either the treatment or control data and subsequently applying weighted losses during model training. we demonstrate that this approach achieves the least variance among all estimators that do not cause shifts in the training distributions. through simulation studies, we demonstrate the lower bias and variance of our approach compared to other methods.",
        "doi": "",
        "created": "2023-10-26",
        "url": "https://arxiv.org/abs/2310.17496",
        "authors": [
            "nian si"
        ]
    },
    {
        "id": "2310.18079",
        "title": "supporting better insights of data science pipelines with fine-grained   provenance",
        "abstract": "successful data-driven science requires complex data engineering pipelines to clean, transform, and alter data in preparation for machine learning, and robust results can only be achieved when each step in the pipeline can be justified, and its effect on the data explained. in this framework, our aim is to provide data scientists with facilities to gain an in-depth understanding of how each step in the pipeline affects the data, from the raw input to training sets ready to be used for learning. starting from an extensible set of data preparation operators commonly used within a data science setting, in this work we present a provenance management infrastructure for generating, storing, and querying very granular accounts of data transformations, at the level of individual elements within datasets whenever possible. then, from the formal definition of a core set of data science preprocessing operators, we derive a provenance semantics embodied by a collection of templates expressed in prov, a standard model for data provenance. using those templates as a reference, our provenance generation algorithm generalises to any operator with observable input/output pairs. we provide a prototype implementation of an application-level provenance capture library to produce, in a semi-automatic way, complete provenance documents that account for the entire pipeline. we report on the ability of our implementations to capture provenance in real ml benchmark pipelines and over tcp-di synthetic data. we finally show how the collected provenance can be used to answer a suite of provenance benchmark queries that underpin some common pipeline inspection questions, as expressed on the data science stack exchange.",
        "doi": "10.1145/3644385",
        "created": "2023-10-27",
        "url": "https://arxiv.org/abs/2310.18079",
        "authors": [
            "adriane chapman",
            "luca lauro",
            "paolo missier",
            "riccardo torlone"
        ]
    },
    {
        "id": "2310.18912",
        "title": "sentence bag graph formulation for biomedical distant supervision   relation extraction",
        "abstract": "we introduce a novel graph-based framework for alleviating key challenges in distantly-supervised relation extraction and demonstrate its effectiveness in the challenging and important domain of biomedical data. specifically, we propose a graph view of sentence bags referring to an entity pair, which enables message-passing based aggregation of information related to the entity pair over the sentence bag. the proposed framework alleviates the common problem of noisy labeling in distantly supervised relation extraction and also effectively incorporates inter-dependencies between sentences within a bag. extensive experiments on two large-scale biomedical relation datasets and the widely utilized nyt dataset demonstrate that our proposed framework significantly outperforms the state-of-the-art methods for biomedical distant supervision relation extraction while also providing excellent performance for relation extraction in the general text mining domain.",
        "doi": "10.1109/tkde.2024.3377229",
        "created": "2023-10-29",
        "url": "https://arxiv.org/abs/2310.18912",
        "authors": [
            "hao zhang",
            "yang liu",
            "xiaoyan liu",
            "tianming liang",
            "gaurav sharma",
            "liang xue",
            "maozu guo"
        ]
    },
    {
        "id": "2310.19083",
        "title": "backward reachability analysis of perturbed continuous-time linear   systems using set propagation",
        "abstract": "backward reachability analysis computes the set of states that reach a target set under the competing influence of control input and disturbances. depending on their interplay, the backward reachable set either represents all states that can be steered into the target set or all states that cannot avoid entering it -- the corresponding solutions can be used for controller synthesis and safety verification, respectively. a popular technique for backward reachable set computation solves hamilton-jacobi-isaacs equations, which scales exponentially with the state dimension due to gridding the state space. in this work, we instead use set propagation techniques to design backward reachability algorithms for linear time-invariant systems. crucially, the proposed algorithms scale only polynomially with the state dimension. our numerical examples demonstrate the tightness of the obtained backward reachable sets and show an overwhelming improvement of our proposed algorithms over state-of-the-art methods regarding scalability, as systems with well over a hundred states can now be analyzed.",
        "doi": "",
        "created": "2023-10-29",
        "url": "https://arxiv.org/abs/2310.19083",
        "authors": [
            "mark wetzlinger",
            "matthias althoff"
        ]
    },
    {
        "id": "2310.20092",
        "title": "the missing u for efficient diffusion models",
        "abstract": "diffusion probabilistic models stand as a critical tool in generative modelling, enabling the generation of complex data distributions. this family of generative models yields record-breaking performance in tasks such as image synthesis, video generation, and molecule design. despite their capabilities, their efficiency, especially in the reverse process, remains a challenge due to slow convergence rates and high computational costs. in this paper, we introduce an approach that leverages continuous dynamical systems to design a novel denoising network for diffusion models that is more parameter-efficient, exhibits faster convergence, and demonstrates increased noise robustness. experimenting with denoising diffusion probabilistic models (ddpms), our framework operates with approximately a quarter of the parameters, and $\\sim$ 30\\% of the floating point operations (flops) compared to standard u-nets in ddpms. furthermore, our model is notably faster in inference than the baseline when measured in fair and equal conditions. we also provide a mathematical intuition as to why our proposed reverse process is faster as well as a mathematical discussion of the empirical tradeoffs in the denoising downstream task. finally, we argue that our method is compatible with existing performance enhancement techniques, enabling further improvements in efficiency, quality, and speed.",
        "doi": "",
        "created": "2023-10-30",
        "url": "https://arxiv.org/abs/2310.20092",
        "authors": [
            "sergio calvo-ordonez",
            "chun-wun cheng",
            "jiahao huang",
            "lipei zhang",
            "guang yang",
            "carola-bibiane schonlieb",
            "angelica i aviles-rivero"
        ]
    },
    {
        "id": "2310.20550",
        "title": "capsfusion: rethinking image-text data at scale",
        "abstract": "large multimodal models demonstrate remarkable generalist ability to perform diverse multimodal tasks in a zero-shot manner. large-scale web-based image-text pairs contribute fundamentally to this success, but suffer from excessive noise. recent studies use alternative captions synthesized by captioning models and have achieved notable benchmark performance. however, our experiments reveal significant scalability deficiency and world knowledge loss issues in models trained with synthetic captions, which have been largely obscured by their initial benchmark success. upon closer examination, we identify the root cause as the overly-simplified language structure and lack of knowledge details in existing synthetic captions. to provide higher-quality and more scalable multimodal pretraining data, we propose capsfusion, an advanced framework that leverages large language models to consolidate and refine information from both web-based image-text pairs and synthetic captions. extensive experiments show that capsfusion captions exhibit remarkable all-round superiority over existing captions in terms of model performance (e.g., 18.8 and 18.3 improvements in cider score on coco and nocaps), sample efficiency (requiring 11-16 times less computation than baselines), world knowledge depth, and scalability. these effectiveness, efficiency and scalability advantages position capsfusion as a promising candidate for future scaling of lmm training.",
        "doi": "",
        "created": "2023-10-31",
        "url": "https://arxiv.org/abs/2310.20550",
        "authors": [
            "qiying yu",
            "quan sun",
            "xiaosong zhang",
            "yufeng cui",
            "fan zhang",
            "yue cao",
            "xinlong wang",
            "jingjing liu"
        ]
    },
    {
        "id": "2311.00176",
        "title": "chipnemo: domain-adapted llms for chip design",
        "abstract": "chipnemo aims to explore the applications of large language models (llms) for industrial chip design. instead of directly deploying off-the-shelf commercial or open-source llms, we instead adopt the following domain adaptation techniques: domain-adaptive tokenization, domain-adaptive continued pretraining, model alignment with domain-specific instructions, and domain-adapted retrieval models. we evaluate these methods on three selected llm applications for chip design: an engineering assistant chatbot, eda script generation, and bug summarization and analysis. our evaluations demonstrate that domain-adaptive pretraining of language models, can lead to superior performance in domain related downstream tasks compared to their base llama2 counterparts, without degradations in generic capabilities. in particular, our largest model, chipnemo-70b, outperforms the highly capable gpt-4 on two of our use cases, namely engineering assistant chatbot and eda scripts generation, while exhibiting competitive performance on bug summarization and analysis. these results underscore the potential of domain-specific customization for enhancing the effectiveness of large language models in specialized applications.",
        "doi": "",
        "created": "2023-10-31",
        "url": "https://arxiv.org/abs/2311.00176",
        "authors": [
            "mingjie liu",
            "teodor-dumitru ene",
            "robert kirby",
            "chris cheng",
            "nathaniel pinckney",
            "rongjian liang",
            "jonah alben",
            "himyanshu anand",
            "sanmitra banerjee",
            "ismet bayraktaroglu",
            "bonita bhaskaran",
            "bryan catanzaro",
            "arjun chaudhuri",
            "sharon clay",
            "bill dally",
            "laura dang",
            "parikshit deshpande",
            "siddhanth dhodhi",
            "sameer halepete",
            "eric hill",
            "jiashang hu",
            "sumit jain",
            "ankit jindal",
            "brucek khailany",
            "george kokai",
            "kishor kunal",
            "xiaowei li",
            "charley lind",
            "hao liu",
            "stuart oberman",
            "sujeet omar",
            "ghasem pasandi",
            "sreedhar pratty",
            "jonathan raiman",
            "ambar sarkar",
            "zhengjiang shao",
            "hanfei sun",
            "pratik p suthar",
            "varun tej",
            "walker turner",
            "kaizhe xu",
            "haoxing ren"
        ]
    },
    {
        "id": "2311.00875",
        "title": "learning collective behaviors from observation",
        "abstract": "we present a comprehensive examination of learning methodologies employed for the structural identification of dynamical systems. these techniques are designed to elucidate emergent phenomena within intricate systems of interacting agents. our approach not only ensures theoretical convergence guarantees but also exhibits computational efficiency when handling high-dimensional observational data. the methods adeptly reconstruct both first- and second-order dynamical systems, accommodating observation and stochastic noise, intricate interaction rules, absent interaction features, and real-world observations in agent systems. the foundational aspect of our learning methodologies resides in the formulation of tailored loss functions using the variational inverse problem approach, inherently equipping our methods with dimension reduction capabilities.",
        "doi": "",
        "created": "2023-11-01",
        "url": "https://arxiv.org/abs/2311.00875",
        "authors": [
            "jinchao feng",
            "ming zhong"
        ]
    },
    {
        "id": "2311.01734",
        "title": "sculpting holistic 3d representation in contrastive language-image-3d   pre-training",
        "abstract": "contrastive learning has emerged as a promising paradigm for 3d open-world understanding, i.e., aligning point cloud representation to image and text embedding space individually. in this paper, we introduce mixcon3d, a simple yet effective method aiming to sculpt holistic 3d representation in contrastive language-image-3d pre-training. in contrast to point cloud only, we develop the 3d object-level representation from complementary perspectives, e.g., multi-view rendered images with the point cloud. then, mixcon3d performs language-3d contrastive learning, comprehensively depicting real-world 3d objects and bolstering text alignment. additionally, we pioneer the first thorough investigation of various training recipes for the 3d contrastive learning paradigm, building a solid baseline with improved performance. extensive experiments conducted on three representative benchmarks reveal that our method significantly improves over the baseline, surpassing the previous state-of-the-art performance on the challenging 1,156-category objaverse-lvis dataset by 5.7%. the versatility of mixcon3d is showcased in applications such as text-to-3d retrieval and point cloud captioning, further evidencing its efficacy in diverse scenarios. the code is available at https://github.com/ucsc-vlaa/mixcon3d.",
        "doi": "",
        "created": "2023-11-03",
        "url": "https://arxiv.org/abs/2311.01734",
        "authors": [
            "yipeng gao",
            "zeyu wang",
            "wei-shi zheng",
            "cihang xie",
            "yuyin zhou"
        ]
    },
    {
        "id": "2311.03904",
        "title": "robustmat: neural diffusion for street landmark patch matching under   challenging environments",
        "abstract": "for autonomous vehicles (avs), visual perception techniques based on sensors like cameras play crucial roles in information acquisition and processing. in various computer perception tasks for avs, it may be helpful to match landmark patches taken by an onboard camera with other landmark patches captured at a different time or saved in a street scene image database. to perform matching under challenging driving environments caused by changing seasons, weather, and illumination, we utilize the spatial neighborhood information of each patch. we propose an approach, named robustmat, which derives its robustness to perturbations from neural differential equations. a convolutional neural ode diffusion module is used to learn the feature representation for the landmark patches. a graph neural pde diffusion module then aggregates information from neighboring landmark patches in the street scene. finally, feature similarity learning outputs the final matching score. our approach is evaluated on several street scene datasets and demonstrated to achieve state-of-the-art matching results under environmental perturbations.",
        "doi": "10.1109/tip.2023.3318963",
        "created": "2023-11-07",
        "url": "https://arxiv.org/abs/2311.03904",
        "authors": [
            "rui she",
            "qiyu kang",
            "sijie wang",
            "yuan-rui yang",
            "kai zhao",
            "yang song",
            "wee peng tay"
        ]
    },
    {
        "id": "2311.04617",
        "title": "image patch-matching with graph-based learning in street scenes",
        "abstract": "matching landmark patches from a real-time image captured by an on-vehicle camera with landmark patches in an image database plays an important role in various computer perception tasks for autonomous driving. current methods focus on local matching for regions of interest and do not take into account spatial neighborhood relationships among the image patches, which typically correspond to objects in the environment. in this paper, we construct a spatial graph with the graph vertices corresponding to patches and edges capturing the spatial neighborhood information. we propose a joint feature and metric learning model with graph-based learning. we provide a theoretical basis for the graph-based loss by showing that the information distance between the distributions conditioned on matched and unmatched pairs is maximized under our framework. we evaluate our model using several street-scene datasets and demonstrate that our approach achieves state-of-the-art matching results.",
        "doi": "10.1109/tip.2023.3281171",
        "created": "2023-11-08",
        "url": "https://arxiv.org/abs/2311.04617",
        "authors": [
            "rui she",
            "qiyu kang",
            "sijie wang",
            "wee peng tay",
            "yong liang guan",
            "diego navarro navarro",
            "andreas hartmannsgruber"
        ]
    },
    {
        "id": "2311.08046",
        "title": "chat-univi: unified visual representation empowers large language models   with image and video understanding",
        "abstract": "large language models have demonstrated impressive universal capabilities across a wide range of open-ended tasks and have extended their utility to encompass multimodal conversations. however, existing methods encounter challenges in effectively handling both image and video understanding, particularly with limited visual tokens. in this work, we introduce chat-univi, a unified vision-language model capable of comprehending and engaging in conversations involving images and videos through a unified visual representation. specifically, we employ a set of dynamic visual tokens to uniformly represent images and videos. this representation framework empowers the model to efficiently utilize a limited number of visual tokens to simultaneously capture the spatial details necessary for images and the comprehensive temporal relationship required for videos. moreover, we leverage a multi-scale representation, enabling the model to perceive both high-level semantic concepts and low-level visual details. notably, chat-univi is trained on a mixed dataset containing both images and videos, allowing direct application to tasks involving both mediums without requiring any modifications. extensive experimental results demonstrate that chat-univi consistently outperforms even existing methods exclusively designed for either images or videos. code is available at https://github.com/pku-yuangroup/chat-univi.",
        "doi": "",
        "created": "2023-11-14",
        "url": "https://arxiv.org/abs/2311.08046",
        "authors": [
            "peng jin",
            "ryuichi takanobu",
            "wancai zhang",
            "xiaochun cao",
            "li yuan"
        ]
    },
    {
        "id": "2311.08283",
        "title": "nonadaptive noise-resilient group testing with order-optimal tests and   fast-and-reliable decoding",
        "abstract": "group testing (gt) is the boolean version of spare signal recovery and, due to its simplicity, a marketplace for ideas that can be brought to bear upon related problems, such as heavy hitters, compressed sensing, and multiple access channels. the definition of a \"good\" gt varies from one buyer to another, but it generally includes (i) usage of nonadaptive tests, (ii) limiting to $o(k \\log n)$ tests, (iii) resiliency to test noise, (iv) $o(k \\mathrm{poly}(\\log n))$ decoding time, and (v) lack of mistakes. in this paper, we propose $gacha~gt$. gacha is an elementary and self-contained, versatile and unified scheme that, for the first time, satisfies all criteria for a fairly large region of parameters, namely when $\\log k < \\log(n)^{1-1/o(1)}$. outside this parameter region, gacha can be specialized to outperform the state-of-the-art partial-recovery gts, exact-recovery gts, and worst-case gts.   the new idea gacha brings to the market is a redesigned reed--solomon code for probabilistic list-decoding at diminishing code rates over reasonably-large alphabets. normally, list-decoding a vanilla reed--solomon code is equivalent to the nontrivial task of identifying the subsets of points that fit low-degree polynomials. in this paper, we explicitly tell the decoder which points belong to the same polynomial, thus reducing the complexity and enabling the improvement on gt.",
        "doi": "",
        "created": "2023-11-14",
        "url": "https://arxiv.org/abs/2311.08283",
        "authors": [
            "venkatesan guruswami",
            "hsin-po wang"
        ]
    },
    {
        "id": "2311.08577",
        "title": "finding ai-generated faces in the wild",
        "abstract": "ai-based image generation has continued to rapidly improve, producing increasingly more realistic images with fewer obvious visual flaws. ai-generated images are being used to create fake online profiles which in turn are being used for spam, fraud, and disinformation campaigns. as the general problem of detecting any type of manipulated or synthesized content is receiving increasing attention, here we focus on a more narrow task of distinguishing a real face from an ai-generated face. this is particularly applicable when tackling inauthentic online accounts with a fake user profile photo. we show that by focusing on only faces, a more resilient and general-purpose artifact can be detected that allows for the detection of ai-generated faces from a variety of gan- and diffusion-based synthesis engines, and across image resolutions (as low as 128 x 128 pixels) and qualities.",
        "doi": "",
        "created": "2023-11-14",
        "url": "https://arxiv.org/abs/2311.08577",
        "authors": [
            "gonzalo j. aniano porcile",
            "jack gindi",
            "shivansh mundra",
            "james r. verbus",
            "hany farid"
        ]
    },
    {
        "id": "2311.09206",
        "title": "tablellama: towards open large generalist models for tables",
        "abstract": "semi-structured tables are ubiquitous. there has been a variety of tasks that aim to automatically interpret, augment, and query tables. current methods often require pretraining on tables or special model architecture design, are restricted to specific table types, or have simplifying assumptions about tables and tasks. this paper makes the first step towards developing open-source large language models (llms) as generalists for a diversity of table-based tasks. towards that end, we construct tableinstruct, a new dataset with a variety of realistic tables and tasks, for instruction tuning and evaluating llms. we further develop the first open-source generalist model for tables, tablellama, by fine-tuning llama 2 (7b) with longlora to address the long context challenge. we experiment under both in-domain setting and out-of-domain setting. on 7 out of 8 in-domain tasks, tablellama achieves comparable or better performance than the sota for each task, despite the latter often has task-specific design. on 6 out-of-domain datasets, it achieves 5-44 absolute point gains compared with the base model, showing that training on tableinstruct enhances the model's generalizability. we open-source our dataset and trained model to boost future work on developing open generalist models for tables.",
        "doi": "",
        "created": "2023-11-15",
        "url": "https://arxiv.org/abs/2311.09206",
        "authors": [
            "tianshu zhang",
            "xiang yue",
            "yifei li",
            "huan sun"
        ]
    },
    {
        "id": "2311.09491",
        "title": "spatial bayesian neural networks",
        "abstract": "interpretable, and well understood models that are routinely employed even though, as is revealed through prior and posterior predictive checks, these can poorly characterise the spatial heterogeneity in the underlying process of interest. here, we propose a new, flexible class of spatial-process models, which we refer to as spatial bayesian neural networks (sbnns). an sbnn leverages the representational capacity of a bayesian neural network; it is tailored to a spatial setting by incorporating a spatial ``embedding layer'' into the network and, possibly, spatially-varying network parameters. an sbnn is calibrated by matching its finite-dimensional distribution at locations on a fine gridding of space to that of a target process of interest. that process could be easy to simulate from or we may have many realisations from it. we propose several variants of sbnns, most of which are able to match the finite-dimensional distribution of the target process at the selected grid better than conventional bnns of similar complexity. we also show that an sbnn can be used to represent a variety of spatial processes often used in practice, such as gaussian processes, lognormal processes, and max-stable processes. we briefly discuss the tools that could be used to make inference with sbnns, and we conclude with a discussion of their advantages and limitations.",
        "doi": "",
        "created": "2023-11-15",
        "url": "https://arxiv.org/abs/2311.09491",
        "authors": [
            "andrew zammit-mangion",
            "michael d. kaminski",
            "ba-hien tran",
            "maurizio filippone",
            "noel cressie"
        ]
    },
    {
        "id": "2311.09559",
        "title": "prompt-based pseudo-labeling strategy for sample-efficient   semi-supervised extractive summarization",
        "abstract": "semi-supervised learning (ssl) is a widely used technique in scenarios where labeled data is scarce and unlabeled data is abundant. while ssl is popular for image and text classification, it is relatively underexplored for the task of extractive text summarization. standard ssl methods follow a teacher-student paradigm to first train a classification model and then use the classifier's confidence values to select pseudo-labels for the subsequent training cycle; however, such classifiers are not suitable to measure the accuracy of pseudo-labels as they lack specific tuning for evaluation, which leads to confidence values that fail to capture the semantics and correctness of the generated summary. to address this problem, we propose a prompt-based pseudo-labeling strategy with llms that picks unlabeled examples with more accurate pseudo-labels than using just the classifier's probability outputs. our approach also includes a relabeling mechanism that improves the quality of pseudo-labels. we evaluate our method on three text summarization datasets: tweetsumm, wikihow, and arxiv/pubmed. we empirically show that a prompting-based llm that scores and generates pseudo-labels outperforms existing ssl methods on rouge-1, rouge-2, and rouge-l scores on all the datasets. furthermore, our method achieves competitive g-eval scores (evaluation with gpt-4) as a fully supervised method that uses 100% of the labeled data with only 16.67% of the labeled data.",
        "doi": "",
        "created": "2023-11-15",
        "url": "https://arxiv.org/abs/2311.09559",
        "authors": [
            "gaurav sahu",
            "olga vechtomova",
            "issam h. laradji"
        ]
    },
    {
        "id": "2311.09635",
        "title": "evaluating in-context learning of libraries for code generation",
        "abstract": "contemporary large language models (llms) exhibit a high degree of code generation and comprehension capability. a particularly promising area is their ability to interpret code modules from unfamiliar libraries for solving user-instructed tasks. recent work has shown that large proprietary llms can learn novel library usage in-context from demonstrations. these results raise several open questions: whether demonstrations of library usage is required, whether smaller (and more open) models also possess such capabilities, etc. in this work, we take a broader approach by systematically evaluating a diverse array of llms across three scenarios reflecting varying levels of domain specialization to understand their abilities and limitations in generating code based on libraries defined in-context. our results show that even smaller open-source llms like llama-2 and starcoder demonstrate an adept understanding of novel code libraries based on specification presented in-context. our findings further reveal that llms exhibit a surprisingly high proficiency in learning novel library modules even when provided with just natural language descriptions or raw code implementations of the functions, which are often cheaper to obtain than demonstrations. overall, our results pave the way for harnessing llms in more adaptable and dynamic coding environments.",
        "doi": "",
        "created": "2023-11-16",
        "url": "https://arxiv.org/abs/2311.09635",
        "authors": [
            "arkil patel",
            "siva reddy",
            "dzmitry bahdanau",
            "pradeep dasigi"
        ]
    },
    {
        "id": "2311.09941",
        "title": "ghost value augmentation for $k$-edge-connectivity",
        "abstract": "we give a poly-time algorithm for the $k$-edge-connected spanning subgraph ($k$-ecss) problem that returns a solution of cost no greater than the cheapest $(k+10)$-ecss on the same graph. our approach enhances the iterative relaxation framework with a new ingredient, which we call ghost values, that allows for high sparsity in intermediate problems.   our guarantees improve upon the best-known approximation factor of $2$ for $k$-ecss whenever the optimal value of $(k+10)$-ecss is close to that of $k$-ecss. this is a property that holds for the closely related problem $k$-edge-connected spanning multi-subgraph ($k$-ecsm), which is identical to $k$-ecss except edges can be selected multiple times at the same cost. as a consequence, we obtain a $\\left(1+o\\left(\\frac{1}{k}\\right)\\right)$-approximation algorithm for $k$-ecsm, which resolves a conjecture of pritchard and improves upon a recent $\\left(1+o\\left(\\frac{1}{\\sqrt{k}}\\right)\\right)$-approximation algorithm of karlin, klein, oveis gharan, and zhang. moreover, we present a matching lower bound for $k$-ecsm, showing that our approximation ratio is tight up to the constant factor in $o\\left(\\frac{1}{k}\\right)$, unless $p=np$.",
        "doi": "",
        "created": "2023-11-16",
        "url": "https://arxiv.org/abs/2311.09941",
        "authors": [
            "d ellis hershkowitz",
            "nathan klein",
            "rico zenklusen"
        ]
    },
    {
        "id": "2311.10533",
        "title": "parsing millions of urls per second",
        "abstract": "urls are fundamental elements of web applications. by applying vector algorithms, we built a fast standard-compliant c++ implementation. our parser uses three times fewer instructions than competing parsers following the whatwg standard (e.g., servo's rust-url) and up to eight times fewer instructions than the popular curl parser. the node.js environment adopted our c++ library. in our tests on realistic data, a recent node.js version (20.0) with our parser is four to five times faster than the last version with the legacy url parser.",
        "doi": "10.1002/spe.3296",
        "created": "2023-11-17",
        "url": "https://arxiv.org/abs/2311.10533",
        "authors": [
            "yagiz nizipli",
            "daniel lemire"
        ]
    },
    {
        "id": "2311.10797",
        "title": "taco: enhancing cross-lingual transfer for low-resource languages in   llms through translation-assisted chain-of-thought processes",
        "abstract": "creating multilingual llms poses a significant challenge. pretraining or fine-tuning llms to adopt new languages is evidently very costly. furthermore, there exist limitations concerning benchmark datasets and the metrics used to measure model performance in multilingual settings. this paper proposes cost-effective solutions to both aforementioned challenges. firstly, we introduce the multilingual instruction-tuning dataset (mits), comprised of alpaca-52k, dolly-15k, and vicuna benchmark translations into 132 languages. secondly, we propose a new method called \\emph{taco: translation-assisted cross-linguality}, which utilizes translations in a chain-of-thought process to instruction-tune llms on new languages through a curriculum-learning process. as a proof of concept, we experimented with the instruction-tuned guanaco-33b model, performing further instruction tuning using our proposed taco method in three low-resource languages and one high-resource language. our results indicate that the taco method impresses gpt-4 with an 82\\% score for a low-resource language in the vicuna benchmark dataset, doubling the performance in contrast to instruction tuning alone. furthermore, taco shows promise in creating multilingual llms, even for low-resource languages. we have released our datasets and model adapters\\footnote{https://github.com/unhsaillab/taco} , encouraging the research community to utilize these resources to advance work on multilingual llms.",
        "doi": "",
        "created": "2023-11-17",
        "url": "https://arxiv.org/abs/2311.10797",
        "authors": [
            "bibek upadhayay",
            "vahid behzadan"
        ]
    },
    {
        "id": "2311.11167",
        "title": "benchmarking machine learning models for quantum error correction",
        "abstract": "quantum error correction (qec) is one of the fundamental problems in quantum computer systems, which aims to detect and correct errors in the data qubits within quantum computers. due to the presence of unreliable data qubits in existing quantum computers, implementing quantum error correction is a critical step when establishing a stable quantum computer system. recently, machine learning (ml)-based approaches have been proposed to address this challenge. however, they lack a thorough understanding of quantum error correction. to bridge this research gap, we provide a new perspective to understand machine learning-based qec in this paper. we find that syndromes in the ancilla qubits result from errors on connected data qubits, and distant ancilla qubits can provide auxiliary information to rule out some incorrect predictions for the data qubits. therefore, to detect errors in data qubits, we must consider the information present in the long-range ancilla qubits. to the best of our knowledge, machine learning is less explored in the dependency relationship of qec. to fill the blank, we curate a machine learning benchmark to assess the capacity to capture long-range dependencies for quantum error correction. to provide a comprehensive evaluation, we evaluate seven state-of-the-art deep learning algorithms spanning diverse neural network architectures, such as convolutional neural networks, graph neural networks, and graph transformers. our exhaustive experiments reveal an enlightening trend: by enlarging the receptive field to exploit information from distant ancilla qubits, the accuracy of qec significantly improves. for instance, u-net can improve cnn by a margin of about 50%. finally, we provide a comprehensive analysis that could inspire future research in this field.",
        "doi": "",
        "created": "2023-11-18",
        "url": "https://arxiv.org/abs/2311.11167",
        "authors": [
            "yue zhao"
        ]
    },
    {
        "id": "2311.11679",
        "title": "perfect simulation of las vegas algorithms via local computation",
        "abstract": "the notion of las vegas algorithms was introduced by babai (1979) and can be defined in two ways:   * in babai's original definition, a randomized algorithm is called las vegas if it has a finitely bounded running time and certifiable random failure.   * another definition widely accepted today is that las vegas algorithms refer to zero-error randomized algorithms with random running times.   the equivalence between the two definitions is straightforward. specifically, for randomized algorithms with certifiable failures, repeatedly running the algorithm until no failure is encountered allows for faithful simulation of the correct output when it executes successfully.   we show that a similar perfect simulation can also be achieved in distributed local computation. specifically, in the local model, with polylogarithmic overhead in time complexity, any las vegas algorithm with finitely bounded running time and locally certifiable failures can be converted to a zero-error las vegas algorithm. this transformed algorithm faithfully reproduces the correct output of the original algorithm in successful executions.",
        "doi": "",
        "created": "2023-11-20",
        "url": "https://arxiv.org/abs/2311.11679",
        "authors": [
            "xinyu fu",
            "yonggang jiang",
            "yitong yin"
        ]
    },
    {
        "id": "2311.11690",
        "title": "refactoring programs using large language models with few-shot examples",
        "abstract": "a less complex and more straightforward program is a crucial factor that enhances its maintainability and makes writing secure and bug-free programs easier. however, due to its heavy workload and the risks of breaking the working programs, programmers are reluctant to do code refactoring, and thus, it also causes the loss of potential learning experiences. to mitigate this, we demonstrate the application of using a large language model (llm), gpt-3.5, to suggest less complex versions of the user-written python program, aiming to encourage users to learn how to write better programs. we propose a method to leverage the prompting with few-shot examples of the llm by selecting the best-suited code refactoring examples for each target programming problem based on the prior evaluation of prompting with the one-shot example. the quantitative evaluation shows that 95.68% of programs can be refactored by generating 10 candidates each, resulting in a 17.35% reduction in the average cyclomatic complexity and a 25.84% decrease in the average number of lines after filtering only generated programs that are semantically correct. furthermore, the qualitative evaluation shows outstanding capability in code formatting, while unnecessary behaviors such as deleting or translating comments are also observed.",
        "doi": "10.1109/apsec60848.2023.00025",
        "created": "2023-11-20",
        "url": "https://arxiv.org/abs/2311.11690",
        "authors": [
            "atsushi shirafuji",
            "yusuke oda",
            "jun suzuki",
            "makoto morishita",
            "yutaka watanobe"
        ]
    },
    {
        "id": "2312.00111",
        "title": "multimodal learning for materials",
        "abstract": "artificial intelligence is transforming computational materials science, improving the prediction of material properties, and accelerating the discovery of novel materials. recently, publicly available material data repositories have grown rapidly. this growth encompasses not only more materials, but also a greater variety and quantity of their associated properties. existing machine learning efforts in materials science focus primarily on single-modality tasks, i.e., relationships between materials and a single physical property, thus not taking advantage of the rich and multimodal set of material properties. here, we introduce multimodal learning for materials (multimat), which enables self-supervised multi-modality training of foundation models for materials. we demonstrate our framework's potential using data from the materials project database on multiple axes: (i) multimat achieves state-of-the-art performance for challenging material property prediction tasks; (ii) multimat enables novel and accurate material discovery via latent space similarity, enabling screening for stable materials with desired properties; and (iii) multimat encodes interpretable emergent features that may provide novel scientific insights.",
        "doi": "",
        "created": "2023-11-30",
        "url": "https://arxiv.org/abs/2312.00111",
        "authors": [
            "viggo moro",
            "charlotte loh",
            "rumen dangovski",
            "ali ghorashi",
            "andrew ma",
            "zhuo chen",
            "peter y. lu",
            "thomas christensen",
            "marin solja\u010di\u0107"
        ]
    },
    {
        "id": "2312.00502",
        "title": "which augmentation should i use? an empirical investigation of   augmentations for self-supervised phonocardiogram representation learning",
        "abstract": "despite the recent increase in research activity, deep-learning models have not yet been widely accepted in several real-world settings, such as medicine. the shortage of high-quality annotated data often hinders the development of robust and generalizable models, which do not suffer from degraded effectiveness when presented with out-of-distribution (ood) datasets. contrastive self-supervised learning (ssl) offers a potential solution to labeled data scarcity, as it takes advantage of unlabeled data to increase model effectiveness and robustness. however, the selection of appropriate transformations during the learning process is not a trivial task and even breaks down the ability of the network to extract meaningful information. in this research, we propose uncovering the optimal augmentations for applying contrastive learning in 1d phonocardiogram (pcg) classification. we perform an extensive comparative evaluation of a wide range of audio-based augmentations, evaluate models on multiple datasets across downstream tasks, and report on the impact of each augmentation. we demonstrate that depending on its training distribution, the effectiveness of a fully-supervised model can degrade up to 32%, while ssl models only lose up to 10% or even improve in some cases. we argue and experimentally demonstrate that, contrastive ssl pretraining can assist in providing robust classifiers which can generalize to unseen, ood data, without relying on time- and labor-intensive annotation processes by medical experts. furthermore, the proposed evaluation protocol sheds light on the most promising and appropriate augmentations for robust pcg signal processing, by calculating their effect size on model training. finally, we provide researchers and practitioners with a roadmap towards producing robust models for pcg classification, in addition to an open-source codebase for developing novel approaches.",
        "doi": "",
        "created": "2023-12-01",
        "url": "https://arxiv.org/abs/2312.00502",
        "authors": [
            "aristotelis ballas",
            "vasileios papapanagiotou",
            "christos diou"
        ]
    },
    {
        "id": "2312.00648",
        "title": "spot: self-training with patch-order permutation for object-centric   learning with autoregressive transformers",
        "abstract": "unsupervised object-centric learning aims to decompose scenes into interpretable object entities, termed slots. slot-based auto-encoders stand out as a prominent method for this task. within them, crucial aspects include guiding the encoder to generate object-specific slots and ensuring the decoder utilizes them during reconstruction. this work introduces two novel techniques, (i) an attention-based self-training approach, which distills superior slot-based attention masks from the decoder to the encoder, enhancing object segmentation, and (ii) an innovative patch-order permutation strategy for autoregressive transformers that strengthens the role of slot vectors in reconstruction. the effectiveness of these strategies is showcased experimentally. the combined approach significantly surpasses prior slot-based autoencoder methods in unsupervised object segmentation, especially with complex real-world images. we provide the implementation code at https://github.com/gkakogeorgiou/spot .",
        "doi": "",
        "created": "2023-12-01",
        "url": "https://arxiv.org/abs/2312.00648",
        "authors": [
            "ioannis kakogeorgiou",
            "spyros gidaris",
            "konstantinos karantzalos",
            "nikos komodakis"
        ]
    },
    {
        "id": "2312.00690",
        "title": "open-vocabulary object 6d pose estimation",
        "abstract": "we introduce the new setting of open-vocabulary object 6d pose estimation, in which a textual prompt is used to specify the object of interest. in contrast to existing approaches, in our setting (i) the object of interest is specified solely through the textual prompt, (ii) no object model (e.g., cad or video sequence) is required at inference, and (iii) the object is imaged from two rgbd viewpoints of different scenes. to operate in this setting, we introduce a novel approach that leverages a vision-language model to segment the object of interest from the scenes and to estimate its relative 6d pose. the key of our approach is a carefully devised strategy to fuse object-level information provided by the prompt with local image features, resulting in a feature space that can generalize to novel concepts. we validate our approach on a new benchmark based on two popular datasets, real275 and toyota-light, which collectively encompass 34 object instances appearing in four thousand image pairs. the results demonstrate that our approach outperforms both a well-established hand-crafted method and a recent deep learning-based baseline in estimating the relative 6d pose of objects in different scenes. code and dataset are available at https://jcorsetti.github.io/oryon.",
        "doi": "",
        "created": "2023-12-01",
        "url": "https://arxiv.org/abs/2312.00690",
        "authors": [
            "jaime corsetti",
            "davide boscaini",
            "changjae oh",
            "andrea cavallaro",
            "fabio poiesi"
        ]
    },
    {
        "id": "2312.02097",
        "title": "inapproximability of maximum diameter clustering for few clusters",
        "abstract": "in the max-k-diameter problem, we are given a set of points in a metric space, and the goal is to partition the input points into k parts such that the maximum pairwise distance between points in the same part of the partition is minimized.   the approximability of the max-k-diameter problem was studied in the eighties, culminating in the work of feder and greene [stoc'88], wherein they showed it is np-hard to approximate within a factor better than 2 in the $\\ell_1$ and $\\ell_\\infty$ metrics, and np-hard to approximate within a factor better than 1.969 in the euclidean metric. this complements the celebrated 2 factor polynomial time approximation algorithm for the problem in general metrics (gonzalez [tcs'85]; hochbaum and shmoys [jacm'86]).   over the last couple of decades, there has been increased interest from the algorithmic community to study the approximability of various clustering objectives when the number of clusters is fixed. in this setting, the framework of coresets has yielded ptas for most popular clustering objectives, including k-means, k-median, k-center, k-minsum, and so on.   in this paper, rather surprisingly, we prove that even when k=3, the max-k-diameter problem is np-hard to approximate within a factor of 1.5 in the $\\ell_1$-metric (and hamming metric) and np-hard to approximate within a factor of 1.304 in the euclidean metric.   our main conceptual contribution is the introduction of a novel framework called cloud systems which embed hypergraphs into $\\ell_p$-metric spaces such that the chromatic number of the hypergraph is related to the quality of the max-k-diameter clustering of the embedded pointset. our main technical contributions are the constructions of nontrivial cloud systems in the euclidean and $\\ell_1$-metrics using extremal geometric structures.",
        "doi": "",
        "created": "2023-12-04",
        "url": "https://arxiv.org/abs/2312.02097",
        "authors": [
            "henry fleischmann",
            "kyrylo karlov",
            "karthik c. s.",
            "ashwin padaki",
            "stepan zharkov"
        ]
    },
    {
        "id": "2312.02702",
        "title": "neural sign actors: a diffusion model for 3d sign language production   from text",
        "abstract": "sign languages (sl) serve as the primary mode of communication for the deaf and hard of hearing communities. deep learning methods for sl recognition and translation have achieved promising results. however, sign language production (slp) poses a challenge as the generated motions must be realistic and have precise semantic meaning. most slp methods rely on 2d data, which hinders their realism. in this work, a diffusion-based slp model is trained on a curated large-scale dataset of 4d signing avatars and their corresponding text transcripts. the proposed method can generate dynamic sequences of 3d avatars from an unconstrained domain of discourse using a diffusion process formed on a novel and anatomically informed graph neural network defined on the smpl-x body skeleton. through quantitative and qualitative experiments, we show that the proposed method considerably outperforms previous methods of slp. this work makes an important step towards realistic neural sign avatars, bridging the communication gap between deaf and hearing communities.",
        "doi": "",
        "created": "2023-12-05",
        "url": "https://arxiv.org/abs/2312.02702",
        "authors": [
            "vasileios baltatzis",
            "rolandos alexandros potamias",
            "evangelos ververas",
            "guanxiong sun",
            "jiankang deng",
            "stefanos zafeiriou"
        ]
    },
    {
        "id": "2312.03052",
        "title": "visual program distillation: distilling tools and programmatic reasoning   into vision-language models",
        "abstract": "solving complex visual tasks such as \"who invented the musical instrument on the right?\" involves a composition of skills: understanding space, recognizing instruments, and also retrieving prior knowledge. recent work shows promise by decomposing such tasks using a large language model (llm) into an executable program that invokes specialized vision models. however, generated programs are error-prone: they omit necessary steps, include spurious ones, and are unable to recover when the specialized models give incorrect outputs. moreover, they require loading multiple models, incurring high latency and computation costs. we propose visual program distillation (vpd), an instruction tuning framework that produces a vision-language model (vlm) capable of solving complex visual tasks with a single forward pass. vpd distills the reasoning ability of llms by using them to sample multiple candidate programs, which are then executed and verified to identify a correct one. it translates each correct program into a language description of the reasoning steps, which are then distilled into a vlm. extensive experiments show that vpd improves the vlm's ability to count, understand spatial relations, and reason compositionally. our vpd-trained pali-x outperforms all prior vlms, achieving state-of-the-art performance across complex vision tasks, including mmbench, ok-vqa, a-okvqa, tallyqa, pope, and hateful memes. an evaluation with human annotators also confirms that vpd improves model response factuality and consistency. finally, experiments on content moderation demonstrate that vpd is also helpful for adaptation to real-world applications with limited data.",
        "doi": "",
        "created": "2023-12-05",
        "url": "https://arxiv.org/abs/2312.03052",
        "authors": [
            "yushi hu",
            "otilia stretcu",
            "chun-ta lu",
            "krishnamurthy viswanathan",
            "kenji hata",
            "enming luo",
            "ranjay krishna",
            "ariel fuxman"
        ]
    },
    {
        "id": "2312.03097",
        "title": "state of health estimation for battery modules with parallel-connected   cells under cell-to-cell variations",
        "abstract": "state of health (soh) estimation for lithium-ion battery modules with cells connected in parallel is a challenging problem, especially with cell-to-cell variations. incremental capacity analysis (ica) and differential voltage analysis (dva) are effective at the cell level, but a generalizable method to extend them to module-level soh estimation remains missing, when only module-level measurements are available. this paper proposes a new method and demonstrates that, with multiple features systematically selected from the module-level ica and dva, the module-level soh can be estimated with high accuracy and confidence in the presence of cell-to-cell variations. first, an information theory-based feature selection algorithm is proposed to find an optimal set of features for module-level soh estimation. second, a relevance vector regression (rvr)-based module-level soh estimation model is proposed to provide both point estimates and three-sigma credible intervals while maintaining model sparsity. with more selected features incorporated, the proposed method achieves better estimation accuracy and higher confidence at the expense of higher model complexity. when applied to a large experimental dataset, the proposed method and the resulting sparse model lead to module-level soh estimates with 0.5% root-mean-square errors and 1.5% average three-sigma values. with all the training processes completed offboard, the proposed method has low computational complexity for onboard implementations.",
        "doi": "",
        "created": "2023-12-05",
        "url": "https://arxiv.org/abs/2312.03097",
        "authors": [
            "qinan zhou",
            "dyche anderson",
            "jing sun"
        ]
    },
    {
        "id": "2312.06420",
        "title": "localization is all you evaluate: data leakage in online mapping   datasets and how to fix it",
        "abstract": "the task of online mapping is to predict a local map using current sensor observations, e.g. from lidar and camera, without relying on a pre-built map. state-of-the-art methods are based on supervised learning and are trained predominantly using two datasets: nuscenes and argoverse 2. however, these datasets revisit the same geographic locations across training, validation, and test sets. specifically, over $80$% of nuscenes and $40$% of argoverse 2 validation and test samples are less than $5$ m from a training sample. at test time, the methods are thus evaluated more on how well they localize within a memorized implicit map built from the training data than on extrapolating to unseen locations. naturally, this data leakage causes inflated performance numbers and we propose geographically disjoint data splits to reveal the true performance in unseen environments. experimental results show that methods perform considerably worse, some dropping more than $45$ map, when trained and evaluated on proper data splits. additionally, a reassessment of prior design choices reveals diverging conclusions from those based on the original split. notably, the impact of lifting methods and the support from auxiliary tasks (e.g., depth supervision) on performance appears less substantial or follows a different trajectory than previously perceived. splits can be found at https://github.com/liljaadam/geographical-splits",
        "doi": "",
        "created": "2023-12-11",
        "url": "https://arxiv.org/abs/2312.06420",
        "authors": [
            "adam lilja",
            "junsheng fu",
            "erik stenborg",
            "lars hammarstrand"
        ]
    },
    {
        "id": "2312.06587",
        "title": "quickquakebuildings: post-earthquake sar-optical dataset for quick   damaged-building detection",
        "abstract": "quick and automated earthquake-damaged building detection from post-event satellite imagery is crucial, yet it is challenging due to the scarcity of training data required to develop robust algorithms. this letter presents the first dataset dedicated to detecting earthquake-damaged buildings from post-event very high resolution (vhr) synthetic aperture radar (sar) and optical imagery. utilizing open satellite imagery and annotations acquired after the 2023 turkey-syria earthquakes, we deliver a dataset of coregistered building footprints and satellite image patches of both sar and optical data, encompassing more than four thousand buildings. the task of damaged building detection is formulated as a binary image classification problem, that can also be treated as an anomaly detection problem due to extreme class imbalance. we provide baseline methods and results to serve as references for comparison. researchers can utilize this dataset to expedite algorithm development, facilitating the rapid detection of damaged buildings in response to future events. the dataset and codes together with detailed explanations and visualization are made publicly available at \\url{https://github.com/ya0-sun/posteq-saropt-buildingdamage}.",
        "doi": "",
        "created": "2023-12-11",
        "url": "https://arxiv.org/abs/2312.06587",
        "authors": [
            "yao sun",
            "yi wang",
            "michael eineder"
        ]
    },
    {
        "id": "2312.08063",
        "title": "estimation of concept explanations should be uncertainty aware",
        "abstract": "model explanations can be valuable for interpreting and debugging predictive models. we study a specific kind called concept explanations, where the goal is to interpret a model using human-understandable concepts. although popular for their easy interpretation, concept explanations are known to be noisy. we begin our work by identifying various sources of uncertainty in the estimation pipeline that lead to such noise. we then propose an uncertainty-aware bayesian estimation method to address these issues, which readily improved the quality of explanations. we demonstrate with theoretical analysis and empirical evaluation that explanations computed by our method are robust to train-time choices while also being label-efficient. further, our method proved capable of recovering relevant concepts amongst a bank of thousands, in an evaluation with real-datasets and off-the-shelf models, demonstrating its scalability. we believe the improved quality of uncertainty-aware concept explanations make them a strong candidate for more reliable model interpretation. we release our code at https://github.com/vps-anonconfs/uace.",
        "doi": "",
        "created": "2023-12-13",
        "url": "https://arxiv.org/abs/2312.08063",
        "authors": [
            "vihari piratla",
            "juyeon heo",
            "katherine m. collins",
            "sukriti singh",
            "adrian weller"
        ]
    },
    {
        "id": "2312.08240",
        "title": "centergrasp: object-aware implicit representation learning for   simultaneous shape reconstruction and 6-dof grasp estimation",
        "abstract": "reliable object grasping is a crucial capability for autonomous robots. however, many existing grasping approaches focus on general clutter removal without explicitly modeling objects and thus only relying on the visible local geometry. we introduce centergrasp, a novel framework that combines object awareness and holistic grasping. centergrasp learns a general object prior by encoding shapes and valid grasps in a continuous latent space. it consists of an rgb-d image encoder that leverages recent advances to detect objects and infer their pose and latent code, and a decoder to predict shape and grasps for each object in the scene. we perform extensive experiments on simulated as well as real-world cluttered scenes and demonstrate strong scene reconstruction and 6-dof grasp-pose estimation performance. compared to the state of the art, centergrasp achieves an improvement of 38.5 mm in shape reconstruction and 33 percentage points on average in grasp success. we make the code and trained models publicly available at http://centergrasp.cs.uni-freiburg.de.",
        "doi": "",
        "created": "2023-12-13",
        "url": "https://arxiv.org/abs/2312.08240",
        "authors": [
            "eugenio chisari",
            "nick heppert",
            "tim welschehold",
            "wolfram burgard",
            "abhinav valada"
        ]
    },
    {
        "id": "2312.08537",
        "title": "object-centric conformance alignments with synchronization (extended   version)",
        "abstract": "real-world processes operate on objects that are inter-dependent. to accurately reflect the nature of such processes, object-centric process mining techniques are needed, notably conformance checking. however, while the object-centric perspective has recently gained traction, few concrete process mining techniques have been presented so far. moreover, existing approaches are severely limited in their abilities to keep track of object identity and object dependencies. consequently, serious problems in logs remain undetected. in this paper, we present a new formalism that combines the key modelling features of two existing approaches, in particular the ability of object-centric petri nets to capture one-to-many relations and the one of petri nets with identifiers to compare and synchronize objects based on their identity. we call the resulting formalism 'object-centric petri nets with identifiers', and define alignments and the conformance checking task for this setting. we propose a conformance checking approach for such nets based on an encoding in satisfiability modulo theories (smt), and illustrate how it can be effectively used to overcome shortcomings of earlier work. to assess its practicality, we perform an evaluation on data from the literature.",
        "doi": "",
        "created": "2023-12-13",
        "url": "https://arxiv.org/abs/2312.08537",
        "authors": [
            "alessandro gianola",
            "marco montali",
            "sarah winkler"
        ]
    },
    {
        "id": "2312.09428",
        "title": "mode selection in cognitive radar networks",
        "abstract": "cognitive radar networks, which were popularized by simon haykin in 2006, have been proposed to address limitations with legacy radar installations. these limitations include large physical size, power consumption, fixed operating parameters, and single point vulnerabilities. cognitive radar solves part of this problem through adaptability, using biologically inspired techniques to observe the environment and adjust operation accordingly. cognitive radar networks (crns) extend the capabilities of cognitive radar spatially, providing the opportunity to observe targets from multiple angles to mitigate stealth effects; distribute resources over space and in time; obtain better tracking performance; and gain more information from a scene. often, problems of cognition in crns are viewed through the lens of iterative learning problems - one or multiple cognitive processes are implemented in the network, where each process first observes the environment, then selects operating parameters (from discrete or continuous options) using the history of observations and previous rewards, then repeats the cycle. further, cognitive radar networks often are modeled with a flexible architecture and wide-bandwidth front-ends, enabling the addition of electronic support measures such as passive signal estimation. in this work we consider questions of the form \"how should a cognitive radar network choose when to observe targets?\" and \"how can a cognitive radar network reduce the amount of energy it uses?\". we implement tools from the multi-armed bandit and age of information literature to select modes for the network, choosing either an active radar mode or a passive signal estimation mode. we show that through the use of target classes, the network can determine how often each target should be observed to optimize tracking performance.",
        "doi": "",
        "created": "2023-11-30",
        "url": "https://arxiv.org/abs/2312.09428",
        "authors": [
            "william w. howard",
            "samuel r. shebert",
            "anthony f. martone",
            "r. michael buehrer"
        ]
    },
    {
        "id": "2312.10835",
        "title": "your student is better than expected: adaptive teacher-student   collaboration for text-conditional diffusion models",
        "abstract": "knowledge distillation methods have recently shown to be a promising direction to speedup the synthesis of large-scale diffusion models by requiring only a few inference steps. while several powerful distillation methods were recently proposed, the overall quality of student samples is typically lower compared to the teacher ones, which hinders their practical usage. in this work, we investigate the relative quality of samples produced by the teacher text-to-image diffusion model and its distilled student version. as our main empirical finding, we discover that a noticeable portion of student samples exhibit superior fidelity compared to the teacher ones, despite the \"approximate\" nature of the student. based on this finding, we propose an adaptive collaboration between student and teacher diffusion models for effective text-to-image synthesis. specifically, the distilled model produces the initial sample, and then an oracle decides whether it needs further improvements with a slow teacher model. extensive experiments demonstrate that the designed pipeline surpasses state-of-the-art text-to-image alternatives for various inference budgets in terms of human preference. furthermore, the proposed approach can be naturally used in popular applications such as text-guided image editing and controllable generation.",
        "doi": "",
        "created": "2023-12-17",
        "url": "https://arxiv.org/abs/2312.10835",
        "authors": [
            "nikita starodubcev",
            "artem fedorov",
            "artem babenko",
            "dmitry baranchuk"
        ]
    },
    {
        "id": "2312.12337",
        "title": "pixelsplat: 3d gaussian splats from image pairs for scalable   generalizable 3d reconstruction",
        "abstract": "we introduce pixelsplat, a feed-forward model that learns to reconstruct 3d radiance fields parameterized by 3d gaussian primitives from pairs of images. our model features real-time and memory-efficient rendering for scalable training as well as fast 3d reconstruction at inference time. to overcome local minima inherent to sparse and locally supported representations, we predict a dense probability distribution over 3d and sample gaussian means from that probability distribution. we make this sampling operation differentiable via a reparameterization trick, allowing us to back-propagate gradients through the gaussian splatting representation. we benchmark our method on wide-baseline novel view synthesis on the real-world realestate10k and acid datasets, where we outperform state-of-the-art light field transformers and accelerate rendering by 2.5 orders of magnitude while reconstructing an interpretable and editable 3d radiance field.",
        "doi": "",
        "created": "2023-12-19",
        "url": "https://arxiv.org/abs/2312.12337",
        "authors": [
            "david charatan",
            "sizhe li",
            "andrea tagliasacchi",
            "vincent sitzmann"
        ]
    },
    {
        "id": "2312.13377",
        "title": "sada: semantic adversarial unsupervised domain adaptation for temporal   action localization",
        "abstract": "temporal action localization (tal) is a complex task that poses relevant challenges, particularly when attempting to generalize on new -- unseen -- domains in real-world applications. these scenarios, despite realistic, are often neglected in the literature, exposing these solutions to important performance degradation. in this work, we tackle this issue by introducing, for the first time, an approach for unsupervised domain adaptation (uda) in sparse tal, which we refer to as semantic adversarial unsupervised domain adaptation (sada). our contributions are threefold: (1) we pioneer the development of a domain adaptation model that operates on realistic sparse action detection benchmarks; (2) we tackle the limitations of global-distribution alignment techniques by introducing a novel adversarial loss that is sensitive to local class distributions, ensuring finer-grained adaptation; and (3) we present a novel set of benchmarks based on epickitchens100 and charadesego, that evaluate multiple domain shifts in a comprehensive manner. our experiments indicate that sada improves the adaptation across domains when compared to fully supervised state-of-the-art and alternative uda methods, attaining a performance boost of up to 6.14% map.",
        "doi": "",
        "created": "2023-12-20",
        "url": "https://arxiv.org/abs/2312.13377",
        "authors": [
            "david pujol-perich",
            "albert clap\u00e9s",
            "sergio escalera"
        ]
    },
    {
        "id": "2312.14239",
        "title": "platonerf: 3d reconstruction in plato's cave via single-view two-bounce   lidar",
        "abstract": "3d reconstruction from a single-view is challenging because of the ambiguity from monocular cues and lack of information about occluded regions. neural radiance fields (nerf), while popular for view synthesis and 3d reconstruction, are typically reliant on multi-view images. existing methods for single-view 3d reconstruction with nerf rely on either data priors to hallucinate views of occluded regions, which may not be physically accurate, or shadows observed by rgb cameras, which are difficult to detect in ambient light and low albedo backgrounds. we propose using time-of-flight data captured by a single-photon avalanche diode to overcome these limitations. our method models two-bounce optical paths with nerf, using lidar transient data for supervision. by leveraging the advantages of both nerf and two-bounce light measured by lidar, we demonstrate that we can reconstruct visible and occluded geometry without data priors or reliance on controlled ambient lighting or scene albedo. in addition, we demonstrate improved generalization under practical constraints on sensor spatial- and temporal-resolution. we believe our method is a promising direction as single-photon lidars become ubiquitous on consumer devices, such as phones, tablets, and headsets.",
        "doi": "",
        "created": "2023-12-21",
        "url": "https://arxiv.org/abs/2312.14239",
        "authors": [
            "tzofi klinghoffer",
            "xiaoyu xiang",
            "siddharth somasundaram",
            "yuchen fan",
            "christian richardt",
            "ramesh raskar",
            "rakesh ranjan"
        ]
    },
    {
        "id": "2312.14264",
        "title": "experimental demonstration of magnetic tunnel junction-based   computational random-access memory",
        "abstract": "conventional computing paradigm struggles to fulfill the rapidly growing demands from emerging applications, especially those for machine intelligence, because much of the power and energy is consumed by constant data transfers between logic and memory modules. a new paradigm, called \"computational random-access memory (cram)\" has emerged to address this fundamental limitation. cram performs logic operations directly using the memory cells themselves, without having the data ever leave the memory. the energy and performance benefits of cram for both conventional and emerging applications have been well established by prior numerical studies. however, there lacks an experimental demonstration and study of cram to evaluate its computation accuracy, which is a realistic and application-critical metrics for its technological feasibility and competitiveness. in this work, a cram array based on magnetic tunnel junctions (mtjs) is experimentally demonstrated. first, basic memory operations as well as 2-, 3-, and 5-input logic operations are studied. then, a 1-bit full adder with two different designs is demonstrated. based on the experimental results, a suite of modeling has been developed to characterize the accuracy of cram computation. further analysis of scalar addition, multiplication, and matrix multiplication shows promising results. these results are then applied to a complete application: a neural network based handwritten digit classifier, as an example to show the connection between the application performance and further mtj development. the classifier achieved almost-perfect classification accuracy, with reasonable projections of future mtj development. with the confirmation of mtj-based cram's accuracy, there is a strong case that this technology will have a significant impact on power- and energy-demanding applications of machine intelligence.",
        "doi": "",
        "created": "2023-12-21",
        "url": "https://arxiv.org/abs/2312.14264",
        "authors": [
            "yang lv",
            "brandon r. zink",
            "robert p. bloom",
            "h\u00fcsrev c\u0131lasun",
            "pravin khanal",
            "salonik resch",
            "zamshed chowdhury",
            "ali habiboglu",
            "weigang wang",
            "sachin s. sapatnekar",
            "ulya karpuzcu",
            "jian-ping wang"
        ]
    },
    {
        "id": "2312.15631",
        "title": "instrumental variables based drem for online asymptotic identification   of perturbed linear systems",
        "abstract": "existing online continuous-time parameter estimation laws provide exact (asymptotic/exponential or finite/fixed time) identification of dynamical linear/nonlinear systems parameters only if the external perturbations are equaled to zero or independent with the regressor of the system. however, in real systems the disturbances are almost always non-vanishing and dependent with the regressor. in the presence of perturbations with such properties the above-mentioned identification approaches ensure only boundedness of a parameter estimation error. the main goal of this study is to close this gap and develop a novel online continuous-time parameter estimator, which guarantees exact asymptotic identification of unknown parameters of linear systems in the presence of unknown but bounded perturbations and has relaxed convergence conditions. to achieve the aforementioned goal, it is proposed to augment the deeply investigated dynamic regressor extension and mixing (drem) procedure with the novel instrumental variables (iv) based extension scheme with averaging. such an approach allows one to obtain a set of scalar regression equations with asymptotically vanishing perturbation if the initial disturbance that affects the plant is bounded and independent not with the system regressor, but with the instrumental variable. it is rigorously proved that a gradient estimation law designed on the basis of such scalar regressions ensures online unbiased asymptotic identification of the parameters of the perturbed linear systems if some weak independence and excitation assumptions are met. theoretical results are illustrated and supported with adequate numerical simulations.",
        "doi": "",
        "created": "2023-12-25",
        "url": "https://arxiv.org/abs/2312.15631",
        "authors": [
            "anton glushchenko",
            "konstantin lastochkin"
        ]
    },
    {
        "id": "2312.16812",
        "title": "spacetime gaussian feature splatting for real-time dynamic view   synthesis",
        "abstract": "novel view synthesis of dynamic scenes has been an intriguing yet challenging problem. despite recent advancements, simultaneously achieving high-resolution photorealistic results, real-time rendering, and compact storage remains a formidable task. to address these challenges, we propose spacetime gaussian feature splatting as a novel dynamic scene representation, composed of three pivotal components. first, we formulate expressive spacetime gaussians by enhancing 3d gaussians with temporal opacity and parametric motion/rotation. this enables spacetime gaussians to capture static, dynamic, as well as transient content within a scene. second, we introduce splatted feature rendering, which replaces spherical harmonics with neural features. these features facilitate the modeling of view- and time-dependent appearance while maintaining small size. third, we leverage the guidance of training error and coarse depth to sample new gaussians in areas that are challenging to converge with existing pipelines. experiments on several established real-world datasets demonstrate that our method achieves state-of-the-art rendering quality and speed, while retaining compact storage. at 8k resolution, our lite-version model can render at 60 fps on an nvidia rtx 4090 gpu. our code is available at https://github.com/oppo-us-research/spacetimegaussians.",
        "doi": "",
        "created": "2023-12-27",
        "url": "https://arxiv.org/abs/2312.16812",
        "authors": [
            "zhan li",
            "zhang chen",
            "zhong li",
            "yi xu"
        ]
    },
    {
        "id": "2312.16862",
        "title": "tinygpt-v: efficient multimodal large language model via small backbones",
        "abstract": "in recent years, multimodal large language models (mllms) such as gpt-4v have demonstrated remarkable advancements, excelling in a variety of vision-language tasks. despite their prowess, the closed-source nature and computational demands of such models limit their accessibility and applicability. this study introduces tinygpt-v, a novel open-source mllm, designed for efficient training and inference across various vision-language tasks, including image captioning (ic) and visual question answering (vqa). leveraging a compact yet powerful architecture, tinygpt-v integrates the phi-2 language model with pre-trained vision encoders, utilizing a unique mapping module for visual and linguistic information fusion. with a training regimen optimized for small backbones and employing a diverse dataset amalgam, tinygpt-v requires significantly lower computational resources 24gb for training and as little as 8gb for inference without compromising on performance. our experiments demonstrate that tinygpt-v, with its language model 2.8 billion parameters, achieves comparable results in vqa and image inference tasks to its larger counterparts while being uniquely suited for deployment on resource-constrained devices through innovative quantization techniques. this work not only paves the way for more accessible and efficient mllms but also underscores the potential of smaller, optimized models in bridging the gap between high performance and computational efficiency in real-world applications. additionally, this paper introduces a new approach to multimodal large language models using smaller backbones. our code and training weights are available in \\url{https://github.com/dlyuangod/tinygpt-v}.",
        "doi": "",
        "created": "2023-12-28",
        "url": "https://arxiv.org/abs/2312.16862",
        "authors": [
            "zhengqing yuan",
            "zhaoxu li",
            "weiran huang",
            "yanfang ye",
            "lichao sun"
        ]
    },
    {
        "id": "2401.00154",
        "title": "aclassihonk: a system framework to annotate and classify vehicular honk   from road traffic",
        "abstract": "recent studies emphasize that vehicular honking contributes to over 50% of noise pollution in developing urban and suburban areas. frequent honking negatively impacts health, road safety, and the environment. recognizing and classifying different vehicle honks could offer valuable insights into environmental noise pollution. existing research on outdoor sound classification and honk detection lacks the ability to classify honks based on vehicle types, limiting contextual information inference for locations, areas, or traffic. therefore, it becomes imperative to design a system that can detect and classify honks of different types of vehicles from which we can infer some contextual information. in this paper, we have developed a novel framework aclassihonk that performs raw vehicular honk sensing, data labeling and classifies the honk into three major groups, i.e., light-weight vehicles, medium-weight vehicles, and heavy-weight vehicles. we collected the raw audio samples of different vehicular honking based on spatio-temporal characteristics and converted them into spectrogram images. we have proposed a deep learning-based multi-label autoencoder model (mae) for automated labeling of the unlabeled data samples, which provides 97.64% accuracy in contrast to existing deep learning-based data labeling methods. further, we have used various pre-trained models, namely inception v3, resnet50, mobilenet, shufflenet, and proposed an ensembled transfer learning model (entl) for vehicle honks classification and performed comparative analysis. results reveal that entl exhibits the best performance compared to pre-trained models and achieves 96.72% accuracy in our dataset. in addition, we have identified a context of a location based on these classified honk signatures in a city.",
        "doi": "",
        "created": "2023-12-30",
        "url": "https://arxiv.org/abs/2401.00154",
        "authors": [
            "biswajit maitya",
            "abdul alima",
            "popuri sree rama charana",
            "amlan chakrabartib",
            "subrata nandia",
            "sanghita bhattacharjeea"
        ]
    },
    {
        "id": "2401.00867",
        "title": "tensor networks for explainable machine learning in cybersecurity",
        "abstract": "in this paper we show how tensor networks help in developing explainability of machine learning algorithms. specifically, we develop an unsupervised clustering algorithm based on matrix product states (mps) and apply it in the context of a real use-case of adversary-generated threat intelligence. our investigation proves that mps rival traditional deep learning models such as autoencoders and gans in terms of performance, while providing much richer model interpretability. our approach naturally facilitates the extraction of feature-wise probabilities, von neumann entropy, and mutual information, offering a compelling narrative for classification of anomalies and fostering an unprecedented level of transparency and interpretability, something fundamental to understand the rationale behind artificial intelligence decisions.",
        "doi": "",
        "created": "2023-12-29",
        "url": "https://arxiv.org/abs/2401.00867",
        "authors": [
            "borja aizpurua",
            "samuel palmer",
            "roman orus"
        ]
    },
    {
        "id": "2401.01598",
        "title": "learning prompt with distribution-based feature replay for few-shot   class-incremental learning",
        "abstract": "few-shot class-incremental learning (fscil) aims to continuously learn new classes based on very limited training data without forgetting the old ones encountered. existing studies solely relied on pure visual networks, while in this paper we solved fscil by leveraging the vision-language model (e.g., clip) and propose a simple yet effective framework, named learning prompt with distribution-based feature replay (lp-dif). we observe that simply using clip for zero-shot evaluation can substantially outperform the most influential methods. then, prompt tuning technique is involved to further improve its adaptation ability, allowing the model to continually capture specific knowledge from each session. to prevent the learnable prompt from forgetting old knowledge in the new session, we propose a pseudo-feature replay approach. specifically, we preserve the old knowledge of each class by maintaining a feature-level gaussian distribution with a diagonal covariance matrix, which is estimated by the image features of training images and synthesized features generated from a vae. when progressing to a new session, pseudo-features are sampled from old-class distributions combined with training images of the current session to optimize the prompt, thus enabling the model to learn new knowledge while retaining old knowledge. experiments on three prevalent benchmarks, i.e., cifar100, mini-imagenet, cub-200, and two more challenging benchmarks, i.e., sun-397 and cub-200$^*$ proposed in this paper showcase the superiority of lp-dif, achieving new state-of-the-art (sota) in fscil. code is publicly available at https://github.com/1170300714/lp-dif.",
        "doi": "",
        "created": "2024-01-03",
        "url": "https://arxiv.org/abs/2401.01598",
        "authors": [
            "zitong huang",
            "ze chen",
            "zhixing chen",
            "erjin zhou",
            "xinxing xu",
            "rick siow mong goh",
            "yong liu",
            "wangmeng zuo",
            "chunmei feng"
        ]
    },
    {
        "id": "2401.01751",
        "title": "text mining arxiv: a look through quantitative finance papers",
        "abstract": "this paper explores articles hosted on the arxiv preprint server with the aim to uncover valuable insights hidden in this vast collection of research. employing text mining techniques and through the application of natural language processing methods, we examine the contents of quantitative finance papers posted in arxiv from 1997 to 2022. we extract and analyze crucial information from the entire documents, including the references, to understand the topics trends over time and to find out the most cited researchers and journals on this domain. additionally, we compare numerous algorithms to perform topic modeling, including state-of-the-art approaches.",
        "doi": "",
        "created": "2024-01-03",
        "url": "https://arxiv.org/abs/2401.01751",
        "authors": [
            "michele leonardo bianchi"
        ]
    },
    {
        "id": "2401.01884",
        "title": "a rewriting-logic-with-smt-based formal analysis and parameter synthesis   framework for parametric time petri nets",
        "abstract": "this paper presents a concrete and a symbolic rewriting logic semantics for parametric time petri nets with inhibitor arcs (pitpns), a flexible model of timed systems where parameters are allowed in firing bounds. we prove that our semantics is bisimilar to the \"standard\" semantics of pitpns. this allows us to use the rewriting logic tool maude, combined with smt solving, to provide sound and complete formal analyses for pitpns. we develop and implement a new general folding approach for symbolic reachability, so that maude-with-smt reachability analysis terminates whenever the parametric state-class graph of the pitpn is finite. our work opens up the possibility of using the many formal analysis capabilities of maude -- including full ltl model checking, analysis with user-defined analysis strategies, and even statistical model checking -- for such nets. we illustrate this by explaining how almost all formal analysis and parameter synthesis methods supported by the state-of-the-art pitpn tool romeo can be performed using maude with smt. in addition, we also support analysis and parameter synthesis from parametric initial markings, as well as full ltl model checking and analysis with user-defined execution strategies. experiments show that our methods outperform romeo in many cases.",
        "doi": "",
        "created": "2024-01-03",
        "url": "https://arxiv.org/abs/2401.01884",
        "authors": [
            "jaime arias",
            "kyungmin bae",
            "carlos olarte",
            "peter csaba \u00f6lveczky",
            "laure petrucci"
        ]
    },
    {
        "id": "2401.02723",
        "title": "predicting traffic flow with federated learning and graph neural with   asynchronous computations network",
        "abstract": "real-time traffic flow prediction holds significant importance within the domain of intelligent transportation systems (its). the task of achieving a balance between prediction precision and computational efficiency presents a significant challenge. in this article, we present a novel deep-learning method called federated learning and asynchronous graph convolutional network (flagcn). our framework incorporates the principles of asynchronous graph convolutional networks with federated learning to enhance the accuracy and efficiency of real-time traffic flow prediction. the flagcn model employs a spatial-temporal graph convolution technique to asynchronously address spatio-temporal dependencies within traffic data effectively. to efficiently handle the computational requirements associated with this deep learning model, this study used a graph federated learning technique known as graphfl. this approach is designed to facilitate the training process. the experimental results obtained from conducting tests on two distinct traffic datasets demonstrate that the utilization of flagcn leads to the optimization of both training and inference durations while maintaining a high level of prediction accuracy. flagcn outperforms existing models with significant improvements by achieving up to approximately 6.85% reduction in rmse, 20.45% reduction in mape, compared to the best-performing existing models.",
        "doi": "",
        "created": "2024-01-05",
        "url": "https://arxiv.org/abs/2401.02723",
        "authors": [
            "muhammad yaqub",
            "shahzad ahmad",
            "malik abdul manan",
            "imran shabir chuhan"
        ]
    },
    {
        "id": "2401.02972",
        "title": "ree-hdsc: recognizing extracted entities for the historical database   suriname curacao",
        "abstract": "we describe the project ree-hdsc and outline our efforts to improve the quality of named entities extracted automatically from texts generated by hand-written text recognition (htr) software. we describe a six-step processing pipeline and test it by processing 19th and 20th century death certificates from the civil registry of curacao. we find that the pipeline extracts dates with high precision but that the precision of person name extraction is low. next we show how name precision extraction can be improved by retraining htr models with names, post-processing and by identifying and removing incorrect names.",
        "doi": "",
        "created": "2023-12-19",
        "url": "https://arxiv.org/abs/2401.02972",
        "authors": [
            "erik tjong kim sang"
        ]
    },
    {
        "id": "2401.03167",
        "title": "posdiffnet: positional neural diffusion for point cloud registration in   a large field of view with perturbations",
        "abstract": "point cloud registration is a crucial technique in 3d computer vision with a wide range of applications. however, this task can be challenging, particularly in large fields of view with dynamic objects, environmental noise, or other perturbations. to address this challenge, we propose a model called posdiffnet. our approach performs hierarchical registration based on window-level, patch-level, and point-level correspondence. we leverage a graph neural partial differential equation (pde) based on beltrami flow to obtain high-dimensional features and position embeddings for point clouds. we incorporate position embeddings into a transformer module based on a neural ordinary differential equation (ode) to efficiently represent patches within points. we employ the multi-level correspondence derived from the high feature similarity scores to facilitate alignment between point clouds. subsequently, we use registration methods such as svd-based algorithms to predict the transformation using corresponding point pairs. we evaluate posdiffnet on several 3d point cloud datasets, verifying that it achieves state-of-the-art (sota) performance for point cloud registration in large fields of view with perturbations. the implementation code of experiments is available at https://github.com/ai-it-avs/posdiffnet.",
        "doi": "10.1609/aaai.v38i1.27775",
        "created": "2024-01-06",
        "url": "https://arxiv.org/abs/2401.03167",
        "authors": [
            "rui she",
            "sijie wang",
            "qiyu kang",
            "kai zhao",
            "yang song",
            "wee peng tay",
            "tianyu geng",
            "xingchao jian"
        ]
    },
    {
        "id": "2401.03629",
        "title": "ddm-lag : a diffusion-based decision-making model for autonomous   vehicles with lagrangian safety enhancement",
        "abstract": "decision-making stands as a pivotal component in the realm of autonomous vehicles (avs), playing a crucial role in navigating the intricacies of autonomous driving. amidst the evolving landscape of data-driven methodologies, enhancing decision-making performance in complex scenarios has emerged as a prominent research focus. despite considerable advancements, current learning-based decision-making approaches exhibit potential for refinement, particularly in aspects of policy articulation and safety assurance. to address these challenges, we introduce ddm-lag, a diffusion decision model, augmented with lagrangian-based safety enhancements. this work conceptualizes the sequential decision-making challenge inherent in autonomous driving as a problem of generative modeling, adopting diffusion models as the medium for assimilating patterns of decision-making. we introduce a hybrid policy update strategy for diffusion models, amalgamating the principles of behavior cloning and q-learning, alongside the formulation of an actor-critic architecture for the facilitation of updates. to augment the model's exploration process with a layer of safety, we incorporate additional safety constraints, employing a sophisticated policy optimization technique predicated on lagrangian relaxation to refine the policy learning endeavor comprehensively. empirical evaluation of our proposed decision-making methodology was conducted across a spectrum of driving tasks, distinguished by their varying degrees of complexity and environmental contexts. the comparative analysis with established baseline methodologies elucidates our model's superior performance, particularly in dimensions of safety and holistic efficacy.",
        "doi": "",
        "created": "2024-01-07",
        "url": "https://arxiv.org/abs/2401.03629",
        "authors": [
            "jiaqi liu",
            "peng hang",
            "xiaocong zhao",
            "jianqiang wang",
            "jian sun"
        ]
    },
    {
        "id": "2401.08822",
        "title": "an empirical study of counterfactual visualization to support visual   causal inference",
        "abstract": "counterfactuals -- expressing what might have been true under different circumstances -- have been widely applied in statistics and machine learning to help understand causal relationships. more recently, counterfactuals have begun to emerge as a technique being applied within visualization research. however, it remains unclear to what extent counterfactuals can aid with visual data communication. in this paper, we primarily focus on assessing the quality of users' understanding of data when provided with counterfactual visualizations. we propose a preliminary model of causality comprehension by connecting theories from causal inference and visual data communication. leveraging this model, we conducted an empirical study to explore how counterfactuals can improve users' understanding of data in static visualizations. our results indicate that visualizing counterfactuals had a positive impact on participants' interpretations of causal relations within datasets. these results motivate a discussion of how to more effectively incorporate counterfactuals into data visualizations.",
        "doi": "10.1177/14738716241229437",
        "created": "2024-01-16",
        "url": "https://arxiv.org/abs/2401.08822",
        "authors": [
            "arran zeyu wang",
            "david borland",
            "david gotz"
        ]
    },
    {
        "id": "2401.10703",
        "title": "drat proofs of unsatisfiability for sat modulo monotonic theories",
        "abstract": "generating proofs of unsatisfiability is a valuable capability of most sat solvers, and is an active area of research for smt solvers. this paper introduces the first method to efficiently generate proofs of unsatisfiability specifically for an important subset of smt: sat modulo monotonic theories (smmt), which includes many useful finite-domain theories (e.g., bit vectors and many graph-theoretic properties) and is used in production at amazon web services. our method uses propositional definitions of the theory predicates, from which it generates compact horn approximations of the definitions, which lead to efficient drat proofs, leveraging the large investment the sat community has made in drat. in experiments on practical smmt problems, our proof generation overhead is minimal (7.41% geometric mean slowdown, 28.8% worst-case), and we can generate and check proofs for many problems that were previously intractable.",
        "doi": "",
        "created": "2024-01-19",
        "url": "https://arxiv.org/abs/2401.10703",
        "authors": [
            "nick feng",
            "alan j. hu",
            "sam bayless",
            "syed m. iqbal",
            "patrick trentin",
            "mike whalen",
            "lee pike",
            "john backes"
        ]
    },
    {
        "id": "2401.11254",
        "title": "the great ban: efficacy and unintended consequences of a massive   deplatforming operation on reddit",
        "abstract": "in the current landscape of online abuses and harms, effective content moderation is necessary to cultivate safe and inclusive online spaces. yet, the effectiveness of many moderation interventions is still unclear. here, we assess the effectiveness of the great ban, a massive deplatforming operation that affected nearly 2,000 communities on reddit. by analyzing 16m comments posted by 17k users during 14 months, we provide nuanced results on the effects, both desired and otherwise, of the ban. among our main findings is that 15.6% of the affected users left reddit and that those who remained reduced their toxicity by 6.6% on average. the ban also caused 5% users to increase their toxicity by more than 70% of their pre-ban level. overall, our multifaceted results provide new insights into the efficacy of deplatforming. as such, our findings can inform the development of future moderation interventions and the policing of online platforms.",
        "doi": "",
        "created": "2024-01-20",
        "url": "https://arxiv.org/abs/2401.11254",
        "authors": [
            "lorenzo cima",
            "amaury trujillo",
            "marco avvenuti",
            "stefano cresci"
        ]
    },
    {
        "id": "2401.11610",
        "title": "note on k-planar and min-k-planar drawings of graphs",
        "abstract": "the k-planar graphs, which are (usually with small values of k such as 1, 2, 3) subject to recent intense research, admit a drawing in which edges are allowed to cross, but each one edge is allowed to carry at most k crossings. in recently introduced [binucci et al., gd 2023] min-k-planar drawings of graphs, edges may possibly carry more than k crossings, but in any two crossing edges, at least one of the two must have at most k crossings. in both concepts, one may consider general drawings or a popular restricted concept of drawings called simple (sometimes also `good'). in a simple drawing, every two edges are allowed to cross at most once, and any two edges which share a vertex are forbidden to cross. while, regarding the former concept, it is for k<=3 known (but not widely known) that every general k-planar graph admits a simple k-planar drawing and this ceases to be true for any k>=4, the difference between general and simple drawings in the latter concept is more striking. we prove that graphs with a min-k-planar drawing but no simple min-k-planar drawing exist for every k>=2, and for every k>=3 there even is a graph with a min-3-planar drawing but no simple min-k-planar drawing.",
        "doi": "",
        "created": "2024-01-21",
        "url": "https://arxiv.org/abs/2401.11610",
        "authors": [
            "petr hlin\u011bn\u00fd"
        ]
    },
    {
        "id": "2401.14295",
        "title": "demystifying chains, trees, and graphs of thoughts",
        "abstract": "the field of natural language processing (nlp) has witnessed significant progress in recent years, with a notable focus on improving large language models' (llm) performance through innovative prompting techniques. among these, prompt engineering coupled with structures has emerged as a promising paradigm, with designs such as chain-of-thought, tree of thoughts, or graph of thoughts, in which the overall llm reasoning is guided by a structure such as a graph. as illustrated with numerous examples, this paradigm significantly enhances the llm's capability to solve numerous tasks, ranging from logical or mathematical reasoning to planning or creative writing. to facilitate the understanding of this growing field and pave the way for future developments, we devise a general blueprint for effective and efficient llm reasoning schemes. for this, we conduct an in-depth analysis of the prompt execution pipeline, clarifying and clearly defining different concepts. we then build the first taxonomy of structure-enhanced llm reasoning schemes. we focus on identifying fundamental classes of harnessed structures, and we analyze the representations of these structures, algorithms executed with these structures, and many others. we refer to these structures as reasoning topologies, because their representation becomes to a degree spatial, as they are contained within the llm context. our study compares existing prompting schemes using the proposed taxonomy, discussing how certain design choices lead to different patterns in performance and cost. we also outline theoretical underpinnings, relationships between prompting and other parts of the llm ecosystem such as knowledge bases, and the associated research challenges. our work will help to advance future prompt engineering techniques.",
        "doi": "",
        "created": "2024-01-25",
        "url": "https://arxiv.org/abs/2401.14295",
        "authors": [
            "maciej besta",
            "florim memedi",
            "zhenyu zhang",
            "robert gerstenberger",
            "guangyuan piao",
            "nils blach",
            "piotr nyczyk",
            "marcin copik",
            "grzegorz kwa\u015bniewski",
            "j\u00fcrgen m\u00fcller",
            "lukas gianinazzi",
            "ales kubicek",
            "hubert niewiadomski",
            "aidan o'mahony",
            "onur mutlu",
            "torsten hoefler"
        ]
    },
    {
        "id": "2401.15587",
        "title": "hyperedge interaction-aware hypergraph neural network",
        "abstract": "hypergraphs provide an effective modeling approach for modeling high-order relationships in many real-world datasets. to capture such complex relationships, several hypergraph neural networks have been proposed for learning hypergraph structure, which propagate information from nodes to hyperedges and then from hyperedges back to nodes. however, most existing methods focus on information propagation between hyperedges and nodes, neglecting the interactions among hyperedges themselves. in this paper, we propose heihnn, a hyperedge interaction-aware hypergraph neural network, which captures the interactions among hyperedges during the convolution process and introduce a novel mechanism to enhance information flow between hyperedges and nodes. specifically, heihnn integrates the interactions between hyperedges into the hypergraph convolution by constructing a three-stage information propagation process. after propagating information from nodes to hyperedges, we introduce a hyperedge-level convolution to update the hyperedge embeddings. finally, the embeddings that capture rich information from the interaction among hyperedges will be utilized to update the node embeddings. additionally, we introduce a hyperedge outlier removal mechanism in the information propagation stages between nodes and hyperedges, which dynamically adjusts the hypergraph structure using the learned embeddings, effectively removing outliers. extensive experiments conducted on real-world datasets show the competitive performance of heihnn compared with state-of-the-art methods.",
        "doi": "",
        "created": "2024-01-28",
        "url": "https://arxiv.org/abs/2401.15587",
        "authors": [
            "rongping ye",
            "xiaobing pei",
            "haoran yang",
            "ruiqi wang"
        ]
    },
    {
        "id": "2402.00157",
        "title": "large language models for mathematical reasoning: progresses and   challenges",
        "abstract": "mathematical reasoning serves as a cornerstone for assessing the fundamental cognitive capabilities of human intelligence. in recent times, there has been a notable surge in the development of large language models (llms) geared towards the automated resolution of mathematical problems. however, the landscape of mathematical problem types is vast and varied, with llm-oriented techniques undergoing evaluation across diverse datasets and settings. this diversity makes it challenging to discern the true advancements and obstacles within this burgeoning field. this survey endeavors to address four pivotal dimensions: i) a comprehensive exploration of the various mathematical problems and their corresponding datasets that have been investigated; ii) an examination of the spectrum of llm-oriented techniques that have been proposed for mathematical problem-solving; iii) an overview of factors and concerns affecting llms in solving math; and iv) an elucidation of the persisting challenges within this domain. to the best of our knowledge, this survey stands as one of the first extensive examinations of the landscape of llms in the realm of mathematics, providing a holistic perspective on the current state, accomplishments, and future challenges in this rapidly evolving field.",
        "doi": "",
        "created": "2024-01-31",
        "url": "https://arxiv.org/abs/2402.00157",
        "authors": [
            "janice ahn",
            "rishu verma",
            "renze lou",
            "di liu",
            "rui zhang",
            "wenpeng yin"
        ]
    },
    {
        "id": "2402.01059",
        "title": "eco-driving under localization uncertainty for connected vehicles on   urban roads: data-driven approach and experiment verification",
        "abstract": "this paper addresses the eco-driving problem for connected vehicles on urban roads, considering localization uncertainty. eco-driving is defined as longitudinal speed planning and control on roads with the presence of a sequence of traffic lights. we solve the problem by using a data-driven model predictive control (mpc) strategy. this approach involves learning a cost-to-go function and constraints from state-input data. the cost-to-go function represents the remaining energy-to-spend from the given state, and the constraints ensure that the controlled vehicle passes the upcoming traffic light timely while obeying traffic laws. the resulting convex optimization problem has a short horizon and is amenable for real-time implementations. we demonstrate the effectiveness of our approach through real-world vehicle experiments. our method demonstrates $12\\%$ improvement in energy efficiency compared to the traditional approaches, which plan longitudinal speed by solving a long-horizon optimal control problem and track the planned speed using another controller, as evidenced by vehicle experiments.",
        "doi": "",
        "created": "2024-02-01",
        "url": "https://arxiv.org/abs/2402.01059",
        "authors": [
            "eunhyek joa",
            "eric yongkeun choi",
            "francesco borrelli"
        ]
    },
    {
        "id": "2402.01740",
        "title": "compensatory biases under cognitive load: reducing selection bias in   large language models",
        "abstract": "large language models (llms) like gpt-3.5-turbo and claude-instant-1.2 have become instrumental in interpreting and executing semantic-based tasks. unfortunately, these models' inherent biases, akin to human cognitive biases, adversely affect their performance. particularly affected is object selection from lists; a fundamental operation in digital navigation and decision-making. this research critically examines these biases and quantifies the effects on a representative list selection task. to explore these biases, we conducted a series of controlled experiments, manipulating temperature, list length, object identity, object type, prompt complexity, and model. this enabled us to isolate and measure the influence of the biases on selection behavior. our findings show that bias structure is strongly dependent on the model, with object type modulating the magnitude of the effect. with a strong primacy effect, causing the first objects in a list to be disproportionately represented in outputs. furthermore the usage of guard rails, a prompt engineering method of ensuring a response structure, can increase bias and decrease instruction adherence when combined with a selection task. the bias is ablated when the guard rail step is separated from the list sampling step, lowering the complexity of each individual task. the implications of this research are two-fold, practically providing a guide for designing unbiased llm applications and theoretically suggesting that llms experience a form of cognitive load compensated for by increasing bias.",
        "doi": "",
        "created": "2024-01-29",
        "url": "https://arxiv.org/abs/2402.01740",
        "authors": [
            "j. e. eicher",
            "r. f. irgoli\u010d"
        ]
    },
    {
        "id": "2402.01779",
        "title": "plug-and-play image restoration with stochastic denoising regularization",
        "abstract": "plug-and-play (pnp) algorithms are a class of iterative algorithms that address image inverse problems by combining a physical model and a deep neural network for regularization. even if they produce impressive image restoration results, these algorithms rely on a non-standard use of a denoiser on images that are less and less noisy along the iterations, which contrasts with recent algorithms based on diffusion models (dm), where the denoiser is applied only on re-noised images. we propose a new pnp framework, called stochastic denoising regularization (snore), which applies the denoiser only on images with noise of the adequate level. it is based on an explicit stochastic regularization, which leads to a stochastic gradient descent algorithm to solve ill-posed inverse problems. a convergence analysis of this algorithm and its annealing extension is provided. experimentally, we prove that snore is competitive with respect to state-of-the-art methods on deblurring and inpainting tasks, both quantitatively and qualitatively.",
        "doi": "",
        "created": "2024-02-01",
        "url": "https://arxiv.org/abs/2402.01779",
        "authors": [
            "marien renaud",
            "jean prost",
            "arthur leclaire",
            "nicolas papadakis"
        ]
    },
    {
        "id": "2402.02081",
        "title": "risk-sensitive diffusion for perturbation-robust optimization",
        "abstract": "the essence of score-based generative models (sgm) is to optimize a score-based model towards the score function. however, we show that noisy samples incur another objective function, rather than the one with score function, which will wrongly optimize the model. to address this problem, we first consider a new setting where every noisy sample is paired with a risk vector, indicating the data quality (e.g., noise level). this setting is very common in real-world applications, especially for medical and sensor data. then, we introduce risk-sensitive sde, a type of stochastic differential equation (sde) parameterized by the risk vector. with this tool, we aim to minimize a measure called perturbation instability, which we define to quantify the negative impact of noisy samples on optimization. we will prove that zero instability measure is only achievable in the case where noisy samples are caused by gaussian perturbation. for non-gaussian cases, we will also provide its optimal coefficients that minimize the misguidance of noisy samples. to apply risk-sensitive sde in practice, we extend widely used diffusion models to their risk-sensitive versions and derive a risk-free loss that is efficient for computation. we also have conducted numerical experiments to confirm the validity of our theorems and show that they let sgm be robust to noisy samples for optimization.",
        "doi": "",
        "created": "2024-02-03",
        "url": "https://arxiv.org/abs/2402.02081",
        "authors": [
            "yangming li",
            "max ruiz luyten",
            "mihaela van der schaar"
        ]
    },
    {
        "id": "2402.03165",
        "title": "risk-aware mpc for stochastic systems with runtime temporal logics",
        "abstract": "this paper concerns the risk-aware control of stochastic systems with temporal logic specifications dynamically assigned during runtime. conventional risk-aware control typically assumes that all specifications are predefined and remain unchanged during runtime. in this paper, we propose a novel, provably correct model predictive control scheme for linear systems with additive unbounded stochastic disturbances that dynamically evaluates the feasibility of runtime signal temporal logic specifications and automatically reschedules the control inputs accordingly. the control method guarantees the probabilistic satisfaction of newly accepted specifications without sacrificing the satisfaction of the previously accepted ones. the proposed control method is validated by a robotic motion planning case study.",
        "doi": "",
        "created": "2024-02-05",
        "url": "https://arxiv.org/abs/2402.03165",
        "authors": [
            "maico h. w. engelaar",
            "zengjie zhang",
            "mircea lazar",
            "sofie haesaert"
        ]
    },
    {
        "id": "2402.03891",
        "title": "control-flow refinement for probabilistic programs in koat",
        "abstract": "recently, we showed how to use control-flow refinement (cfr) to improve automatic complexity analysis of integer programs. while up to now cfr was limited to classical programs, in this paper we extend cfr to probabilistic programs and show its soundness for complexity analysis. to demonstrate its benefits, we implemented our new cfr technique in our complexity analysis tool koat.",
        "doi": "",
        "created": "2024-02-06",
        "url": "https://arxiv.org/abs/2402.03891",
        "authors": [
            "nils lommen",
            "\u00e9l\u00e9anore meyer",
            "j\u00fcrgen giesl"
        ]
    },
    {
        "id": "2402.04520",
        "title": "on computational limits of modern hopfield models: a fine-grained   complexity analysis",
        "abstract": "we investigate the computational limits of the memory retrieval dynamics of modern hopfield models from the fine-grained complexity analysis. our key contribution is the characterization of a phase transition behavior in the efficiency of all possible modern hopfield models based on the norm of patterns. specifically, we establish an upper bound criterion for the norm of input query patterns and memory patterns. only below this criterion, sub-quadratic (efficient) variants of the modern hopfield model exist, assuming the strong exponential time hypothesis (seth). to showcase our theory, we provide a formal example of efficient constructions of modern hopfield models using low-rank approximation when the efficient criterion holds. this includes a derivation of a lower bound on the computational time, scaling linearly with $\\max\\{$\\# of stored memory patterns, length of input query sequence$\\}$. in addition, we prove its memory retrieval error bound and exponential memory capacity.",
        "doi": "",
        "created": "2024-02-06",
        "url": "https://arxiv.org/abs/2402.04520",
        "authors": [
            "jerry yao-chieh hu",
            "thomas lin",
            "zhao song",
            "han liu"
        ]
    },
    {
        "id": "2402.06132",
        "title": "tetris: towards exploring the robustness of interactive segmentation",
        "abstract": "interactive segmentation methods rely on user inputs to iteratively update the selection mask. a click specifying the object of interest is arguably the most simple and intuitive interaction type, and thereby the most common choice for interactive segmentation. however, user clicking patterns in the interactive segmentation context remain unexplored. accordingly, interactive segmentation evaluation strategies rely more on intuition and common sense rather than empirical studies (e.g., assuming that users tend to click in the center of the area with the largest error). in this work, we conduct a real user study to investigate real user clicking patterns. this study reveals that the intuitive assumption made in the common evaluation strategy may not hold. as a result, interactive segmentation models may show high scores in the standard benchmarks, but it does not imply that they would perform well in a real world scenario. to assess the applicability of interactive segmentation methods, we propose a novel evaluation strategy providing a more comprehensive analysis of a model's performance. to this end, we propose a methodology for finding extreme user inputs by a direct optimization in a white-box adversarial attack on the interactive segmentation model. based on the performance with such adversarial user inputs, we assess the robustness of interactive segmentation models w.r.t click positions. besides, we introduce a novel benchmark for measuring the robustness of interactive segmentation, and report the results of an extensive evaluation of dozens of models.",
        "doi": "10.1609/aaai.v38i5.28225",
        "created": "2024-02-08",
        "url": "https://arxiv.org/abs/2402.06132",
        "authors": [
            "andrey moskalenko",
            "vlad shakhuro",
            "anna vorontsova",
            "anton konushin",
            "anton antonov",
            "alexander krapukhin",
            "denis shepelev",
            "konstantin soshin"
        ]
    },
    {
        "id": "2402.06646",
        "title": "diffusion model-based probabilistic downscaling for 180-year east asian   climate reconstruction",
        "abstract": "as our planet is entering into the \"global boiling\" era, understanding regional climate change becomes imperative. effective downscaling methods that provide localized insights are crucial for this target. traditional approaches, including computationally-demanding regional dynamical models or statistical downscaling frameworks, are often susceptible to the influence of downscaling uncertainty. here, we address these limitations by introducing a diffusion probabilistic downscaling model (dpdm) into the meteorological field. this model can efficiently transform data from 1{\\deg} to 0.1{\\deg} resolution. compared with deterministic downscaling schemes, it not only has more accurate local details, but also can generate a large number of ensemble members based on probability distribution sampling to evaluate the uncertainty of downscaling. additionally, we apply the model to generate a 180-year dataset of monthly surface variables in east asia, offering a more detailed perspective for understanding local scale climate change over the past centuries.",
        "doi": "",
        "created": "2024-02-01",
        "url": "https://arxiv.org/abs/2402.06646",
        "authors": [
            "fenghua ling",
            "zeyu lu",
            "jing-jia luo",
            "lei bai",
            "swadhin k. behera",
            "dachao jin",
            "baoxiang pan",
            "huidong jiang",
            "toshio yamagata"
        ]
    },
    {
        "id": "2402.06935",
        "title": "taxonomic classification with maximal exact matches in katka kernels and   minimizer digests",
        "abstract": "for taxonomic classification, we are asked to index the genomes in a phylogenetic tree such that later, given a dna read, we can quickly choose a small subtree likely to contain the genome from which that read was drawn. although popular classifiers such as kraken use $k$-mers, recent research indicates that using maximal exact matches (mems) can lead to better classifications. for example, we can build an augmented fm-index over the the genomes in the tree concatenated in left-to-right order; for each mem in a read, find the interval in the suffix array containing the starting positions of that mem's occurrences in those genomes; find the minimum and maximum values stored in that interval; take the lowest common ancestor (lca) of the genomes containing the characters at those positions. this solution is practical, however, only when the total size of the genomes in the tree is fairly small. in this paper we consider applying the same solution to three lossily compressed representations of the genomes' concatenation: a katka kernel, which discards characters that are not in the first or last occurrence of any $k_{\\max}$-tuple, for a parameter $k_{\\max}$; a minimizer digest; a katka kernel of a minimizer digest. with a test dataset and these three representations of it, simulated reads and various parameter settings, we checked how many reads' longest mems occurred only in the sequences from which those reads were generated (\"true positive\" reads). for some parameter settings we achieved significant compression while only slightly decreasing the true-positive rate.",
        "doi": "",
        "created": "2024-02-10",
        "url": "https://arxiv.org/abs/2402.06935",
        "authors": [
            "dominika draesslerov\u00e1",
            "omar ahmed",
            "travis gagie",
            "jan holub",
            "ben langmead",
            "giovanni manzini",
            "gonzalo navarro"
        ]
    },
    {
        "id": "2402.07087",
        "title": "self-correcting self-consuming loops for generative model training",
        "abstract": "as synthetic data becomes higher quality and proliferates on the internet, machine learning models are increasingly trained on a mix of human- and machine-generated data. despite the successful stories of using synthetic data for representation learning, using synthetic data for generative model training creates \"self-consuming loops\" which may lead to training instability or even collapse, unless certain conditions are met. our paper aims to stabilize self-consuming generative model training. our theoretical results demonstrate that by introducing an idealized correction function, which maps a data point to be more likely under the true data distribution, self-consuming loops can be made exponentially more stable. we then propose self-correction functions, which rely on expert knowledge (e.g. the laws of physics programmed in a simulator), and aim to approximate the idealized corrector automatically and at scale. we empirically validate the effectiveness of self-correcting self-consuming loops on the challenging human motion synthesis task, and observe that it successfully avoids model collapse, even when the ratio of synthetic data to real data is as high as 100%.",
        "doi": "",
        "created": "2024-02-10",
        "url": "https://arxiv.org/abs/2402.07087",
        "authors": [
            "nate gillman",
            "michael freeman",
            "daksh aggarwal",
            "chia-hong hsu",
            "calvin luo",
            "yonglong tian",
            "chen sun"
        ]
    },
    {
        "id": "2402.08787",
        "title": "rethinking machine unlearning for large language models",
        "abstract": "we explore machine unlearning (mu) in the domain of large language models (llms), referred to as llm unlearning. this initiative aims to eliminate undesirable data influence (e.g., sensitive or illegal information) and the associated model capabilities, while maintaining the integrity of essential knowledge generation and not affecting causally unrelated information. we envision llm unlearning becoming a pivotal element in the life-cycle management of llms, potentially standing as an essential foundation for developing generative ai that is not only safe, secure, and trustworthy, but also resource-efficient without the need of full retraining. we navigate the unlearning landscape in llms from conceptual formulation, methodologies, metrics, and applications. in particular, we highlight the often-overlooked aspects of existing llm unlearning research, e.g., unlearning scope, data-model interaction, and multifaceted efficacy assessment. we also draw connections between llm unlearning and related areas such as model editing, influence functions, model explanation, adversarial training, and reinforcement learning. furthermore, we outline an effective assessment framework for llm unlearning and explore its applications in copyright and privacy safeguards and sociotechnical harm reduction.",
        "doi": "",
        "created": "2024-02-13",
        "url": "https://arxiv.org/abs/2402.08787",
        "authors": [
            "sijia liu",
            "yuanshun yao",
            "jinghan jia",
            "stephen casper",
            "nathalie baracaldo",
            "peter hase",
            "xiaojun xu",
            "yuguang yao",
            "hang li",
            "kush r. varshney",
            "mohit bansal",
            "sanmi koyejo",
            "yang liu"
        ]
    },
    {
        "id": "2402.09949",
        "title": "multi-word tokenization for sequence compression",
        "abstract": "large language models have proven highly successful at modelling a variety of tasks. however, this comes at a steep computational cost that hinders wider industrial uptake. in this paper, we present mwt: a multi-word tokenizer that goes beyond word boundaries by representing frequent multi-word expressions as single tokens. mwts produce a more compact and efficient tokenization that yields two benefits: (1) increase in performance due to a greater coverage of input data given a fixed sequence length budget; (2) faster and lighter inference due to the ability to reduce the sequence length with negligible drops in performance. our results show that mwt is more robust across shorter sequence lengths, thus allowing for major speedups via early sequence truncation.",
        "doi": "10.18653/v1/2023.emnlp-industry.58",
        "created": "2024-02-15",
        "url": "https://arxiv.org/abs/2402.09949",
        "authors": [
            "leonidas gee",
            "leonardo rigutini",
            "marco ernandes",
            "andrea zugarini"
        ]
    },
    {
        "id": "2402.10059",
        "title": "partial synchrony for free? new upper bounds for byzantine agreement",
        "abstract": "byzantine agreement allows n processes to decide on a common value, in spite of arbitrary failures. the seminal dolev-reischuk bound states that any deterministic solution to byzantine agreement exchanges omega(n^2) bits. in synchronous networks, solutions with optimal o(n^2) bit complexity, optimal fault tolerance, and no cryptography have been established for over three decades. however, these solutions lack robustness under adverse network conditions. therefore, research has increasingly focused on byzantine agreement for partially synchronous networks. numerous solutions have been proposed for the partially synchronous setting. however, these solutions are notoriously hard to prove correct, and the most efficient cryptography-free algorithms still require o(n^3) exchanged bits in the worst case. in this paper, we introduce oper, the first generic transformation of deterministic byzantine agreement algorithms from synchrony to partial synchrony. oper requires no cryptography, is optimally resilient (n >= 3t+1, where t is the maximum number of failures), and preserves the worst-case per-process bit complexity of the transformed synchronous algorithm. leveraging oper, we present the first partially synchronous byzantine agreement algorithm that (1) achieves optimal o(n^2) bit complexity, (2) requires no cryptography, and (3) is optimally resilient (n >= 3t+1), thus showing that the dolev-reischuk bound is tight even in partial synchrony. moreover, we adapt oper for long values and obtain several new partially synchronous algorithms with improved complexity and weaker (or completely absent) cryptographic assumptions.",
        "doi": "",
        "created": "2024-02-15",
        "url": "https://arxiv.org/abs/2402.10059",
        "authors": [
            "pierre civit",
            "muhammad ayaz dzulfikar",
            "seth gilbert",
            "rachid guerraoui",
            "jovan komatovic",
            "manuel vidigueira",
            "igor zablotchi"
        ]
    },
    {
        "id": "2402.10291",
        "title": "an evaluation of real-time adaptive sampling change point detection   algorithm using kcusum",
        "abstract": "detecting abrupt changes in real-time data streams from scientific simulations presents a challenging task, demanding the deployment of accurate and efficient algorithms. identifying change points in live data stream involves continuous scrutiny of incoming observations for deviations in their statistical characteristics, particularly in high-volume data scenarios. maintaining a balance between sudden change detection and minimizing false alarms is vital. many existing algorithms for this purpose rely on known probability distributions, limiting their feasibility. in this study, we introduce the kernel-based cumulative sum (kcusum) algorithm, a non-parametric extension of the traditional cumulative sum (cusum) method, which has gained prominence for its efficacy in online change point detection under less restrictive conditions. kcusum splits itself by comparing incoming samples directly with reference samples and computes a statistic grounded in the maximum mean discrepancy (mmd) non-parametric framework. this approach extends kcusum's pertinence to scenarios where only reference samples are available, such as atomic trajectories of proteins in vacuum, facilitating the detection of deviations from the reference sample without prior knowledge of the data's underlying distribution. furthermore, by harnessing mmd's inherent random-walk structure, we can theoretically analyze kcusum's performance across various use cases, including metrics like expected delay and mean runtime to false alarms. finally, we discuss real-world use cases from scientific simulations such as nwchem codar and protein folding data, demonstrating kcusum's practical effectiveness in online change point detection.",
        "doi": "",
        "created": "2024-02-15",
        "url": "https://arxiv.org/abs/2402.10291",
        "authors": [
            "vijayalakshmi saravanan",
            "perry siehien",
            "shinjae yoo",
            "hubertus van dam",
            "thomas flynn",
            "christopher kelly",
            "khaled z ibrahim"
        ]
    },
    {
        "id": "2402.10293",
        "title": "parallel play saves quantifiers",
        "abstract": "the number of quantifiers needed to express first-order properties is captured by two-player combinatorial games called multi-structural (ms) games. we play these games on linear orders and strings, and introduce a technique we call \"parallel play\", that dramatically reduces the number of quantifiers needed in many cases. linear orders and strings are the most basic representatives of ordered structures -- a class of structures that has historically been notoriously difficult to analyze. yet, in this paper, we provide upper bounds on the number of quantifiers needed to characterize different-sized subsets of these structures, and prove that they are tight up to constant factors, including, in some cases, up to a factor of $1+\\varepsilon$, for arbitrarily small $\\varepsilon$.",
        "doi": "",
        "created": "2024-02-15",
        "url": "https://arxiv.org/abs/2402.10293",
        "authors": [
            "marco carmosino",
            "ronald fagin",
            "neil immerman",
            "phokion kolaitis",
            "jonathan lenchner",
            "rik sengupta",
            "ryan williams"
        ]
    },
    {
        "id": "2402.11322",
        "title": "spikenas: a fast memory-aware neural architecture search framework for   spiking neural network-based autonomous agents",
        "abstract": "autonomous mobile agents (e.g., uavs and ugvs) are typically expected to incur low power/energy consumption for solving machine learning tasks (such as object recognition), as these mobile agents are usually powered by portable batteries. these requirements can be fulfilled by spiking neural networks (snns), since their bio-inspired spike-based operations offer high accuracy and ultra low-power/energy computation. currently, most of the snn architectures are derived from artificial neural networks whose neurons' architectures and operations are different from snns, or developed without considering memory budgets from the underlying processing hardware of autonomous mobile agents. these limitations hinder snns from reaching their full potential in accuracy and efficiency. toward this, we propose spikenas, a novel fast memory-aware neural architecture search (nas) framework for snns that quickly finds an appropriate snn architecture with high accuracy under the given memory budgets from autonomous mobile agents. to do this, our spikenas employs several key steps: analyzing the impacts of network operations on the accuracy, enhancing the network architecture to improve the learning quality, and developing a fast memory-aware search algorithm. the experimental results show that our spikenas improves the searching time and maintains high accuracy as compared to state-of-the-art while meeting the given memory budgets (e.g., 4.4x faster search with 1.3% accuracy improvement for cifar100, using an nvidia rtx 6000 ada gpu machine), thereby quickly providing the appropriate snn architecture for the memory-constrained autonomous mobile agents.",
        "doi": "",
        "created": "2024-02-17",
        "url": "https://arxiv.org/abs/2402.11322",
        "authors": [
            "rachmad vidya wicaksana putra",
            "muhammad shafique"
        ]
    },
    {
        "id": "2402.11950",
        "title": "a novel molecule generative model of vae combined with transformer for   unseen structure generation",
        "abstract": "recently, molecule generation using deep learning has been actively investigated in drug discovery. in this field, transformer and vae are widely used as powerful models, but they are rarely used in combination due to structural and performance mismatch of them. this study proposes a model that combines these two models through structural and parameter optimization in handling diverse molecules. the proposed model shows comparable performance to existing models in generating molecules, and showed by far superior performance in generating molecules with unseen structures. another advantage of this vae model is that it generates molecules from latent representation, and therefore properties of molecules can be easily predicted or conditioned with it, and indeed, we show that the latent representation of the model successfully predicts molecular properties. ablation study suggested the advantage of vae over other generative models like language model in generating novel molecules. it also indicated that the latent representation can be shortened to ~32 dimensional variables without loss of reconstruction, suggesting the possibility of a much smaller molecular descriptor or model than existing ones. this study is expected to provide a virtual chemical library containing a wide variety of compounds for virtual screening and to enable efficient screening.",
        "doi": "",
        "created": "2024-02-19",
        "url": "https://arxiv.org/abs/2402.11950",
        "authors": [
            "yasuhiro yoshikai",
            "tadahaya mizuno",
            "shumpei nemoto",
            "hiroyuki kusuhara"
        ]
    },
    {
        "id": "2402.12891",
        "title": "mind the exit pupil gap: revisiting the intrinsics of a standard   plenoptic camera",
        "abstract": "among the common applications of plenoptic cameras are depth reconstruction and post-shot refocusing. these require a calibration relating the camera-side light field to that of the scene. numerous methods with this goal have been developed based on thin lens models for the plenoptic camera's main lens and microlenses. our work addresses the often-overlooked role of the main lens exit pupil in these models and specifically in the decoding process of standard plenoptic camera (spc) images. we formally deduce the connection between the refocusing distance and the resampling parameter for the decoded light field and provide an analysis of the errors that arise when the exit pupil is not considered. in addition, previous work is revisited with respect to the exit pupil's role and all theoretical results are validated through a ray-tracing-based simulation. with the public release of the evaluated spc designs alongside our simulation and experimental data we aim to contribute to a more accurate and nuanced understanding of plenoptic camera optics.",
        "doi": "",
        "created": "2024-02-20",
        "url": "https://arxiv.org/abs/2402.12891",
        "authors": [
            "tim michels",
            "daniel m\u00e4ckelmann",
            "reinhard koch"
        ]
    },
    {
        "id": "2402.13917",
        "title": "could we have had better multilingual llms if english was not the   central language?",
        "abstract": "large language models (llms) demonstrate strong machine translation capabilities on languages they are trained on. however, the impact of factors beyond training data size on translation performance remains a topic of debate, especially concerning languages not directly encountered during training. our study delves into llama2's translation capabilities. by modeling a linear relationship between linguistic feature distances and machine translation scores, we ask ourselves if there are potentially better central languages for llms other than english. our experiments show that the 7b llama2 model yields above 10 bleu when translating into all languages it has seen, which rarely happens for languages it has not seen. most translation improvements into unseen languages come from scaling up the model size rather than instruction tuning or increasing shot count. furthermore, our correlation analysis reveals that syntactic similarity is not the only linguistic factor that strongly correlates with machine translation scores. interestingly, we discovered that under specific circumstances, some languages (e.g. swedish, catalan), despite having significantly less training data, exhibit comparable correlation levels to english. these insights challenge the prevailing landscape of llms, suggesting that models centered around languages other than english could provide a more efficient foundation for multilingual applications.",
        "doi": "",
        "created": "2024-02-21",
        "url": "https://arxiv.org/abs/2402.13917",
        "authors": [
            "ryandito diandaru",
            "lucky susanto",
            "zilu tang",
            "ayu purwarianti",
            "derry wijaya"
        ]
    },
    {
        "id": "2402.14493",
        "title": "an improved pseudopolynomial time algorithm for subset sum",
        "abstract": "we investigate pseudo-polynomial time algorithms for subset sum. given a multi-set $x$ of $n$ positive integers and a target $t$, subset sum asks whether some subset of $x$ sums to $t$. bringmann proposes an $\\tilde{o}(n + t)$-time algorithm [bringmann soda'17], and an open question has naturally arisen: can subset sum be solved in $o(n + w)$ time? here $w$ is the maximum integer in $x$. we make a progress towards resolving the open question by proposing an $\\tilde{o}(n + \\sqrt{wt})$-time algorithm.",
        "doi": "",
        "created": "2024-02-22",
        "url": "https://arxiv.org/abs/2402.14493",
        "authors": [
            "lin chen",
            "jiayi lian",
            "yuchen mao",
            "guochuan zhang"
        ]
    },
    {
        "id": "2402.15584",
        "title": "state space models for event cameras",
        "abstract": "today, state-of-the-art deep neural networks that process event-camera data first convert a temporal window of events into dense, grid-like input representations. as such, they exhibit poor generalizability when deployed at higher inference frequencies (i.e., smaller temporal windows) than the ones they were trained on. we address this challenge by introducing state-space models (ssms) with learnable timescale parameters to event-based vision. this design adapts to varying frequencies without the need to retrain the network at different frequencies. additionally, we investigate two strategies to counteract aliasing effects when deploying the model at higher frequencies. we comprehensively evaluate our approach against existing methods based on rnn and transformer architectures across various benchmarks, including gen1 and 1 mpx event camera datasets. our results demonstrate that ssm-based models train 33% faster and also exhibit minimal performance degradation when tested at higher frequencies than the training input. traditional rnn and transformer models exhibit performance drops of more than 20 map, with ssms having a drop of 3.31 map, highlighting the effectiveness of ssms in event-based vision tasks.",
        "doi": "",
        "created": "2024-02-23",
        "url": "https://arxiv.org/abs/2402.15584",
        "authors": [
            "nikola zubi\u0107",
            "mathias gehrig",
            "davide scaramuzza"
        ]
    },
    {
        "id": "2402.19326",
        "title": "generalizable whole slide image classification with fine-grained   visual-semantic interaction",
        "abstract": "whole slide image (wsi) classification is often formulated as a multiple instance learning (mil) problem. recently, vision-language models (vlms) have demonstrated remarkable performance in wsi classification. however, existing methods leverage coarse-grained pathogenetic descriptions for visual representation supervision, which are insufficient to capture the complex visual appearance of pathogenetic images, hindering the generalizability of models on diverse downstream tasks. additionally, processing high-resolution wsis can be computationally expensive. in this paper, we propose a novel \"fine-grained visual-semantic interaction\" (five) framework for wsi classification. it is designed to enhance the model's generalizability by leveraging the interaction between localized visual patterns and fine-grained pathological semantics. specifically, with meticulously designed queries, we start by utilizing a large language model to extract fine-grained pathological descriptions from various non-standardized raw reports. the output descriptions are then reconstructed into fine-grained labels used for training. by introducing a task-specific fine-grained semantics (tfs) module, we enable prompts to capture crucial visual information in wsis, which enhances representation learning and augments generalization capabilities significantly. furthermore, given that pathological visual patterns are redundantly distributed across tissue slices, we sample a subset of visual instances during training. our method demonstrates robust generalizability and strong transferability, dominantly outperforming the counterparts on the tcga lung cancer dataset with at least 9.19% higher accuracy in few-shot experiments. the code is available at: https://github.com/ls1rius/wsi_five.",
        "doi": "",
        "created": "2024-02-29",
        "url": "https://arxiv.org/abs/2402.19326",
        "authors": [
            "hao li",
            "ying chen",
            "yifei chen",
            "wenxian yang",
            "bowen ding",
            "yuchen han",
            "liansheng wang",
            "rongshan yu"
        ]
    },
    {
        "id": "2402.19340",
        "title": "one model to use them all: training a segmentation model with   complementary datasets",
        "abstract": "understanding a surgical scene is crucial for computer-assisted surgery systems to provide any intelligent assistance functionality. one way of achieving this scene understanding is via scene segmentation, where every pixel of a frame is classified and therefore identifies the visible structures and tissues. progress on fully segmenting surgical scenes has been made using machine learning. however, such models require large amounts of annotated training data, containing examples of all relevant object classes. such fully annotated datasets are hard to create, as every pixel in a frame needs to be annotated by medical experts and, therefore, are rarely available. in this work, we propose a method to combine multiple partially annotated datasets, which provide complementary annotations, into one model, enabling better scene segmentation and the use of multiple readily available datasets. our method aims to combine available data with complementary labels by leveraging mutual exclusive properties to maximize information. specifically, we propose to use positive annotations of other classes as negative samples and to exclude background pixels of binary annotations, as we cannot tell if they contain a class not annotated but predicted by the model. we evaluate our method by training a deeplabv3 on the publicly available dresden surgical anatomy dataset, which provides multiple subsets of binary segmented anatomical structures. our approach successfully combines 6 classes into one model, increasing the overall dice score by 4.4% compared to an ensemble of models trained on the classes individually. by including information on multiple classes, we were able to reduce confusion between stomach and colon by 24%. our results demonstrate the feasibility of training a model on multiple datasets. this paves the way for future work further alleviating the need for one large, fully segmented datasets.",
        "doi": "",
        "created": "2024-02-29",
        "url": "https://arxiv.org/abs/2402.19340",
        "authors": [
            "alexander c. jenke",
            "sebastian bodenstedt",
            "fiona r. kolbinger",
            "marius distler",
            "j\u00fcrgen weitz",
            "stefanie speidel"
        ]
    },
    {
        "id": "2403.01265",
        "title": "smooth computation without input delay: robust tube-based model   predictive control for robot manipulator planning",
        "abstract": "model predictive control (mpc) has exhibited remarkable capabilities in optimizing objectives and meeting constraints. however, the substantial computational burden associated with solving the optimal control problem (ocp) at each triggering instant introduces significant delays between state sampling and control application. these delays limit the practicality of mpc in resource-constrained systems when engaging in complex tasks. the intuition to address this issue in this paper is that by predicting the successor state, the controller can solve the ocp one time step ahead of time thus avoiding the delay of the next action. to this end, we compute deviations between real and nominal system states, predicting forthcoming real states as initial conditions for the imminent ocp solution. anticipatory computation stores optimal control based on current nominal states, thus mitigating the delay effects. additionally, we establish an upper bound for linearization error, effectively linearizing the nonlinear system, reducing ocp complexity, and enhancing response speed. we provide empirical validation through two numerical simulations and corresponding real-world robot tasks, demonstrating significant performance improvements and augmented response speed (up to $90\\%$) resulting from the seamless integration of our proposed approach compared to conventional time-triggered mpc strategies.",
        "doi": "",
        "created": "2024-03-02",
        "url": "https://arxiv.org/abs/2403.01265",
        "authors": [
            "yu luo",
            "qie sima",
            "tianyin ji",
            "fuchun sun",
            "huaping liu",
            "jianwei zhang"
        ]
    },
    {
        "id": "2403.01300",
        "title": "causal mode multiplexer: a novel framework for unbiased multispectral   pedestrian detection",
        "abstract": "rgbt multispectral pedestrian detection has emerged as a promising solution for safety-critical applications that require day/night operations. however, the modality bias problem remains unsolved as multispectral pedestrian detectors learn the statistical bias in datasets. specifically, datasets in multispectral pedestrian detection mainly distribute between roto (day) and rxto (night) data; the majority of the pedestrian labels statistically co-occur with their thermal features. as a result, multispectral pedestrian detectors show poor generalization ability on examples beyond this statistical correlation, such as rotx data. to address this problem, we propose a novel causal mode multiplexer (cmm) framework that effectively learns the causalities between multispectral inputs and predictions. moreover, we construct a new dataset (rotx-mp) to evaluate modality bias in multispectral pedestrian detection. rotx-mp mainly includes rotx examples not presented in previous datasets. extensive experiments demonstrate that our proposed cmm framework generalizes well on existing datasets (kaist, cvc-14, flir) and the new rotx-mp. we will release our new dataset to the public for future research.",
        "doi": "",
        "created": "2024-03-02",
        "url": "https://arxiv.org/abs/2403.01300",
        "authors": [
            "taeheon kim",
            "sebin shin",
            "youngjoon yu",
            "hak gu kim",
            "yong man ro"
        ]
    },
    {
        "id": "2403.01439",
        "title": "dynamic adapter meets prompt tuning: parameter-efficient transfer   learning for point cloud analysis",
        "abstract": "point cloud analysis has achieved outstanding performance by transferring point cloud pre-trained models. however, existing methods for model adaptation usually update all model parameters, i.e., full fine-tuning paradigm, which is inefficient as it relies on high computational costs (e.g., training gpu memory) and massive storage space. in this paper, we aim to study parameter-efficient transfer learning for point cloud analysis with an ideal trade-off between task performance and parameter efficiency. to achieve this goal, we freeze the parameters of the default pre-trained models and then propose the dynamic adapter, which generates a dynamic scale for each token, considering the token significance to the downstream task. we further seamlessly integrate dynamic adapter with prompt tuning (dapt) by constructing internal prompts, capturing the instance-specific features for interaction. extensive experiments conducted on five challenging datasets demonstrate that the proposed dapt achieves superior performance compared to the full fine-tuning counterparts while significantly reducing the trainable parameters and training gpu memory by 95% and 35%, respectively. code is available at https://github.com/lmd0311/dapt.",
        "doi": "",
        "created": "2024-03-03",
        "url": "https://arxiv.org/abs/2403.01439",
        "authors": [
            "xin zhou",
            "dingkang liang",
            "wei xu",
            "xingkui zhu",
            "yihan xu",
            "zhikang zou",
            "xiang bai"
        ]
    },
    {
        "id": "2403.01482",
        "title": "eagle: eigen aggregation learning for object-centric unsupervised   semantic segmentation",
        "abstract": "semantic segmentation has innately relied on extensive pixel-level annotated data, leading to the emergence of unsupervised methodologies. among them, leveraging self-supervised vision transformers for unsupervised semantic segmentation (uss) has been making steady progress with expressive deep features. yet, for semantically segmenting images with complex objects, a predominant challenge remains: the lack of explicit object-level semantic encoding in patch-level features. this technical limitation often leads to inadequate segmentation of complex objects with diverse structures. to address this gap, we present a novel approach, eagle, which emphasizes object-centric representation learning for unsupervised semantic segmentation. specifically, we introduce eicue, a spectral technique providing semantic and structural cues through an eigenbasis derived from the semantic similarity matrix of deep image features and color affinity from an image. further, by incorporating our object-centric contrastive loss with eicue, we guide our model to learn object-level representations with intra- and inter-image object-feature consistency, thereby enhancing semantic accuracy. extensive experiments on coco-stuff, cityscapes, and potsdam-3 datasets demonstrate the state-of-the-art uss results of eagle with accurate and consistent semantic segmentation across complex scenes.",
        "doi": "",
        "created": "2024-03-03",
        "url": "https://arxiv.org/abs/2403.01482",
        "authors": [
            "chanyoung kim",
            "woojung han",
            "dayun ju",
            "seong jae hwang"
        ]
    },
    {
        "id": "2403.01628",
        "title": "recent advances, applications, and open challenges in machine learning   for health: reflections from research roundtables at ml4h 2023 symposium",
        "abstract": "the third ml4h symposium was held in person on december 10, 2023, in new orleans, louisiana, usa. the symposium included research roundtable sessions to foster discussions between participants and senior researchers on timely and relevant topics for the \\ac{ml4h} community. encouraged by the successful virtual roundtables in the previous year, we organized eleven in-person roundtables and four virtual roundtables at ml4h 2022. the organization of the research roundtables at the conference involved 17 senior chairs and 19 junior chairs across 11 tables. each roundtable session included invited senior chairs (with substantial experience in the field), junior chairs (responsible for facilitating the discussion), and attendees from diverse backgrounds with interest in the session's topic. herein we detail the organization process and compile takeaways from these roundtable discussions, including recent advances, applications, and open challenges for each topic. we conclude with a summary and lessons learned across all roundtables. this document serves as a comprehensive review paper, summarizing the recent advancements in machine learning for healthcare as contributed by foremost researchers in the field.",
        "doi": "",
        "created": "2024-03-03",
        "url": "https://arxiv.org/abs/2403.01628",
        "authors": [
            "hyewon jeong",
            "sarah jabbour",
            "yuzhe yang",
            "rahul thapta",
            "hussein mozannar",
            "william jongwon han",
            "nikita mehandru",
            "michael wornow",
            "vladislav lialin",
            "xin liu",
            "alejandro lozano",
            "jiacheng zhu",
            "rafal dariusz kocielnik",
            "keith harrigian",
            "haoran zhang",
            "edward lee",
            "milos vukadinovic",
            "aparna balagopalan",
            "vincent jeanselme",
            "katherine matton",
            "ilker demirel",
            "jason fries",
            "parisa rashidi",
            "brett beaulieu-jones",
            "xuhai orson xu",
            "matthew mcdermott",
            "tristan naumann",
            "monica agrawal",
            "marinka zitnik",
            "berk ustun",
            "edward choi",
            "kristen yeom",
            "gamze gursoy",
            "marzyeh ghassemi",
            "emma pierson",
            "george chen",
            "sanjat kanjilal",
            "michael oberst",
            "linying zhang",
            "harvineet singh",
            "tom hartvigsen",
            "helen zhou",
            "chinasa t. okolo"
        ]
    },
    {
        "id": "2403.02972",
        "title": "bodioid: philosophical reflections on the hybrid of bodies and artefacts   towards post-human",
        "abstract": "the advent of the post-human era has blurred the boundary between the body and artefacts. further, external materials and information are more deeply integrated into the body, making emerging technology a key driving force for shaping post-human existence and promoting bodily evolution. based on this, this study analyses the transformation process of three technological forms, namely tools, machines, and cyborgs, and reveals the construction of bodies and artefacts. from the phenomenological perspective, the essences of body and artefact existences are reflected upon, and the 'existence is construction' viewpoint is proposed. furthermore, a technological design concept, 'bodioid', is proposed to meticulously depict the characteristics of integrating similarities and differences towards unity between the body and artefacts, based on the theoretical foundation of technology mediation and the materialization of morality. finally, through analogizing the organizational form of language, the two key forms and specific mechanisms of bodioid construction, namely extension and mirroring, are indicated. with this in mind, the post-human existence landscape is discussed with the objective of providing theoretical insights into the study of the underlying philosophical principles of technological design.",
        "doi": "",
        "created": "2024-03-05",
        "url": "https://arxiv.org/abs/2403.02972",
        "authors": [
            "jiang xu",
            "gang sun",
            "jingyu xu",
            "pujie su"
        ]
    },
    {
        "id": "2403.04460",
        "title": "pearl: a review-driven persona-knowledge grounded conversational   recommendation dataset",
        "abstract": "conversational recommender system is an emerging area that has garnered an increasing interest in the community, especially with the advancements in large language models (llms) that enable diverse reasoning over conversational input. despite the progress, the field has many aspects left to explore. the currently available public datasets for conversational recommendation lack specific user preferences and explanations for recommendations, hindering high-quality recommendations. to address such challenges, we present a novel conversational recommendation dataset named pearl, synthesized with persona- and knowledge-augmented llm simulators. we obtain detailed persona and knowledge from real-world reviews and construct a large-scale dataset with over 57k dialogues. our experimental results demonstrate that utterances in pearl include more specific user preferences, show expertise in the target domain, and provide recommendations more relevant to the dialogue context than those in prior datasets.",
        "doi": "",
        "created": "2024-03-07",
        "url": "https://arxiv.org/abs/2403.04460",
        "authors": [
            "minjin kim",
            "minju kim",
            "hana kim",
            "beong-woo kwak",
            "soyeon chun",
            "hyunseo kim",
            "seongku kang",
            "youngjae yu",
            "jinyoung yeo",
            "dongha lee"
        ]
    },
    {
        "id": "2403.05061",
        "title": "radardistill: boosting radar-based object detection performance via   knowledge distillation from lidar features",
        "abstract": "the inherent noisy and sparse characteristics of radar data pose challenges in finding effective representations for 3d object detection. in this paper, we propose radardistill, a novel knowledge distillation (kd) method, which can improve the representation of radar data by leveraging lidar data. radardistill successfully transfers desirable characteristics of lidar features into radar features using three key components: cross-modality alignment (cma), activation-based feature distillation (afd), and proposal-based feature distillation (pfd). cma enhances the density of radar features by employing multiple layers of dilation operations, effectively addressing the challenge of inefficient knowledge transfer from lidar to radar. afd selectively transfers knowledge based on regions of the lidar features, with a specific focus on areas where activation intensity exceeds a predefined threshold. pfd similarly guides the radar network to selectively mimic features from the lidar network within the object proposals. our comparative analyses conducted on the nuscenes datasets demonstrate that radardistill achieves state-of-the-art (sota) performance for radar-only object detection task, recording 20.5% in map and 43.7% in nds. also, radardistill significantly improves the performance of the camera-radar fusion model.",
        "doi": "",
        "created": "2024-03-08",
        "url": "https://arxiv.org/abs/2403.05061",
        "authors": [
            "geonho bang",
            "kwangjin choi",
            "jisong kim",
            "dongsuk kum",
            "jun won choi"
        ]
    },
    {
        "id": "2403.05855",
        "title": "assessing user apprehensions about mixed reality artifacts and   applications: the mixed reality concerns (mrc) questionnaire",
        "abstract": "current research in mixed reality (mr) presents a wide range of novel use cases for blending virtual elements with the real world. this yet-to-be-ubiquitous technology challenges how users currently work and interact with digital content. while offering many potential advantages, mr technologies introduce new security, safety, and privacy challenges. thus, it is relevant to understand users' apprehensions towards mr technologies, ranging from security concerns to social acceptance. to address this challenge, we present the mixed reality concerns (mrc) questionnaire, designed to assess users' concerns towards mr artifacts and applications systematically. the development followed a structured process considering previous work, expert interviews, iterative refinements, and confirmatory tests to analytically validate the questionnaire. the mrc questionnaire offers a new method of assessing users' critical opinions to compare and assess novel mr artifacts and applications regarding security, privacy, social implications, and trust.",
        "doi": "10.1145/3613904.3642631",
        "created": "2024-03-09",
        "url": "https://arxiv.org/abs/2403.05855",
        "authors": [
            "christopher katins",
            "pawe\u0142 w. wo\u017aniak",
            "aodi chen",
            "ihsan tumay",
            "luu viet trinh le",
            "john uschold",
            "thomas kosch"
        ]
    },
    {
        "id": "2403.05944",
        "title": "model-predictive trajectory generation for autonomous aerial search and   coverage",
        "abstract": "this paper addresses the trajectory planning problem for search and coverage missions with an unmanned aerial vehicle (uav). the objective is to devise optimal coverage trajectories based on a utility map describing prior region information, assumed to be effectively approximated by a gaussian mixture model (gmm). we introduce a model predictive control (mpc) algorithm employing a relaxed formulation that promotes the exploration of the map by preventing the uav from revisiting previously covered areas. this is achieved by penalizing intersections between the uav's visibility regions along its trajectory. the algorithm is assessed in matlab and validated in gazebo, as well as in outdoor experimental tests. the results show that the proposed strategy can generate efficient and smooth trajectories for search and coverage missions.",
        "doi": "",
        "created": "2024-03-09",
        "url": "https://arxiv.org/abs/2403.05944",
        "authors": [
            "hugo matias",
            "daniel silvestre"
        ]
    },
    {
        "id": "2403.06546",
        "title": "omh: structured sparsity via optimally matched hierarchy for   unsupervised semantic segmentation",
        "abstract": "unsupervised semantic segmentation (uss) involves segmenting images without relying on predefined labels, aiming to alleviate the burden of extensive human labeling. existing methods utilize features generated by self-supervised models and specific priors for clustering. however, their clustering objectives are not involved in the optimization of the features during training. additionally, due to the lack of clear class definitions in uss, the resulting segments may not align well with the clustering objective. in this paper, we introduce a novel approach called optimally matched hierarchy (omh) to simultaneously address the above issues. the core of our method lies in imposing structured sparsity on the feature space, which allows the features to encode information with different levels of granularity. the structure of this sparsity stems from our hierarchy (omh). to achieve this, we learn a soft but sparse hierarchy among parallel clusters through optimal transport. our omh yields better unsupervised segmentation performance compared to existing uss methods. our extensive experiments demonstrate the benefits of omh when utilizing our differentiable paradigm. we will make our code publicly available.",
        "doi": "",
        "created": "2024-03-11",
        "url": "https://arxiv.org/abs/2403.06546",
        "authors": [
            "baran ozaydin",
            "tong zhang",
            "deblina bhattacharjee",
            "sabine s\u00fcsstrunk",
            "mathieu salzmann"
        ]
    },
    {
        "id": "2403.06563",
        "title": "unraveling the mystery of scaling laws: part i",
        "abstract": "scaling law principles indicate a power-law correlation between loss and variables such as model size, dataset size, and computational resources utilized during training. these principles play a vital role in optimizing various aspects of model pre-training, ultimately contributing to the success of large language models such as gpt-4, llama and gemini. however, the original scaling law paper by openai did not disclose the complete details necessary to derive the precise scaling law formulas, and their conclusions are only based on models containing up to 1.5 billion parameters. though some subsequent works attempt to unveil these details and scale to larger models, they often neglect the training dependency of important factors such as the learning rate, context length and batch size, leading to their failure to establish a reliable formula for predicting the test loss trajectory. in this technical report, we confirm that the scaling law formulations proposed in the original openai paper remain valid when scaling the model size up to 33 billion, but the constant coefficients in these formulas vary significantly with the experiment setup. we meticulously identify influential factors and provide transparent, step-by-step instructions to estimate all constant terms in scaling-law formulas by training on models with only 1m~60m parameters. using these estimated formulas, we showcase the capability to accurately predict various attributes for models with up to 33b parameters before their training, including (1) the minimum possible test loss; (2) the minimum required training steps and processed tokens to achieve a specific loss; (3) the critical batch size with an optimal time/computation trade-off at any loss value; and (4) the complete test loss trajectory with arbitrary batch size.",
        "doi": "",
        "created": "2024-03-11",
        "url": "https://arxiv.org/abs/2403.06563",
        "authors": [
            "hui su",
            "zhi tian",
            "xiaoyu shen",
            "xunliang cai"
        ]
    },
    {
        "id": "2403.06749",
        "title": "evaluating large language models in process mining: capabilities,   benchmarks, and evaluation strategies",
        "abstract": "using large language models (llms) for process mining (pm) tasks is becoming increasingly essential, and initial approaches yield promising results. however, little attention has been given to developing strategies for evaluating and benchmarking the utility of incorporating llms into pm tasks. this paper reviews the current implementations of llms in pm and reflects on three different questions. 1) what is the minimal set of capabilities required for pm on llms? 2) which benchmark strategies help choose optimal llms for pm? 3) how do we evaluate the output of llms on specific pm tasks? the answer to these questions is fundamental to the development of comprehensive process mining benchmarks on llms covering different tasks and implementation paradigms.",
        "doi": "",
        "created": "2024-03-11",
        "url": "https://arxiv.org/abs/2403.06749",
        "authors": [
            "alessandro berti",
            "humam kourani",
            "hannes hafke",
            "chiao-yun li",
            "daniel schuster"
        ]
    },
    {
        "id": "2403.07721",
        "title": "visual decoding and reconstruction via eeg embeddings with guided   diffusion",
        "abstract": "how to decode human vision through neural signals has attracted a long-standing interest in neuroscience and machine learning. modern contrastive learning and generative models improved the performance of fmri-based visual decoding and reconstruction. however, the high cost and low temporal resolution of fmri limit their applications in brain-computer interfaces (bcis), prompting a high need for eeg-based visual reconstruction. in this study, we present an eeg-based visual reconstruction framework. it consists of a plug-and-play eeg encoder called the adaptive thinking mapper (atm), which is aligned with image embeddings, and a two-stage eeg guidance image generator that first transforms eeg features into image priors and then reconstructs the visual stimuli with a pre-trained image generator. our approach allows eeg embeddings to achieve superior performance in image classification and retrieval tasks. our two-stage image generation strategy vividly reconstructs images seen by humans. furthermore, we analyzed the impact of signals from different time windows and brain regions on decoding and reconstruction. the versatility of our framework is demonstrated in the magnetoencephalogram (meg) data modality. we report that eeg-based visual decoding achieves sota performance, highlighting the portability, low cost, and high temporal resolution of eeg, enabling a wide range of bci applications. the code of atm is available at https://github.com/dongyangli-del/eeg_image_decode.",
        "doi": "",
        "created": "2024-03-12",
        "url": "https://arxiv.org/abs/2403.07721",
        "authors": [
            "dongyang li",
            "chen wei",
            "shiying li",
            "jiachen zou",
            "quanying liu"
        ]
    },
    {
        "id": "2403.09124",
        "title": "single domain generalization for crowd counting",
        "abstract": "due to its promising results, density map regression has been widely employed for image-based crowd counting. the approach, however, often suffers from severe performance degradation when tested on data from unseen scenarios, the so-called \"domain shift\" problem. to address the problem, we investigate in this work single domain generalization (sdg) for crowd counting. the existing sdg approaches are mainly for image classification and segmentation, and can hardly be extended to our case due to its regression nature and label ambiguity (i.e., ambiguous pixel-level ground truths). we propose mpcount, a novel effective sdg approach even for narrow source distribution. mpcount stores diverse density values for density map regression and reconstructs domain-invariant features by means of only one memory bank, a content error mask and attention consistency loss. by partitioning the image into grids, it employs patch-wise classification as an auxiliary task to mitigate label ambiguity. through extensive experiments on different datasets, mpcount is shown to significantly improve counting accuracy compared to the state of the art under diverse scenarios unobserved in the training data characterized by narrow source distribution. code is available at https://github.com/shimmer93/mpcount.",
        "doi": "",
        "created": "2024-03-14",
        "url": "https://arxiv.org/abs/2403.09124",
        "authors": [
            "zhuoxuan peng",
            "s. -h. gary chan"
        ]
    },
    {
        "id": "2403.10167",
        "title": "efficient detection of exchangeable factors in factor graphs",
        "abstract": "to allow for tractable probabilistic inference with respect to domain sizes, lifted probabilistic inference exploits symmetries in probabilistic graphical models. however, checking whether two factors encode equivalent semantics and hence are exchangeable is computationally expensive. in this paper, we efficiently solve the problem of detecting exchangeable factors in a factor graph. in particular, we introduce the detection of exchangeable factors (deft) algorithm, which allows us to drastically reduce the computational effort for checking whether two factors are exchangeable in practice. while previous approaches iterate all $o(n!)$ permutations of a factor's argument list in the worst case (where $n$ is the number of arguments of the factor), we prove that deft efficiently identifies restrictions to drastically reduce the number of permutations and validate the efficiency of deft in our empirical evaluation.",
        "doi": "",
        "created": "2024-03-15",
        "url": "https://arxiv.org/abs/2403.10167",
        "authors": [
            "malte luttermann",
            "johann machemer",
            "marcel gehrke"
        ]
    },
    {
        "id": "2403.10344",
        "title": "scilla: surface implicit learning for large urban area, a volumetric   hybrid solution",
        "abstract": "neural implicit surface representation methods have recently shown impressive 3d reconstruction results. however, existing solutions struggle to reconstruct urban outdoor scenes due to their large, unbounded, and highly detailed nature. hence, to achieve accurate reconstructions, additional supervision data such as lidar, strong geometric priors, and long training times are required. to tackle such issues, we present scilla, a new hybrid implicit surface learning method to reconstruct large driving scenes from 2d images. scilla's hybrid architecture models two separate implicit fields: one for the volumetric density and another for the signed distance to the surface. to accurately represent urban outdoor scenarios, we introduce a novel volume-rendering strategy that relies on self-supervised probabilistic density estimation to sample points near the surface and transition progressively from volumetric to surface representation. our solution permits a proper and fast initialization of the signed distance field without relying on any geometric prior on the scene, compared to concurrent methods. by conducting extensive experiments on four outdoor driving datasets, we show that scilla can learn an accurate and detailed 3d surface scene representation in various urban scenarios while being two times faster to train compared to previous state-of-the-art solutions.",
        "doi": "",
        "created": "2024-03-15",
        "url": "https://arxiv.org/abs/2403.10344",
        "authors": [
            "hala djeghim",
            "nathan piasco",
            "moussab bennehar",
            "luis rold\u00e3o",
            "dzmitry tsishkou",
            "d\u00e9sir\u00e9 sidib\u00e9"
        ]
    },
    {
        "id": "2403.10427",
        "title": "swag: splatting in the wild images with appearance-conditioned gaussians",
        "abstract": "implicit neural representation methods have shown impressive advancements in learning 3d scenes from unstructured in-the-wild photo collections but are still limited by the large computational cost of volumetric rendering. more recently, 3d gaussian splatting emerged as a much faster alternative with superior rendering quality and training efficiency, especially for small-scale and object-centric scenarios. nevertheless, this technique suffers from poor performance on unstructured in-the-wild data. to tackle this, we extend over 3d gaussian splatting to handle unstructured image collections. we achieve this by modeling appearance to seize photometric variations in the rendered images. additionally, we introduce a new mechanism to train transient gaussians to handle the presence of scene occluders in an unsupervised manner. experiments on diverse photo collection scenes and multi-pass acquisition of outdoor landmarks show the effectiveness of our method over prior works achieving state-of-the-art results with improved efficiency.",
        "doi": "",
        "created": "2024-03-15",
        "url": "https://arxiv.org/abs/2403.10427",
        "authors": [
            "hiba dahmani",
            "moussab bennehar",
            "nathan piasco",
            "luis roldao",
            "dzmitry tsishkou"
        ]
    },
    {
        "id": "2403.12199",
        "title": "empirical analysis on ci/cd pipeline evolution in machine learning   projects",
        "abstract": "the growing popularity of machine learning (ml) and the integration of ml components with other software artifacts has led to the use of continuous integration and delivery (ci/cd) tools, such as travis ci, github actions, etc. that enable faster integration and testing for ml projects. such ci/cd configurations and services require synchronization during the life cycle of the projects. several works discussed how ci/cd configuration and services change during their usage in traditional software systems. however, there is very limited knowledge of how ci/cd configuration and services change in ml projects.   to fill this knowledge gap, this work presents the first empirical analysis of how ci/cd configuration evolves for ml software systems. we manually analyzed 343 commits collected from 508 open-source ml projects to identify common ci/cd configuration change categories in ml projects and devised a taxonomy of 14 co-changes in ci/cd and ml components. moreover, we developed a ci/cd configuration change clustering tool that identified frequent ci/cd configuration change patterns in 15,634 commits. furthermore, we measured the expertise of ml developers who modify ci/cd configurations. based on this analysis, we found that 61.8% of commits include a change to the build policy and minimal changes related to performance and maintainability compared to general open-source projects. additionally, the co-evolution analysis identified that ci/cd configurations, in many cases, changed unnecessarily due to bad practices such as the direct inclusion of dependencies and a lack of usage of standardized testing frameworks. more practices were found through the change patterns analysis consisting of using deprecated settings and reliance on a generic build language. finally, our developer's expertise analysis suggests that experienced developers are more inclined to modify ci/cd configurations.",
        "doi": "",
        "created": "2024-03-18",
        "url": "https://arxiv.org/abs/2403.12199",
        "authors": [
            "alaa houerbi",
            "rahul ghanshyam chavan",
            "dhia elhaq rzig",
            "foyzul hassan"
        ]
    },
    {
        "id": "2403.12553",
        "title": "pretraining codomain attention neural operators for solving multiphysics   pdes",
        "abstract": "existing neural operator architectures face challenges when solving multiphysics problems with coupled partial differential equations (pdes), due to complex geometries, interactions between physical variables, and the lack of large amounts of high-resolution training data. to address these issues, we propose codomain attention neural operator (coda-no), which tokenizes functions along the codomain or channel space, enabling self-supervised learning or pretraining of multiple pde systems. specifically, we extend positional encoding, self-attention, and normalization layers to the function space. coda-no can learn representations of different pde systems with a single model. we evaluate coda-no's potential as a backbone for learning multiphysics pdes over multiple systems by considering few-shot learning settings. on complex downstream tasks with limited data, such as fluid flow simulations and fluid-structure interactions, we found coda-no to outperform existing methods on the few-shot learning task by over $36\\%$. the code is available at https://github.com/ashiq24/coda-no.",
        "doi": "",
        "created": "2024-03-19",
        "url": "https://arxiv.org/abs/2403.12553",
        "authors": [
            "md ashiqur rahman",
            "robert joseph george",
            "mogab elleithy",
            "daniel leibovici",
            "zongyi li",
            "boris bonev",
            "colin white",
            "julius berner",
            "raymond a. yeh",
            "jean kossaifi",
            "kamyar azizzadenesheli",
            "anima anandkumar"
        ]
    },
    {
        "id": "2403.12686",
        "title": "watervg: waterway visual grounding based on text-guided vision and   mmwave radar",
        "abstract": "the perception of waterways based on human intent is significant for autonomous navigation and operations of unmanned surface vehicles (usvs) in water environments. inspired by visual grounding, we introduce watervg, the first visual grounding dataset designed for usv-based waterway perception based on human prompts. watervg encompasses prompts describing multiple targets, with annotations at the instance level including bounding boxes and masks. notably, watervg includes 11,568 samples with 34,987 referred targets, whose prompts integrates both visual and radar characteristics. the pattern of text-guided two sensors equips a finer granularity of text prompts with visual and radar features of referred targets. moreover, we propose a low-power visual grounding model, potamoi, which is a multi-task model with a well-designed phased heterogeneous modality fusion (phmf) mode, including adaptive radar weighting (arw) and multi-head slim cross attention (mhsca). exactly, arw extracts required radar features to fuse with vision for prompt alignment. mhsca is an efficient fusion module with a remarkably small parameter count and flops, elegantly fusing scenario context captured by two sensors with linguistic features, which performs expressively on visual grounding tasks. comprehensive experiments and evaluations have been conducted on watervg, where our potamoi archives state-of-the-art performances compared with counterparts.",
        "doi": "",
        "created": "2024-03-19",
        "url": "https://arxiv.org/abs/2403.12686",
        "authors": [
            "runwei guan",
            "liye jia",
            "fengyufan yang",
            "shanliang yao",
            "erick purwanto",
            "xiaohui zhu",
            "eng gee lim",
            "jeremy smith",
            "ka lok man",
            "xuming hu",
            "yutao yue"
        ]
    },
    {
        "id": "2403.13793",
        "title": "evaluating frontier models for dangerous capabilities",
        "abstract": "to understand the risks posed by a new ai system, we must understand what it can and cannot do. building on prior work, we introduce a programme of new \"dangerous capability\" evaluations and pilot them on gemini 1.0 models. our evaluations cover four areas: (1) persuasion and deception; (2) cyber-security; (3) self-proliferation; and (4) self-reasoning. we do not find evidence of strong dangerous capabilities in the models we evaluated, but we flag early warning signs. our goal is to help advance a rigorous science of dangerous capability evaluation, in preparation for future models.",
        "doi": "",
        "created": "2024-03-20",
        "url": "https://arxiv.org/abs/2403.13793",
        "authors": [
            "mary phuong",
            "matthew aitchison",
            "elliot catt",
            "sarah cogan",
            "alexandre kaskasoli",
            "victoria krakovna",
            "david lindner",
            "matthew rahtz",
            "yannis assael",
            "sarah hodkinson",
            "heidi howard",
            "tom lieberum",
            "ramana kumar",
            "maria abi raad",
            "albert webson",
            "lewis ho",
            "sharon lin",
            "sebastian farquhar",
            "marcus hutter",
            "gregoire deletang",
            "anian ruoss",
            "seliem el-sayed",
            "sasha brown",
            "anca dragan",
            "rohin shah",
            "allan dafoe",
            "toby shevlane"
        ]
    },
    {
        "id": "2403.13869",
        "title": "accurately predicting probabilities of safety-critical rare events for   intelligent systems",
        "abstract": "intelligent systems are increasingly integral to our daily lives, yet rare safety-critical events present significant latent threats to their practical deployment. addressing this challenge hinges on accurately predicting the probability of safety-critical events occurring within a given time step from the current state, a metric we define as 'criticality'. the complexity of predicting criticality arises from the extreme data imbalance caused by rare events in high dimensional variables associated with the rare events, a challenge we refer to as the curse of rarity. existing methods tend to be either overly conservative or prone to overlooking safety-critical events, thus struggling to achieve both high precision and recall rates, which severely limits their applicability. this study endeavors to develop a criticality prediction model that excels in both precision and recall rates for evaluating the criticality of safety-critical autonomous systems. we propose a multi-stage learning framework designed to progressively densify the dataset, mitigating the curse of rarity across stages. to validate our approach, we evaluate it in two cases: lunar lander and bipedal walker scenarios. the results demonstrate that our method surpasses traditional approaches, providing a more accurate and dependable assessment of criticality in intelligent systems.",
        "doi": "",
        "created": "2024-03-20",
        "url": "https://arxiv.org/abs/2403.13869",
        "authors": [
            "ruoxuan bai",
            "jingxuan yang",
            "weiduo gong",
            "yi zhang",
            "qiujing lu",
            "shuo feng"
        ]
    },
    {
        "id": "2403.13923",
        "title": "credit vs. discount-based congestion pricing: a comparison study",
        "abstract": "tolling, or congestion pricing, offers a promising traffic management policy for regulating congestion, but has also attracted criticism for placing outsized financial burdens on low-income users. credit-based congestion pricing (cbcp) and discount-based congestion pricing (dbcp) policies, which respectively provide travel credits and toll discounts to low-income users on tolled roads, have emerged as promising mechanisms for reducing traffic congestion without worsening societal inequities. however, the optimal design of cbcp and dbcp policies, as well as their relative advantages and disadvantages, remain poorly understood. to address this, we study the effects of implementing cbcp and dbcp policies to route users on a network of multi-lane highways with tolled express lanes. we formulate a non-atomic routing game framework in which a subset of eligible users is granted toll relief in the form of a fixed budget or toll discount, while the remaining ineligible users must pay out-of-pocket. we prove the existence of nash equilibrium traffic flow patterns corresponding to any given cbcp or dbcp policy. under the additional assumption that eligible users have time-invariant vots, we provide a convex program to efficiently compute these equilibria. for networks consisting of a single edge, we identify conditions under which cbcp policies outperform dbcp policies (and vice versa), in the sense of improving eligible users' access to the express lane. finally, we present empirical results from a cbcp pilot study of the san mateo 101 express lane project in california. our empirical results corroborate our theoretical analysis of the impact of deploying credit-based and discount-based policies, and lend insights into the sensitivity of their impact with respect to the travel demand and users' vots.",
        "doi": "",
        "created": "2024-03-20",
        "url": "https://arxiv.org/abs/2403.13923",
        "authors": [
            "chih-yuan chiu",
            "devansh jalota",
            "marco pavone"
        ]
    },
    {
        "id": "2403.14932",
        "title": "attention-driven reasoning: unlocking the potential of large language   models",
        "abstract": "large language models (llms) have shown remarkable capabilities, but their reasoning abilities and underlying mechanisms remain poorly understood. we present a novel approach to enhance llms' reasoning through attention mechanism optimization, without additional training data. we identify inefficiencies in the attention distribution caused by non-semantic tokens and propose an algorithm to re-balance the skewed distribution, enabling the model to abstract more nuanced knowledge. our experiments demonstrate significantly improved reasoning capabilities, particularly for non-stem questions. we provide insights into the role of attention patterns in llms' reasoning and propose a method to enhance these abilities, paving the way for more powerful and versatile language models.",
        "doi": "",
        "created": "2024-03-21",
        "url": "https://arxiv.org/abs/2403.14932",
        "authors": [
            "bingli liao",
            "danilo vasconcellos vargas"
        ]
    },
    {
        "id": "2403.14989",
        "title": "masontigers at semeval-2024 task 8: performance analysis of   transformer-based models on machine-generated text detection",
        "abstract": "this paper presents the masontigers entry to the semeval-2024 task 8 - multigenerator, multidomain, and multilingual black-box machine-generated text detection. the task encompasses binary human-written vs. machine-generated text classification (track a), multi-way machine-generated text classification (track b), and human-machine mixed text detection (track c). our best performing approaches utilize mainly the ensemble of discriminator transformer models along with sentence transformer and statistical machine learning approaches in specific cases. moreover, zero-shot prompting and fine-tuning of flan-t5 are used for track a and b.",
        "doi": "",
        "created": "2024-03-22",
        "url": "https://arxiv.org/abs/2403.14989",
        "authors": [
            "sadiya sayara chowdhury puspo",
            "md nishat raihan",
            "dhiman goswami",
            "al nahian bin emran",
            "amrita ganguly",
            "ozlem uzuner"
        ]
    },
    {
        "id": "2403.15263",
        "title": "federated bayesian deep learning: the application of statistical   aggregation methods to bayesian models",
        "abstract": "federated learning (fl) is an approach to training machine learning models that takes advantage of multiple distributed datasets while maintaining data privacy and reducing communication costs associated with sharing local datasets. aggregation strategies have been developed to pool or fuse the weights and biases of distributed deterministic models; however, modern deterministic deep learning (dl) models are often poorly calibrated and lack the ability to communicate a measure of epistemic uncertainty in prediction, which is desirable for remote sensing platforms and safety-critical applications. conversely, bayesian dl models are often well calibrated and capable of quantifying and communicating a measure of epistemic uncertainty along with a competitive prediction accuracy. unfortunately, because the weights and biases in bayesian dl models are defined by a probability distribution, simple application of the aggregation methods associated with fl schemes for deterministic models is either impossible or results in sub-optimal performance. in this work, we use independent and identically distributed (iid) and non-iid partitions of the cifar-10 dataset and a fully variational resnet-20 architecture to analyze six different aggregation strategies for bayesian dl models. additionally, we analyze the traditional federated averaging approach applied to an approximate bayesian monte carlo dropout model as a lightweight alternative to more complex variational inference methods in fl. we show that aggregation strategy is a key hyperparameter in the design of a bayesian fl system with downstream effects on accuracy, calibration, uncertainty quantification, training stability, and client compute requirements.",
        "doi": "",
        "created": "2024-03-22",
        "url": "https://arxiv.org/abs/2403.15263",
        "authors": [
            "john fischer",
            "marko orescanin",
            "justin loomis",
            "patrick mcclure"
        ]
    },
    {
        "id": "2403.15472",
        "title": "enhancing programming education with chatgpt: a case study on student   perceptions and interactions in a python course",
        "abstract": "the integration of chatgpt as a supportive tool in education, notably in programming courses, addresses the unique challenges of programming education by providing assistance with debugging, code generation, and explanations. despite existing research validating chatgpt's effectiveness, its application in university-level programming education and a detailed understanding of student interactions and perspectives remain limited. this paper explores chatgpt's impact on learning in a python programming course tailored for first-year students over eight weeks. by analyzing responses from surveys, open-ended questions, and student-chatgpt dialog data, we aim to provide a comprehensive view of chatgpt's utility and identify both its advantages and limitations as perceived by students. our study uncovers a generally positive reception toward chatgpt and offers insights into its role in enhancing the programming education experience. these findings contribute to the broader discourse on ai's potential in education, suggesting paths for future research and application.",
        "doi": "",
        "created": "2024-03-20",
        "url": "https://arxiv.org/abs/2403.15472",
        "authors": [
            "boxaun ma",
            "li chen",
            "shin'ichi konomi"
        ]
    },
    {
        "id": "2403.15623",
        "title": "approximation algorithms for school assignment: group fairness and   multi-criteria optimization",
        "abstract": "we consider the problem of assigning students to schools, when students have different utilities for schools and schools have capacity. there are additional group fairness considerations over students that can be captured either by concave objectives, or additional constraints on the groups. we present approximation algorithms for this problem via convex program rounding that achieve various trade-offs between utility violation, capacity violation, and running time. we also show that our techniques easily extend to the setting where there are arbitrary covering constraints on the feasible assignment, capturing multi-criteria and ranking optimization.",
        "doi": "",
        "created": "2024-03-22",
        "url": "https://arxiv.org/abs/2403.15623",
        "authors": [
            "santhini k. a.",
            "kamesh munagala",
            "meghana nasre",
            "govind s. sankar"
        ]
    },
    {
        "id": "2403.16081",
        "title": "the interplay of learning, analytics, and artificial intelligence in   education",
        "abstract": "this paper presents a multi dimensional view of ai's role in learning and education, emphasizing the intricate interplay between ai, analytics, and the learning processes. here, i challenge the prevalent narrow conceptualization of ai as stochastic tools, as exemplified in generative ai, and argue for the importance of alternative conceptualisations of ai. i highlight the differences between human intelligence and artificial information processing, the cognitive diversity inherent in ai algorithms, and posit that ai can also serve as an instrument for understanding human learning. early learning sciences and ai in education research, which saw ai as an analogy for human intelligence, have diverged from this perspective, prompting a need to rekindle this connection. the paper presents three unique conceptualizations of ai in education: the externalization of human cognition, the internalization of ai models to influence human thought processes, and the extension of human cognition via tightly integrated human-ai systems. examples from current research and practice are examined as instances of the three conceptualisations, highlighting the potential value and limitations of each conceptualisation for education, as well as the perils of overemphasis on externalising human cognition as exemplified in today's hype surrounding generative ai tools. the paper concludes with an advocacy for a broader educational approach that includes educating people about ai and innovating educational systems to remain relevant in an ai enabled world.",
        "doi": "",
        "created": "2024-03-24",
        "url": "https://arxiv.org/abs/2403.16081",
        "authors": [
            "mutlu cukurova"
        ]
    },
    {
        "id": "2403.16159",
        "title": "designing child-centric ai learning environments: insights from   llm-enhanced creative project-based learning",
        "abstract": "project-based learning (pbl) is an instructional method that is very helpful in nurturing students' creativity, but it requires significant time and energy from both students and teachers. large language models (llms) have been proven to assist in creative tasks, yet much controversy exists regarding their role in fostering creativity. this paper explores the potential of llms in pbl settings, with a special focus on fostering creativity. we began with an exploratory study involving 12 middle school students and identified five design considerations for llm applications in pbl. building on this, we developed an llm-empowered, 48-hour pbl program and conducted an instructional experiment with 31 middle school students. our results indicated that llms can enhance every stage of pbl. additionally, we also discovered ambivalent perspectives among students and mentors toward llm usage. furthermore, we explored the challenge and design implications of integrating llms into pbl and reflected on the program. by bridging ai advancements into educational practice, our work aims to inspire further discourse and investigation into harnessing ai's potential in child-centric educational settings.",
        "doi": "",
        "created": "2024-03-24",
        "url": "https://arxiv.org/abs/2403.16159",
        "authors": [
            "siyu zha",
            "yuehan qiao",
            "qingyu hu",
            "zhongsheng li",
            "jiangtao gong",
            "yingqing xu"
        ]
    },
    {
        "id": "2403.16896",
        "title": "inverting the sum of two singular matrices",
        "abstract": "square matrices of the form $\\widetilde{\\mathbf{a}} =\\mathbf{a} + \\mathbf{e}d \\mathbf{f}^*$ are considered. an explicit expression for the inverse is given, provided $\\widetilde{\\mathbf{a}}$ and $d$ are invertible with $\\text{rank}(\\widetilde{\\mathbf{a}}) =\\text{rank}(\\mathbf{a})+\\text{rank}(\\mathbf{e}d \\mathbf{f}^*)$. the inverse is presented in two ways, one that uses singular value decomposition and another that depends directly on the components $\\mathbf{a}$, $\\mathbf{e}$, $\\mathbf{f}$ and $d$. additionally, a matrix determinant lemma for singular matrices follows from the derivations.",
        "doi": "",
        "created": "2024-03-25",
        "url": "https://arxiv.org/abs/2403.16896",
        "authors": [
            "sofia eriksson",
            "jonas nordqvist"
        ]
    },
    {
        "id": "2403.16932",
        "title": "on the maximum theta series over unimodular lattices",
        "abstract": "the theta series of a lattice has been extensively studied in the literature and is closely related to a critical quantity widely used in the fields of physical layer security and cryptography, known as the flatness factor, or equivalently, the smoothing parameter of a lattice. both fields raise the fundamental question of determining the (globally) maximum theta series over a particular set of volume-one lattices, namely, the stable lattices. in this work, we present a property of unimodular lattices, a subfamily of stable lattices, to verify that the integer lattice $\\mathbb{z}^{n}$ achieves the largest possible value of theta series over the set of unimodular lattices. such a result moves towards proving a conjecture recently stated by regev and stephens-davidowitz: any unimodular lattice, except for those lattices isomorphic to $\\mathbb{z}^{n}$, has a strictly smaller theta series than that of $\\mathbb{z}^{n}$. our techniques are mainly based on studying the ratio of the theta series of a unimodular lattice to the theta series of $\\mathbb{z}^n$, called the secrecy ratio. we relate the regev and stephens-davidowitz conjecture with another conjecture for unimodular lattices, known in the literature as the belfiore-sol\\'e conjecture. the latter assumes that the secrecy ratio of any unimodular lattice has a symmetry point, which is exactly where the global minimum of the secrecy ratio is achieved.",
        "doi": "",
        "created": "2024-03-25",
        "url": "https://arxiv.org/abs/2403.16932",
        "authors": [
            "maiara f. bollauf",
            "hsuan-yin lin"
        ]
    },
    {
        "id": "2403.17448",
        "title": "adaptive line-of-sight guidance law based on vector fields path   following for underactuated unmanned surface vehicle",
        "abstract": "the focus of this paper is to develop a methodology that enables an unmanned surface vehicle (usv) to efficiently track a planned path. the introduction of a vector field-based adaptive line of-sight guidance law (vfalos) for accurate trajectory tracking and minimizing the overshoot response time during usv tracking of curved paths improves the overall line-of-sight (los) guidance method. these improvements contribute to faster convergence to the desired path, reduce oscillations, and can mitigate the effects of persistent external disturbances. it is shown that the proposed guidance law exhibits k-exponential stability when converging to the desired path consisting of straight and curved lines. the results in the paper show that the proposed method effectively improves the accuracy of the usv tracking the desired path while ensuring the safety of the usv work.",
        "doi": "",
        "created": "2024-03-26",
        "url": "https://arxiv.org/abs/2403.17448",
        "authors": [
            "jie qi",
            "ronghua wanga",
            "nailong wu"
        ]
    },
    {
        "id": "2403.17753",
        "title": "ccdsreformer: traffic flow prediction with a criss-crossed dual-stream   enhanced rectified transformer model",
        "abstract": "accurate, and effective traffic forecasting is vital for smart traffic systems, crucial in urban traffic planning and management. current spatio-temporal transformer models, despite their prediction capabilities, struggle with balancing computational efficiency and accuracy, favoring global over local information, and handling spatial and temporal data separately, limiting insight into complex interactions. we introduce the criss-crossed dual-stream enhanced rectified transformer model (ccdsreformer), which includes three innovative modules: enhanced rectified spatial self-attention (ressa), enhanced rectified delay aware self-attention (redasa), and enhanced rectified temporal self-attention (retsa). these modules aim to lower computational needs via sparse attention, focus on local information for better traffic dynamics understanding, and merge spatial and temporal insights through a unique learning method. extensive tests on six real-world datasets highlight ccdsreformer's superior performance. an ablation study also confirms the significant impact of each component on the model's predictive accuracy, showcasing our model's ability to forecast traffic flow effectively.",
        "doi": "",
        "created": "2024-03-26",
        "url": "https://arxiv.org/abs/2403.17753",
        "authors": [
            "zhiqi shao",
            "michael g. h. bell",
            "ze wang",
            "d. glenn geers",
            "xusheng yao",
            "junbin gao"
        ]
    },
    {
        "id": "2403.18578",
        "title": "steingen: generating fidelitous and diverse graph samples",
        "abstract": "generating graphs that preserve characteristic structures while promoting sample diversity can be challenging, especially when the number of graph observations is small. here, we tackle the problem of graph generation from only one observed graph. the classical approach of graph generation from parametric models relies on the estimation of parameters, which can be inconsistent or expensive to compute due to intractable normalisation constants. generative modelling based on machine learning techniques to generate high-quality graph samples avoids parameter estimation but usually requires abundant training samples. our proposed generating procedure, steingen, which is phrased in the setting of graphs as realisations of exponential random graph models, combines ideas from stein's method and mcmc by employing markovian dynamics which are based on a stein operator for the target model. steingen uses the glauber dynamics associated with an estimated stein operator to generate a sample, and re-estimates the stein operator from the sample after every sampling step. we show that on a class of exponential random graph models this novel \"estimation and re-estimation\" generation strategy yields high distributional similarity (high fidelity) to the original data, combined with high sample diversity.",
        "doi": "",
        "created": "2024-03-27",
        "url": "https://arxiv.org/abs/2403.18578",
        "authors": [
            "gesine reinert",
            "wenkai xu"
        ]
    },
    {
        "id": "2403.19655",
        "title": "gaussiancube: structuring gaussian splatting using optimal transport for   3d generative modeling",
        "abstract": "3d gaussian splatting (gs) have achieved considerable improvement over neural radiance fields in terms of 3d fitting fidelity and rendering speed. however, this unstructured representation with scattered gaussians poses a significant challenge for generative modeling. to address the problem, we introduce gaussiancube, a structured gs representation that is both powerful and efficient for generative modeling. we achieve this by first proposing a modified densification-constrained gs fitting algorithm which can yield high-quality fitting results using a fixed number of free gaussians, and then re-arranging the gaussians into a predefined voxel grid via optimal transport. the structured grid representation allows us to use standard 3d u-net as our backbone in diffusion generative modeling without elaborate designs. extensive experiments conducted on shapenet and omniobject3d show that our model achieves state-of-the-art generation results both qualitatively and quantitatively, underscoring the potential of gaussiancube as a powerful and versatile 3d representation.",
        "doi": "",
        "created": "2024-03-28",
        "url": "https://arxiv.org/abs/2403.19655",
        "authors": [
            "bowen zhang",
            "yiji cheng",
            "jiaolong yang",
            "chunyu wang",
            "feng zhao",
            "yansong tang",
            "dong chen",
            "baining guo"
        ]
    },
    {
        "id": "2403.20045",
        "title": "blockchain for energy market: a comprehensive survey",
        "abstract": "the energy market encompasses the behavior of energy supply and trading within a platform system. by utilizing centralized or distributed trading, energy can be effectively managed and distributed across different regions, thereby achieving market equilibrium and satisfying both producers and consumers. however, recent years have presented unprecedented challenges and difficulties for the development of the energy market. these challenges include regional energy imbalances, volatile energy pricing, high computing costs, and issues related to transaction information disclosure. researchers widely acknowledge that the security features of blockchain technology can enhance the efficiency of energy transactions and establish the fundamental stability and robustness of the energy market. this type of blockchain-enabled energy market is commonly referred to as an energy blockchain. currently, there is a burgeoning amount of research in this field, encompassing algorithm design, framework construction, and practical application. it is crucial to organize and compare these research efforts to facilitate the further advancement of energy blockchain. this survey aims to comprehensively review the fundamental characteristics of blockchain and energy markets, highlighting the significant advantages of combining the two. moreover, based on existing research outcomes, we will categorize and compare the current energy market research supported by blockchain in terms of algorithm design, market framework construction, and the policies and practical applications adopted by different countries. finally, we will address current issues and propose potential future directions for improvement, to provide guidance for the practical implementation of blockchain in the energy market.",
        "doi": "",
        "created": "2024-03-29",
        "url": "https://arxiv.org/abs/2403.20045",
        "authors": [
            "tianqi jiang",
            "haoxiang luo",
            "kun yang",
            "gang sun",
            "hongfang yu",
            "qi huang",
            "athanasios v. vasilakos"
        ]
    },
    {
        "id": "2403.20106",
        "title": "learning enriched features via selective state spaces model for   efficient image deblurring",
        "abstract": "image deblurring aims to restore a high-quality image from its corresponding blurred. the emergence of cnns and transformers has enabled significant progress. however, these methods often face the dilemma between eliminating long-range degradation perturbations and maintaining computational efficiency. while the selective state space model (ssm) shows promise in modeling long-range dependencies with linear complexity, it also encounters challenges such as local pixel forgetting and channel redundancy. to address this issue, we propose an efficient image deblurring network that leverages selective state spaces model to aggregate enriched and accurate features. specifically, we introduce an aggregate local and global information block (algblock) designed to effectively capture and integrate both local invariant properties and non-local information. the algblock comprises two primary modules: a module for capturing local and global features (clgf), and a feature aggregation module (fa). the clgf module is composed of two branches: the global branch captures long-range dependency features via a selective state spaces model, while the local branch employs simplified channel attention to model local connectivity, thereby reducing local pixel forgetting and channel redundancy. in addition, we design a fa module to accentuate the local part by recalibrating the weight during the aggregation of the two branches for restoration. experimental results demonstrate that the proposed method outperforms state-of-the-art approaches on widely used benchmarks.",
        "doi": "",
        "created": "2024-03-29",
        "url": "https://arxiv.org/abs/2403.20106",
        "authors": [
            "hu gao",
            "depeng dang"
        ]
    },
    {
        "id": "2404.00086",
        "title": "dvis-daq: improving video segmentation via dynamic anchor queries",
        "abstract": "modern video segmentation methods adopt object queries to perform inter-frame association and demonstrate satisfactory performance in tracking continuously appearing objects despite large-scale motion and transient occlusion. however, they all underperform on newly emerging and disappearing objects that are common in the real world because they attempt to model object emergence and disappearance through feature transitions between background and foreground queries that have significant feature gaps. we introduce dynamic anchor queries (daq) to shorten the transition gap between the anchor and target queries by dynamically generating anchor queries based on the features of potential candidates. furthermore, we introduce a query-level object emergence and disappearance simulation (eds) strategy, which unleashes daq's potential without any additional cost. finally, we combine our proposed daq and eds with dvis to obtain dvis-daq. extensive experiments demonstrate that dvis-daq achieves a new state-of-the-art (sota) performance on five mainstream video segmentation benchmarks. code and models are available at \\url{https://github.com/skyworkai/daq-vs}.",
        "doi": "",
        "created": "2024-03-29",
        "url": "https://arxiv.org/abs/2404.00086",
        "authors": [
            "yikang zhou",
            "tao zhang",
            "shunping ji",
            "shuicheng yan",
            "xiangtai li"
        ]
    },
    {
        "id": "2404.00185",
        "title": "on inherent adversarial robustness of active vision systems",
        "abstract": "current deep neural networks are vulnerable to adversarial examples, which alter their predictions by adding carefully crafted noise. since human eyes are robust to such inputs, it is possible that the vulnerability stems from the standard way of processing inputs in one shot by processing every pixel with the same importance. in contrast, neuroscience suggests that the human vision system can differentiate salient features by (1) switching between multiple fixation points (saccades) and (2) processing the surrounding with a non-uniform external resolution (foveation). in this work, we advocate that the integration of such active vision mechanisms into current deep learning systems can offer robustness benefits. specifically, we empirically demonstrate the inherent robustness of two active vision methods - gfnet and falcon - under a black box threat model. by learning and inferencing based on downsampled glimpses obtained from multiple distinct fixation points within an input, we show that these active methods achieve (2-3) times greater robustness compared to a standard passive convolutional network under state-of-the-art adversarial attacks. more importantly, we provide illustrative and interpretable visualization analysis that demonstrates how performing inference from distinct fixation points makes active vision methods less vulnerable to malicious inputs.",
        "doi": "",
        "created": "2024-03-29",
        "url": "https://arxiv.org/abs/2404.00185",
        "authors": [
            "amitangshu mukherjee",
            "timur ibrayev",
            "kaushik roy"
        ]
    },
    {
        "id": "2404.00477",
        "title": "de-hnn: an effective neural model for circuit netlist representation",
        "abstract": "the run-time for optimization tools used in chip design has grown with the complexity of designs to the point where it can take several days to go through one design cycle which has become a bottleneck. designers want fast tools that can quickly give feedback on a design. using the input and output data of the tools from past designs, one can attempt to build a machine learning model that predicts the outcome of a design in significantly shorter time than running the tool. the accuracy of such models is affected by the representation of the design data, which is usually a netlist that describes the elements of the digital circuit and how they are connected. graph representations for the netlist together with graph neural networks have been investigated for such models. however, the characteristics of netlists pose several challenges for existing graph learning frameworks, due to the large number of nodes and the importance of long-range interactions between nodes. to address these challenges, we represent the netlist as a directed hypergraph and propose a directional equivariant hypergraph neural network (de-hnn) for the effective learning of (directed) hypergraphs. theoretically, we show that our de-hnn can universally approximate any node or hyperedge based function that satisfies certain permutation equivariant and invariant properties natural for directed hypergraphs. we compare the proposed de-hnn with several state-of-the-art (sota) machine learning models for (hyper)graphs and netlists, and show that the de-hnn significantly outperforms them in predicting the outcome of optimized place-and-route tools directly from the input netlists. our source code and the netlists data used are publicly available at https://github.com/yusulab/chips.git",
        "doi": "",
        "created": "2024-03-30",
        "url": "https://arxiv.org/abs/2404.00477",
        "authors": [
            "zhishang luo",
            "truong son hy",
            "puoya tabaghi",
            "donghyeon koh",
            "michael defferrard",
            "elahe rezaei",
            "ryan carey",
            "rhett davis",
            "rajeev jain",
            "yusu wang"
        ]
    },
    {
        "id": "2404.00498",
        "title": "94% on cifar-10 in 3.29 seconds on a single gpu",
        "abstract": "cifar-10 is among the most widely used datasets in machine learning, facilitating thousands of research projects per year. to accelerate research and reduce the cost of experiments, we introduce training methods for cifar-10 which reach 94% accuracy in 3.29 seconds, 95% in 10.4 seconds, and 96% in 46.3 seconds, when run on a single nvidia a100 gpu. as one factor contributing to these training speeds, we propose a derandomized variant of horizontal flipping augmentation, which we show improves over the standard method in every case where flipping is beneficial over no flipping at all. our code is released at https://github.com/kellerjordan/cifar10-airbench.",
        "doi": "",
        "created": "2024-03-30",
        "url": "https://arxiv.org/abs/2404.00498",
        "authors": [
            "keller jordan"
        ]
    },
    {
        "id": "2404.00712",
        "title": "survey of computerized adaptive testing: a machine learning perspective",
        "abstract": "computerized adaptive testing (cat) provides an efficient and tailored method for assessing the proficiency of examinees, by dynamically adjusting test questions based on their performance. widely adopted across diverse fields like education, healthcare, sports, and sociology, cat has revolutionized testing practices. while traditional methods rely on psychometrics and statistics, the increasing complexity of large-scale testing has spurred the integration of machine learning techniques. this paper aims to provide a machine learning-focused survey on cat, presenting a fresh perspective on this adaptive testing method. by examining the test question selection algorithm at the heart of cat's adaptivity, we shed light on its functionality. furthermore, we delve into cognitive diagnosis models, question bank construction, and test control within cat, exploring how machine learning can optimize these components. through an analysis of current methods, strengths, limitations, and challenges, we strive to develop robust, fair, and efficient cat systems. by bridging psychometric-driven cat research with machine learning, this survey advocates for a more inclusive and interdisciplinary approach to the future of adaptive testing.",
        "doi": "",
        "created": "2024-03-31",
        "url": "https://arxiv.org/abs/2404.00712",
        "authors": [
            "qi liu",
            "yan zhuang",
            "haoyang bi",
            "zhenya huang",
            "weizhe huang",
            "jiatong li",
            "junhao yu",
            "zirui liu",
            "zirui hu",
            "yuting hong",
            "zachary a. pardos",
            "haiping ma",
            "mengxiao zhu",
            "shijin wang",
            "enhong chen"
        ]
    },
    {
        "id": "2404.01054",
        "title": "regularized best-of-n sampling to mitigate reward hacking for language   model alignment",
        "abstract": "best-of-n (bon) sampling with a reward model has been shown to be an effective strategy for aligning large language models (llms) to human preferences at the time of decoding. bon sampling is susceptible to a problem known as reward hacking. because the reward model is an imperfect proxy for the true objective, over-optimizing its value can compromise its performance on the true objective. a common solution to prevent reward hacking in preference learning techniques is to optimize a reward using proximity regularization (e.g., kl regularization), which ensures that the language model remains close to the reference model. in this research, we propose regularized best-of-n (rbon), a variant of bon that aims to mitigate reward hacking by incorporating a proximity term in response selection, similar to preference learning techniques. we evaluate two variants of rbon on the alpacafarm dataset and find that they outperform bon, especially when the proxy reward model has a low correlation with the true objective.",
        "doi": "",
        "created": "2024-04-01",
        "url": "https://arxiv.org/abs/2404.01054",
        "authors": [
            "yuu jinnai",
            "tetsuro morimura",
            "kaito ariu",
            "kenshi abe"
        ]
    },
    {
        "id": "2404.01112",
        "title": "few-shot point cloud reconstruction and denoising via learned guassian   splats renderings and fine-tuned diffusion features",
        "abstract": "existing deep learning methods for the reconstruction and denoising of point clouds rely on small datasets of 3d shapes. we circumvent the problem by leveraging deep learning methods trained on billions of images. we propose a method to reconstruct point clouds from few images and to denoise point clouds from their rendering by exploiting prior knowledge distilled from image-based deep learning models. to improve reconstruction in constraint settings, we regularize the training of a differentiable renderer with hybrid surface and appearance by introducing semantic consistency supervision. in addition, we propose a pipeline to finetune stable diffusion to denoise renderings of noisy point clouds and we demonstrate how these learned filters can be used to remove point cloud noise coming without 3d supervision. we compare our method with dss and pointradiance and achieved higher quality 3d reconstruction on the sketchfab testset and scut dataset.",
        "doi": "",
        "created": "2024-04-01",
        "url": "https://arxiv.org/abs/2404.01112",
        "authors": [
            "pietro bonazzi"
        ]
    },
    {
        "id": "2404.01205",
        "title": "foundations of cyber resilience: the confluence of game, control, and   learning theories",
        "abstract": "cyber resilience is a complementary concept to cybersecurity, focusing on the preparation, response, and recovery from cyber threats that are challenging to prevent. organizations increasingly face such threats in an evolving cyber threat landscape. understanding and establishing foundations for cyber resilience provide a quantitative and systematic approach to cyber risk assessment, mitigation policy evaluation, and risk-informed defense design. a systems-scientific view toward cyber risks provides holistic and system-level solutions. this chapter starts with a systemic view toward cyber risks and presents the confluence of game theory, control theory, and learning theories, which are three major pillars for the design of cyber resilience mechanisms to counteract increasingly sophisticated and evolving threats in our networks and organizations. game and control theoretic methods provide a set of modeling frameworks to capture the strategic and dynamic interactions between defenders and attackers. control and learning frameworks together provide a feedback-driven mechanism that enables autonomous and adaptive responses to threats. game and learning frameworks offer a data-driven approach to proactively reason about adversarial behaviors and resilient strategies. the confluence of the three lays the theoretical foundations for the analysis and design of cyber resilience. this chapter presents various theoretical paradigms, including dynamic asymmetric games, moving horizon control, conjectural learning, and meta-learning, as recent advances at the intersection. this chapter concludes with future directions and discussions of the role of neurosymbolic learning and the synergy between foundation models and game models in cyber resilience.",
        "doi": "",
        "created": "2024-04-01",
        "url": "https://arxiv.org/abs/2404.01205",
        "authors": [
            "quanyan zhu"
        ]
    },
    {
        "id": "2404.01365",
        "title": "prompt-prompted mixture of experts for efficient llm generation",
        "abstract": "with the development of transformer-based large language models (llms), they have been applied to many fields due to their remarkable utility, but this comes at a considerable computational cost at deployment. fortunately, some methods such as pruning or constructing a mixture of experts (moe) aim at exploiting sparsity in transformer feedforward (ff) blocks to gain boosts in speed and reduction in memory requirements. however, these techniques can be very costly and inflexible in practice, as they often require training or are restricted to specific types of architectures. to address this, we introduce griffin, a novel training-free moe that selects unique ff experts at the sequence level for efficient generation across a plethora of llms with different non-relu activation functions. this is possible due to a critical observation that many trained llms naturally produce highly structured ff activation patterns within a sequence, which we call flocking. despite our method's simplicity, we show with 50% of the ff parameters, griffin maintains the original model's performance with little to no degradation on a variety of classification and generation tasks, all while improving latency (e.g. 1.25$\\times$ speed-up in llama 2 13b on an nvidia l40). code is available at https://github.com/hdong920/griffin.",
        "doi": "",
        "created": "2024-04-01",
        "url": "https://arxiv.org/abs/2404.01365",
        "authors": [
            "harry dong",
            "beidi chen",
            "yuejie chi"
        ]
    },
    {
        "id": "2404.01655",
        "title": "fashionengine: interactive generation and editing of 3d clothed humans",
        "abstract": "we present fashionengine, an interactive 3d human generation and editing system that allows us to design 3d digital humans in a way that aligns with how humans interact with the world, such as natural languages, visual perceptions, and hand-drawing. fashionengine automates the 3d human production with three key components: 1) a pre-trained 3d human diffusion model that learns to model 3d humans in a semantic uv latent space from 2d image training data, which provides strong priors for diverse generation and editing tasks. 2) multimodality-uv space encoding the texture appearance, shape topology, and textual semantics of human clothing in a canonical uv-aligned space, which faithfully aligns the user multimodal inputs with the implicit uv latent space for controllable 3d human editing. the multimodality-uv space is shared across different user inputs, such as texts, images, and sketches, which enables various joint multimodal editing tasks. 3) multimodality-uv aligned sampler learns to sample high-quality and diverse 3d humans from the diffusion prior for multimodal user inputs. extensive experiments validate fashionengine's state-of-the-art performance for conditional generation/editing tasks. in addition, we present an interactive user interface for our fashionengine that enables both conditional and unconditional generation tasks, and editing tasks including pose/view/shape control, text-, image-, and sketch-driven 3d human editing and 3d virtual try-on, in a unified framework. our project page is at: https://taohuumd.github.io/projects/fashionengine.",
        "doi": "",
        "created": "2024-04-02",
        "url": "https://arxiv.org/abs/2404.01655",
        "authors": [
            "tao hu",
            "fangzhou hong",
            "zhaoxi chen",
            "ziwei liu"
        ]
    },
    {
        "id": "2404.01744",
        "title": "octopus v2: on-device language model for super agent",
        "abstract": "language models have shown effectiveness in a variety of software applications, particularly in tasks related to automatic workflow. these models possess the crucial ability to call functions, which is essential in creating ai agents. despite the high performance of large-scale language models in cloud environments, they are often associated with concerns over privacy and cost. current on-device models for function calling face issues with latency and accuracy. our research presents a new method that empowers an on-device model with 2 billion parameters to surpass the performance of gpt-4 in both accuracy and latency, and decrease the context length by 95\\%. when compared to llama-7b with a rag-based function calling mechanism, our method enhances latency by 35-fold. this method reduces the latency to levels deemed suitable for deployment across a variety of edge devices in production environments, aligning with the performance requisites for real-world applications.",
        "doi": "",
        "created": "2024-04-02",
        "url": "https://arxiv.org/abs/2404.01744",
        "authors": [
            "wei chen",
            "zhiyuan li"
        ]
    },
    {
        "id": "2404.01887",
        "title": "3d scene generation from scene graphs and self-attention",
        "abstract": "synthesizing realistic and diverse indoor 3d scene layouts in a controllable fashion opens up applications in simulated navigation and virtual reality. as concise and robust representations of a scene, scene graphs have proven to be well-suited as the semantic control on the generated layout. we present a variant of the conditional variational autoencoder (cvae) model to synthesize 3d scenes from scene graphs and floor plans. we exploit the properties of self-attention layers to capture high-level relationships between objects in a scene, and use these as the building blocks of our model. our model, leverages graph transformers to estimate the size, dimension and orientation of the objects in a room while satisfying relationships in the given scene graph. our experiments shows self-attention layers leads to sparser (7.9x compared to graphto3d) and more diverse scenes (16%).",
        "doi": "",
        "created": "2024-04-02",
        "url": "https://arxiv.org/abs/2404.01887",
        "authors": [
            "pietro bonazzi"
        ]
    },
    {
        "id": "2404.02000",
        "title": "africa-centric self-supervised pre-training for multilingual speech   representation in a sub-saharan context",
        "abstract": "we present the first self-supervised multilingual speech model trained exclusively on african speech. the model learned from nearly 60 000 hours of unlabeled speech segments in 21 languages and dialects spoken in sub-saharan africa. on the ssa subset of the fleurs-102 dataset, our approach based on a hubert$_{base}$ (0.09b) architecture shows competitive results, for asr downstream task, compared to the w2v-bert-51 (0.6b) pre-trained model proposed in the fleurs benchmark, while being more efficient by using 7x less data and 6x less parameters. furthermore, in the context of a lid downstream task, our approach outperforms fleurs baselines accuracy by over 22\\%.",
        "doi": "",
        "created": "2024-04-02",
        "url": "https://arxiv.org/abs/2404.02000",
        "authors": [
            "antoine caubri\u00e8re",
            "elodie gauthier"
        ]
    },
    {
        "id": "2404.02072",
        "title": "egtr: extracting graph from transformer for scene graph generation",
        "abstract": "scene graph generation (sgg) is a challenging task of detecting objects and predicting relationships between objects. after detr was developed, one-stage sgg models based on a one-stage object detector have been actively studied. however, complex modeling is used to predict the relationship between objects, and the inherent relationship between object queries learned in the multi-head self-attention of the object detector has been neglected. we propose a lightweight one-stage sgg model that extracts the relation graph from the various relationships learned in the multi-head self-attention layers of the detr decoder. by fully utilizing the self-attention by-products, the relation graph can be extracted effectively with a shallow relation extraction head. considering the dependency of the relation extraction task on the object detection task, we propose a novel relation smoothing technique that adjusts the relation label adaptively according to the quality of the detected objects. by the relation smoothing, the model is trained according to the continuous curriculum that focuses on object detection task at the beginning of training and performs multi-task learning as the object detection performance gradually improves. furthermore, we propose a connectivity prediction task that predicts whether a relation exists between object pairs as an auxiliary task of the relation extraction. we demonstrate the effectiveness and efficiency of our method for the visual genome and open image v6 datasets. our code is publicly available at https://github.com/naver-ai/egtr.",
        "doi": "",
        "created": "2024-04-02",
        "url": "https://arxiv.org/abs/2404.02072",
        "authors": [
            "jinbae im",
            "jeongyeon nam",
            "nokyung park",
            "hyungmin lee",
            "seunghyun park"
        ]
    },
    {
        "id": "2404.02111",
        "title": "risk-aware real-time task allocation for stochastic multi-agent systems   under stl specifications",
        "abstract": "this paper addresses the control synthesis of heterogeneous stochastic linear multi-agent systems with real-time allocation of signal temporal logic (stl) specifications. based on previous work, we decompose specifications into sub-specifications on the individual agent level. to leverage the efficiency of task allocation, a heuristic filter evaluates potential task allocation based on stl robustness. subsequently, an auctioning algorithm determines the definite allocation of specifications. finally, a control strategy is synthesized for each agent-specification pair using tube-based model predictive control (mpc), ensuring provable probabilistic satisfaction. we demonstrate the efficacy of the proposed methods using a multi-bus scenario that highlights a promising extension to autonomous driving applications like crossing an intersection.",
        "doi": "",
        "created": "2024-04-02",
        "url": "https://arxiv.org/abs/2404.02111",
        "authors": [
            "maico h. w. engelaar",
            "zengjie zhang",
            "eleftherios e. vlahakis",
            "mircea lazar",
            "sofie haesaert"
        ]
    },
    {
        "id": "2404.02124",
        "title": "exploring automated distractor generation for math multiple-choice   questions via large language models",
        "abstract": "multiple-choice questions (mcqs) are ubiquitous in almost all levels of education since they are easy to administer, grade, and are a reliable format in assessments and practices. one of the most important aspects of mcqs is the distractors, i.e., incorrect options that are designed to target common errors or misconceptions among real students. to date, the task of crafting high-quality distractors largely remains a labor and time-intensive process for teachers and learning content designers, which has limited scalability. in this work, we study the task of automated distractor generation in the domain of math mcqs and explore a wide variety of large language model (llm)-based approaches, from in-context learning to fine-tuning. we conduct extensive experiments using a real-world math mcq dataset and find that although llms can generate some mathematically valid distractors, they are less adept at anticipating common errors or misconceptions among real students.",
        "doi": "",
        "created": "2024-04-02",
        "url": "https://arxiv.org/abs/2404.02124",
        "authors": [
            "wanyong feng",
            "jaewook lee",
            "hunter mcnichols",
            "alexander scarlatos",
            "digory smith",
            "simon woodhead",
            "nancy otero ornelas",
            "andrew lan"
        ]
    },
    {
        "id": "2404.02249",
        "title": "rat: retrieval-augmented transformer for click-through rate prediction",
        "abstract": "predicting click-through rates (ctr) is a fundamental task for web applications, where a key issue is to devise effective models for feature interactions. current methodologies predominantly concentrate on modeling feature interactions within an individual sample, while overlooking the potential cross-sample relationships that can serve as a reference context to enhance the prediction. to make up for such deficiency, this paper develops a retrieval-augmented transformer (rat), aiming to acquire fine-grained feature interactions within and across samples. by retrieving similar samples, we construct augmented input for each target sample. we then build transformer layers with cascaded attention to capture both intra- and cross-sample feature interactions, facilitating comprehensive reasoning for improved ctr prediction while retaining efficiency. extensive experiments on real-world datasets substantiate the effectiveness of rat and suggest its advantage in long-tail scenarios. the code has been open-sourced at \\url{https://github.com/yushenli807/www24-rat}.",
        "doi": "10.1145/3589335.3651550",
        "created": "2024-04-02",
        "url": "https://arxiv.org/abs/2404.02249",
        "authors": [
            "yushen li",
            "jinpeng wang",
            "tao dai",
            "jieming zhu",
            "jun yuan",
            "rui zhang",
            "shu-tao xia"
        ]
    },
    {
        "id": "2404.02257",
        "title": "snag: scalable and accurate video grounding",
        "abstract": "temporal grounding of text descriptions in videos is a central problem in vision-language learning and video understanding. existing methods often prioritize accuracy over scalability -- they have been optimized for grounding only a few text queries within short videos, and fail to scale up to long videos with hundreds of queries. in this paper, we study the effect of cross-modal fusion on the scalability of video grounding models. our analysis establishes late fusion as a more cost-effective fusion scheme for long-form videos with many text queries. moreover, it leads us to a novel, video-centric sampling scheme for efficient training. based on these findings, we present snag, a simple baseline for scalable and accurate video grounding. without bells and whistles, snag is 43% more accurate and 1.5x faster than cone, a state of the art for long-form video grounding on the challenging mad dataset, while achieving highly competitive results on short videos.",
        "doi": "",
        "created": "2024-04-02",
        "url": "https://arxiv.org/abs/2404.02257",
        "authors": [
            "fangzhou mu",
            "sicheng mo",
            "yin li"
        ]
    },
    {
        "id": "2404.02325",
        "title": "heat death of generative models in closed-loop learning",
        "abstract": "improvement and adoption of generative machine learning models is rapidly accelerating, as exemplified by the popularity of llms (large language models) for text, and diffusion models for image generation.as generative models become widespread, data they generate is incorporated into shared content through the public web. this opens the question of what happens when data generated by a model is fed back to the model in subsequent training campaigns. this is a question about the stability of the training process, whether the distribution of publicly accessible content, which we refer to as \"knowledge\", remains stable or collapses.   small scale empirical experiments reported in the literature show that this closed-loop training process is prone to degenerating. models may start producing gibberish data, or sample from only a small subset of the desired data distribution (a phenomenon referred to as mode collapse). so far there has been only limited theoretical understanding of this process, in part due to the complexity of the deep networks underlying these generative models.   the aim of this paper is to provide insights into this process (that we refer to as \"generative closed-loop learning\") by studying the learning dynamics of generative models that are fed back their own produced content in addition to their original training dataset. the sampling of many of these models can be controlled via a \"temperature\" parameter. using dynamical systems tools, we show that, unless a sufficient amount of external data is introduced at each iteration, any non-trivial temperature leads the model to asymptotically degenerate. in fact, either the generative distribution collapses to a small set of outputs, or becomes uniform over a large set of outputs.",
        "doi": "",
        "created": "2024-04-02",
        "url": "https://arxiv.org/abs/2404.02325",
        "authors": [
            "matteo marchi",
            "stefano soatto",
            "pratik chaudhari",
            "paulo tabuada"
        ]
    },
    {
        "id": "2404.02456",
        "title": "phonologybench: evaluating phonological skills of large language models",
        "abstract": "phonology, the study of speech's structure and pronunciation rules, is a critical yet often overlooked component in large language model (llm) research. llms are widely used in various downstream applications that leverage phonology such as educational tools and poetry generation. moreover, llms can potentially learn imperfect associations between orthographic and phonological forms from the training data. thus, it is imperative to benchmark the phonological skills of llms. to this end, we present phonologybench, a novel benchmark consisting of three diagnostic tasks designed to explicitly test the phonological skills of llms in english: grapheme-to-phoneme conversion, syllable counting, and rhyme word generation. despite having no access to speech data, llms showcased notable performance on the phonologybench tasks. however, we observe a significant gap of 17% and 45% on rhyme word generation and syllable counting, respectively, when compared to humans. our findings underscore the importance of studying llm performance on phonological tasks that inadvertently impact real-world applications. furthermore, we encourage researchers to choose llms that perform well on the phonological task that is closely related to the downstream application since we find that no single model consistently outperforms the others on all the tasks.",
        "doi": "",
        "created": "2024-04-03",
        "url": "https://arxiv.org/abs/2404.02456",
        "authors": [
            "ashima suvarna",
            "harshita khandelwal",
            "nanyun peng"
        ]
    },
    {
        "id": "2404.02548",
        "title": "ai-tutoring in software engineering education",
        "abstract": "with the rapid advancement of artificial intelligence (ai) in various domains, the education sector is set for transformation. the potential of ai-driven tools in enhancing the learning experience, especially in programming, is immense. however, the scientific evaluation of large language models (llms) used in automated programming assessment systems (apass) as an ai-tutor remains largely unexplored. therefore, there is a need to understand how students interact with such ai-tutors and to analyze their experiences. in this paper, we conducted an exploratory case study by integrating the gpt-3.5-turbo model as an ai-tutor within the apas artemis. through a combination of empirical data collection and an exploratory survey, we identified different user types based on their interaction patterns with the ai-tutor. additionally, the findings highlight advantages, such as timely feedback and scalability. however, challenges like generic responses and students' concerns about a learning progress inhibition when using the ai-tutor were also evident. this research adds to the discourse on ai's role in education.",
        "doi": "10.1145/3639474.3640061",
        "created": "2024-04-03",
        "url": "https://arxiv.org/abs/2404.02548",
        "authors": [
            "eduard frankford",
            "clemens sauerwein",
            "patrick bassner",
            "stephan krusche",
            "ruth breu"
        ]
    },
    {
        "id": "2404.02733",
        "title": "instantstyle: free lunch towards style-preserving in text-to-image   generation",
        "abstract": "tuning-free diffusion-based models have demonstrated significant potential in the realm of image personalization and customization. however, despite this notable progress, current models continue to grapple with several complex challenges in producing style-consistent image generation. firstly, the concept of style is inherently underdetermined, encompassing a multitude of elements such as color, material, atmosphere, design, and structure, among others. secondly, inversion-based methods are prone to style degradation, often resulting in the loss of fine-grained details. lastly, adapter-based approaches frequently require meticulous weight tuning for each reference image to achieve a balance between style intensity and text controllability. in this paper, we commence by examining several compelling yet frequently overlooked observations. we then proceed to introduce instantstyle, a framework designed to address these issues through the implementation of two key strategies: 1) a straightforward mechanism that decouples style and content from reference images within the feature space, predicated on the assumption that features within the same space can be either added to or subtracted from one another. 2) the injection of reference image features exclusively into style-specific blocks, thereby preventing style leaks and eschewing the need for cumbersome weight tuning, which often characterizes more parameter-heavy designs.our work demonstrates superior visual stylization outcomes, striking an optimal balance between the intensity of style and the controllability of textual elements. our codes will be available at https://github.com/instantstyle/instantstyle.",
        "doi": "",
        "created": "2024-04-03",
        "url": "https://arxiv.org/abs/2404.02733",
        "authors": [
            "haofan wang",
            "matteo spinelli",
            "qixun wang",
            "xu bai",
            "zekui qin",
            "anthony chen"
        ]
    },
    {
        "id": "2404.02817",
        "title": "a survey of optimization-based task and motion planning: from classical   to learning approaches",
        "abstract": "task and motion planning (tamp) integrates high-level task planning and low-level motion planning to equip robots with the autonomy to effectively reason over long-horizon, dynamic tasks. optimization-based tamp focuses on hybrid optimization approaches that define goal conditions via objective functions and are capable of handling open-ended goals, robotic dynamics, and physical interaction between the robot and the environment. therefore, optimization-based tamp is particularly suited to solve highly complex, contact-rich locomotion and manipulation problems. this survey provides a comprehensive review on optimization-based tamp, covering (i) planning domain representations, including action description languages and temporal logic, (ii) individual solution strategies for components of tamp, including ai planning and trajectory optimization (to), and (iii) the dynamic interplay between logic-based task planning and model-based to. a particular focus of this survey is to highlight the algorithm structures to efficiently solve tamp, especially hierarchical and distributed approaches. additionally, the survey emphasizes the synergy between the classical methods and contemporary learning-based innovations such as large language models. furthermore, the future research directions for tamp is discussed in this survey, highlighting both algorithmic and application-specific challenges.",
        "doi": "",
        "created": "2024-04-03",
        "url": "https://arxiv.org/abs/2404.02817",
        "authors": [
            "zhigen zhao",
            "shuo cheng",
            "yan ding",
            "ziyi zhou",
            "shiqi zhang",
            "danfei xu",
            "ye zhao"
        ]
    },
    {
        "id": "2404.03017",
        "title": "distributionally robust policy and lyapunov-certificate learning",
        "abstract": "this article presents novel methods for synthesizing distributionally robust stabilizing neural controllers and certificates for control systems under model uncertainty. a key challenge in designing controllers with stability guarantees for uncertain systems is the accurate determination of and adaptation to shifts in model parametric uncertainty during online deployment. we tackle this with a novel distributionally robust formulation of the lyapunov derivative chance constraint ensuring a monotonic decrease of the lyapunov certificate. to avoid the computational complexity involved in dealing with the space of probability measures, we identify a sufficient condition in the form of deterministic convex constraints that ensures the lyapunov derivative constraint is satisfied. we integrate this condition into a loss function for training a neural network-based controller and show that, for the resulting closed-loop system, the global asymptotic stability of its equilibrium can be certified with high confidence, even with out-of-distribution (ood) model uncertainties. to demonstrate the efficacy and efficiency of the proposed methodology, we compare it with an uncertainty-agnostic baseline approach and several reinforcement learning approaches in two control problems in simulation.",
        "doi": "",
        "created": "2024-04-03",
        "url": "https://arxiv.org/abs/2404.03017",
        "authors": [
            "kehan long",
            "jorge cortes",
            "nikolay atanasov"
        ]
    },
    {
        "id": "2404.03037",
        "title": "model-based reinforcement learning for parameterized action spaces",
        "abstract": "we propose a novel model-based reinforcement learning algorithm -- dynamics learning and predictive control with parameterized actions (dlpa) -- for parameterized action markov decision processes (pamdps). the agent learns a parameterized-action-conditioned dynamics model and plans with a modified model predictive path integral control. we theoretically quantify the difference between the generated trajectory and the optimal trajectory during planning in terms of the value they achieved through the lens of lipschitz continuity. our empirical results on several standard benchmarks show that our algorithm achieves superior sample efficiency and asymptotic performance than state-of-the-art pamdp methods.",
        "doi": "",
        "created": "2024-04-03",
        "url": "https://arxiv.org/abs/2404.03037",
        "authors": [
            "renhao zhang",
            "haotian fu",
            "yilin miao",
            "george konidaris"
        ]
    },
    {
        "id": "2404.03443",
        "title": "part-attention based model make occluded person re-identification   stronger",
        "abstract": "the goal of occluded person re-identification (reid) is to retrieve specific pedestrians in occluded situations. however, occluded person reid still suffers from background clutter and low-quality local feature representations, which limits model performance. in our research, we introduce a new framework called pab-reid, which is a novel reid model incorporating part-attention mechanisms to tackle the aforementioned issues effectively. firstly, we introduce the human parsing label to guide the generation of more accurate human part attention maps. in addition, we propose a fine-grained feature focuser for generating fine-grained human local feature representations while suppressing background interference. moreover, we also design a part triplet loss to supervise the learning of human local features, which optimizes intra/inter-class distance. we conducted extensive experiments on specialized occlusion and regular reid datasets, showcasing that our approach outperforms the existing state-of-the-art methods.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03443",
        "authors": [
            "zhihao chen",
            "yiyuan ge"
        ]
    },
    {
        "id": "2404.03493",
        "title": "a methodology to study the impact of spiking neural network parameters   considering event-based automotive data",
        "abstract": "autonomous driving (ad) systems are considered as the future of human mobility and transportation. solving computer vision tasks such as image classification and object detection/segmentation, with high accuracy and low power/energy consumption, is highly needed to realize ad systems in real life. these requirements can potentially be satisfied by spiking neural networks (snns). however, the state-of-the-art works in snn-based ad systems still focus on proposing network models that can achieve high accuracy, and they have not systematically studied the roles of snn parameters when used for learning event-based automotive data. therefore, we still lack understanding of how to effectively develop snn models for ad systems. toward this, we propose a novel methodology to systematically study and analyze the impact of snn parameters considering event-based automotive data, then leverage this analysis for enhancing snn developments. to do this, we first explore different settings of snn parameters that directly affect the learning mechanism (i.e., batch size, learning rate, neuron threshold potential, and weight decay), then analyze the accuracy results. afterward, we propose techniques that jointly improve snn accuracy and reduce training time. experimental results show that our methodology can improve the snn models for ad systems than the state-of-the-art, as it achieves higher accuracy (i.e., 86%) for the ncars dataset, and it can also achieve iso-accuracy (i.e., ~85% with standard deviation less than 0.5%) while speeding up the training time by 1.9x. in this manner, our research work provides a set of guidelines for snn parameter enhancements, thereby enabling the practical developments of snn-based ad systems.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03493",
        "authors": [
            "iqra bano",
            "rachmad vidya wicaksana putra",
            "alberto marchisio",
            "muhammad shafique"
        ]
    },
    {
        "id": "2404.03528",
        "title": "banglaautokg: automatic bangla knowledge graph construction with   semantic neural graph filtering",
        "abstract": "knowledge graphs (kgs) have proven essential in information processing and reasoning applications because they link related entities and give context-rich information, supporting efficient information retrieval and knowledge discovery; presenting information flow in a very effective manner. despite being widely used globally, bangla is relatively underrepresented in kgs due to a lack of comprehensive datasets, encoders, ner (named entity recognition) models, pos (part-of-speech) taggers, and lemmatizers, hindering efficient information processing and reasoning applications in the language. addressing the kg scarcity in bengali, we propose banglaautokg, a pioneering framework that is able to automatically construct bengali kgs from any bangla text. we utilize multilingual llms to understand various languages and correlate entities and relations universally. by employing a translation dictionary to identify english equivalents and extracting word features from pre-trained bert models, we construct the foundational kg. to reduce noise and align word embeddings with our goal, we employ graph-based polynomial filters. lastly, we implement a gnn-based semantic filter, which elevates contextual understanding and trims unnecessary edges, culminating in the formation of the definitive kg. empirical findings and case studies demonstrate the universal effectiveness of our model, capable of autonomously constructing semantically enriched kgs from any text.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03528",
        "authors": [
            "azmine toushik wasi",
            "taki hasan rafi",
            "raima islam",
            "dong-kyu chae"
        ]
    },
    {
        "id": "2404.03563",
        "title": "easse-de: easier automatic sentence simplification evaluation for german",
        "abstract": "in this work, we propose easse-multi, a framework for easier automatic sentence evaluation for languages other than english. compared to the original easse framework, easse-multi does not focus only on english. it contains tokenizers and versions of text simplification evaluation metrics which are suitable for multiple languages. in this paper, we exemplify the usage of easse-multi for german ts, resulting in easse-de. further, we compare text simplification results when evaluating with different language or tokenization settings of the metrics. based on this, we formulate recommendations on how to make the evaluation of (german) ts models more transparent and better comparable. the code of easse-multi and its german specialisation (easse-de) can be found at https://github.com/rstodden/easse-de.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03563",
        "authors": [
            "regina stodden"
        ]
    },
    {
        "id": "2404.03604",
        "title": "a unified algorithmic framework for dynamic assortment optimization   under mnl choice",
        "abstract": "we consider assortment and inventory planning problems with dynamic stockout-based substitution effects and no replenishment. we consider two settings: 1. customers can see all available products when they arrive, which is commonly seen in physical stores. 2. the seller can choose to offer a subset of available products to each customer, which is typical on online platforms. both settings are known to be computationally challenging, and the current approximation algorithms for the two settings are quite different. we develop a unified algorithm framework under the mnl choice model for both settings. our algorithms improve on the state-of-the-art algorithms in terms of approximation guarantee, runtime, and the ability to manage uncertainty in the total number of customers and handle more complex constraints. in the process, we establish various novel properties of dynamic assortment planning (under the mnl choice) that may be useful more broadly.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03604",
        "authors": [
            "shuo sun",
            "rajan udwani",
            "zuo-jun max shen"
        ]
    },
    {
        "id": "2404.03635",
        "title": "wordepth: variational language prior for monocular depth estimation",
        "abstract": "three-dimensional (3d) reconstruction from a single image is an ill-posed problem with inherent ambiguities, i.e. scale. predicting a 3d scene from text description(s) is similarly ill-posed, i.e. spatial arrangements of objects described. we investigate the question of whether two inherently ambiguous modalities can be used in conjunction to produce metric-scaled reconstructions. to test this, we focus on monocular depth estimation, the problem of predicting a dense depth map from a single image, but with an additional text caption describing the scene. to this end, we begin by encoding the text caption as a mean and standard deviation; using a variational framework, we learn the distribution of the plausible metric reconstructions of 3d scenes corresponding to the text captions as a prior. to \"select\" a specific reconstruction or depth map, we encode the given image through a conditional sampler that samples from the latent space of the variational text encoder, which is then decoded to the output depth map. our approach is trained alternatingly between the text and image branches: in one optimization step, we predict the mean and standard deviation from the text description and sample from a standard gaussian, and in the other, we sample using a (image) conditional sampler. once trained, we directly predict depth from the encoded text using the conditional sampler. we demonstrate our approach on indoor (nyuv2) and outdoor (kitti) scenarios, where we show that language can consistently improve performance in both.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03635",
        "authors": [
            "ziyao zeng",
            "daniel wang",
            "fengyu yang",
            "hyoungseob park",
            "yangchao wu",
            "stefano soatto",
            "byung-woo hong",
            "dong lao",
            "alex wong"
        ]
    },
    {
        "id": "2404.03659",
        "title": "federated unlearning for human activity recognition",
        "abstract": "the rapid evolution of internet of things (iot) technology has spurred the widespread adoption of human activity recognition (har) in various daily life domains. federated learning (fl) is frequently utilized to build a global har model by aggregating user contributions without transmitting raw individual data. despite substantial progress in user privacy protection with fl, challenges persist. regulations like the general data protection regulation (gdpr) empower users to request data removal, raising a new query in fl: how can a har client request data removal without compromising other clients' privacy? in response, we propose a lightweight machine unlearning method for refining the fl har model by selectively removing a portion of a client's training data. our method employs a third-party dataset unrelated to model training. using kl divergence as a loss function for fine-tuning, we aim to align the predicted probability distribution on forgotten data with the third-party dataset. additionally, we introduce a membership inference evaluation method to assess unlearning effectiveness. experimental results across diverse datasets show our method achieves unlearning accuracy comparable to \\textit{retraining} methods, resulting in speedups ranging from hundreds to thousands.",
        "doi": "",
        "created": "2024-01-17",
        "url": "https://arxiv.org/abs/2404.03659",
        "authors": [
            "kongyang chen",
            "dongping zhang",
            "yaping chai",
            "weibin zhang",
            "shaowei wang",
            "jiaxing shen"
        ]
    },
    {
        "id": "2404.03660",
        "title": "machine learning in proton exchange membrane water electrolysis -- part   i: a knowledge-integrated framework",
        "abstract": "in this study, we propose to adopt a novel framework, knowledge-integrated machine learning, for advancing proton exchange membrane water electrolysis (pemwe) development. given the significance of pemwe in green hydrogen production and the inherent challenges in optimizing its performance, our framework aims to meld data-driven models with domain-specific insights systematically to address the domain challenges. we first identify the uncertainties originating from data acquisition conditions, data-driven model mechanisms, and domain expertise, highlighting their complementary characteristics in carrying information from different perspectives. building upon this foundation, we showcase how to adeptly decompose knowledge and extract unique information to contribute to the data augmentation, modeling process, and knowledge discovery. we demonstrate a hierarchical three-level framework, termed the \"ladder of knowledge-integrated machine learning\", in the pemwe context, applying it to three case studies within a context of cell degradation analysis to affirm its efficacy in interpolation, extrapolation, and information representation. this research lays the groundwork for more knowledge-informed enhancements in ml applications in engineering.",
        "doi": "",
        "created": "2024-01-23",
        "url": "https://arxiv.org/abs/2404.03660",
        "authors": [
            "xia chen",
            "alexander rex",
            "janis woelke",
            "christoph eckert",
            "boris bensmann",
            "richard hanke-rauschenbach",
            "philipp geyer"
        ]
    },
    {
        "id": "2404.03661",
        "title": "benchmarking formalisms for dynamic structure system modeling and   simulation",
        "abstract": "modeling and simulation of complex systems is key to explore systems dynamics. many scientific approaches were developed to represent dynamic structure systems but most of these approaches are efficient for some kinds of systems and inefficient for others. which approach can be adopted for different dynamic structure systems categories is a topic of interest for many researchers and until now has not been fully resolved. therefore it is essential to explore the existing approaches, understand them, and identify gaps. to fulfil this goal, we identified criteria at stake for a smooth flow from model creation to its simulation for dynamic structure systems. using these criteria, we benchmark the existing modeling formalisms focusing more on devs extensions, and use the results to identify approaches gaps and discuss them.",
        "doi": "",
        "created": "2024-01-25",
        "url": "https://arxiv.org/abs/2404.03661",
        "authors": [
            "aya attia",
            "cl\u00e9ment foucher",
            "luiz fernando lavado villa"
        ]
    },
    {
        "id": "2404.03662",
        "title": "x-lifecycle learning for cloud incident management using llms",
        "abstract": "incident management for large cloud services is a complex and tedious process and requires significant amount of manual efforts from on-call engineers (oces). oces typically leverage data from different stages of the software development lifecycle [sdlc] (e.g., codes, configuration, monitor data, service properties, service dependencies, trouble-shooting documents, etc.) to generate insights for detection, root causing and mitigating of incidents. recent advancements in large language models [llms] (e.g., chatgpt, gpt-4, gemini) created opportunities to automatically generate contextual recommendations to the oces assisting them to quickly identify and mitigate critical issues. however, existing research typically takes a silo-ed view for solving a certain task in incident management by leveraging data from a single stage of sdlc. in this paper, we demonstrate that augmenting additional contextual data from different stages of sdlc improves the performance of two critically important and practically challenging tasks: (1) automatically generating root cause recommendations for dependency failure related incidents, and (2) identifying ontology of service monitors used for automatically detecting incidents. by leveraging 353 incident and 260 monitor dataset from microsoft, we demonstrate that augmenting contextual information from different stages of the sdlc improves the performance over state-of-the-art methods.",
        "doi": "",
        "created": "2024-02-15",
        "url": "https://arxiv.org/abs/2404.03662",
        "authors": [
            "drishti goel",
            "fiza husain",
            "aditya singh",
            "supriyo ghosh",
            "anjaly parayil",
            "chetan bansal",
            "xuchao zhang",
            "saravan rajmohan"
        ]
    },
    {
        "id": "2404.03663",
        "title": "spike-driven transformer v2: meta spiking neural network architecture   inspiring the design of next-generation neuromorphic chips",
        "abstract": "neuromorphic computing, which exploits spiking neural networks (snns) on neuromorphic chips, is a promising energy-efficient alternative to traditional ai. cnn-based snns are the current mainstream of neuromorphic computing. by contrast, no neuromorphic chips are designed especially for transformer-based snns, which have just emerged, and their performance is only on par with cnn-based snns, offering no distinct advantage. in this work, we propose a general transformer-based snn architecture, termed as ``meta-spikeformer\", whose goals are: 1) lower-power, supports the spike-driven paradigm that there is only sparse addition in the network; 2) versatility, handles various vision tasks; 3) high-performance, shows overwhelming performance advantages over cnn-based snns; 4) meta-architecture, provides inspiration for future next-generation transformer-based neuromorphic chip designs. specifically, we extend the spike-driven transformer in \\citet{yao2023spike} into a meta architecture, and explore the impact of structure, spike-driven self-attention, and skip connection on its performance. on imagenet-1k, meta-spikeformer achieves 80.0\\% top-1 accuracy (55m), surpassing the current state-of-the-art (sota) snn baselines (66m) by 3.7\\%. this is the first direct training snn backbone that can simultaneously supports classification, detection, and segmentation, obtaining sota results in snns. finally, we discuss the inspiration of the meta snn architecture for neuromorphic chip design. source code and models are available at \\url{https://github.com/biclab/spike-driven-transformer-v2}.",
        "doi": "",
        "created": "2024-02-15",
        "url": "https://arxiv.org/abs/2404.03663",
        "authors": [
            "man yao",
            "jiakui hu",
            "tianxiang hu",
            "yifan xu",
            "zhaokun zhou",
            "yonghong tian",
            "bo xu",
            "guoqi li"
        ]
    },
    {
        "id": "2404.03665",
        "title": "serial parallel reliability redundancy allocation optimization for   energy efficient and fault tolerant cloud computing",
        "abstract": "serial-parallel redundancy is a reliable way to ensure service and systems will be available in cloud computing. that method involves making copies of the same system or program, with only one remaining active. when an error occurs, the inactive copy can step in as a backup right away, this provides continuous performance and uninterrupted operation. this approach is called parallel redundancy, otherwise known as active-active redundancy, and its exceptional when it comes to strategy. it creates duplicates of a system or service that are all running at once. by doing this fault tolerance increases since if one copy fails, the workload can be distributed across any replica thats functioning properly. reliability allocation depends on features in a system and the availability and fault tolerance you want from it. serial redundancy or parallel redundancies can be applied to increase the dependability of systems and services. to demonstrate how well this concept works, we looked into fixed serial parallel reliability redundancy allocation issues followed by using an innovative hybrid optimization technique to find the best possible allocation for peak dependability. we then measured our findings against other research.",
        "doi": "",
        "created": "2024-02-16",
        "url": "https://arxiv.org/abs/2404.03665",
        "authors": [
            "gutha jaya krishna"
        ]
    },
    {
        "id": "2404.03673",
        "title": "rl for consistency models: faster reward guided text-to-image generation",
        "abstract": "reinforcement learning (rl) has improved guided image generation with diffusion models by directly optimizing rewards that capture image quality, aesthetics, and instruction following capabilities. however, the resulting generative policies inherit the same iterative sampling process of diffusion models that causes slow generation. to overcome this limitation, consistency models proposed learning a new class of generative models that directly map noise to data, resulting in a model that can generate an image in as few as one sampling iteration. in this work, to optimize text-to-image generative models for task specific rewards and enable fast training and inference, we propose a framework for fine-tuning consistency models via rl. our framework, called reinforcement learning for consistency model (rlcm), frames the iterative inference process of a consistency model as an rl procedure. rlcm improves upon rl fine-tuned diffusion models on text-to-image generation capabilities and trades computation during inference time for sample quality. experimentally, we show that rlcm can adapt text-to-image consistency models to objectives that are challenging to express with prompting, such as image compressibility, and those derived from human feedback, such as aesthetic quality. comparing to rl finetuned diffusion models, rlcm trains significantly faster, improves the quality of the generation measured under the reward objectives, and speeds up the inference procedure by generating high quality images with as few as two inference steps. our code is available at https://rlcm.owenoertell.com",
        "doi": "",
        "created": "2024-03-25",
        "url": "https://arxiv.org/abs/2404.03673",
        "authors": [
            "owen oertell",
            "jonathan d. chang",
            "yiyi zhang",
            "kiant\u00e9 brantley",
            "wen sun"
        ]
    },
    {
        "id": "2404.03676",
        "title": "neural information organizing and processing -- neural machines",
        "abstract": "the informational synthesis of neural structures, processes, parameters and characteristics that allow a unified description and modeling as neural machines of natural and artificial neural systems is presented. the general informational parameters as the global quantitative measure of the neural systems computing potential as absolute and relative neural power were proposed. neural information organizing and processing follows the way in which nature manages neural information by developing functions, functionalities and circuits related to different internal or peripheral components and also to the whole system through a non-deterministic memorization, fragmentation and aggregation of afferent and efferent information, deep neural information processing representing multiple alternations of fragmentation and aggregation stages. the relevant neural characteristics were integrated into a neural machine type model that incorporates unitary also peripheral or interface components as the central ones. the proposed approach allows overcoming the technical constraints in artificial computational implementations of neural information processes and also provides a more relevant description of natural ones.",
        "doi": "",
        "created": "2024-02-15",
        "url": "https://arxiv.org/abs/2404.03676",
        "authors": [
            "iosif iulian petrila"
        ]
    },
    {
        "id": "2404.03678",
        "title": "machine learning augmented diagnostic testing to identify sources of   variability in test performance",
        "abstract": "diagnostic tests which can detect pre-clinical or sub-clinical infection, are one of the most powerful tools in our armoury of weapons to control infectious diseases. considerable effort has been therefore paid to improving diagnostic testing for human, plant and animal diseases, including strategies for targeting the use of diagnostic tests towards individuals who are more likely to be infected. here, we follow other recent proposals to further refine this concept, by using machine learning to assess the situational risk under which a diagnostic test is applied to augment its interpretation . we develop this to predict the occurrence of breakdowns of cattle herds due to bovine tuberculosis, exploiting the availability of exceptionally detailed testing records. we show that, without compromising test specificity, test sensitivity can be improved so that the proportion of infected herds detected by the skin test, improves by over 16 percentage points. while many risk factors are associated with increased risk of becoming infected, of note are several factors which suggest that, in some herds there is a higher risk of infection going undetected, including effects that are correlated to the veterinary practice conducting the test, and number of livestock moved off the herd.",
        "doi": "",
        "created": "2024-03-28",
        "url": "https://arxiv.org/abs/2404.03678",
        "authors": [
            "christopher j. banks",
            "aeron sanchez",
            "vicki stewart",
            "kate bowen",
            "graham smith",
            "rowland r. kao"
        ]
    },
    {
        "id": "2404.03683",
        "title": "stream of search (sos): learning to search in language",
        "abstract": "language models are rarely shown fruitful mistakes while training. they then struggle to look beyond the next token, suffering from a snowballing of errors and struggling to predict the consequence of their actions several steps ahead. in this paper, we show how language models can be taught to search by representing the process of search in language, as a flattened string -- a stream of search (sos). we propose a unified language for search that captures an array of different symbolic search strategies. we demonstrate our approach using the simple yet difficult game of countdown, where the goal is to combine input numbers with arithmetic operations to reach a target number. we pretrain a transformer-based language model from scratch on a dataset of streams of search generated by heuristic solvers. we find that sos pretraining increases search accuracy by 25% over models trained to predict only the optimal search trajectory. we further finetune this model with two policy improvement methods: advantage-induced policy alignment (apa) and self-taught reasoner (star). the finetuned sos models solve 36% of previously unsolved problems, including problems that cannot be solved by any of the heuristic solvers. our results indicate that language models can learn to solve problems via search, self-improve to flexibly use different search strategies, and potentially discover new ones.",
        "doi": "",
        "created": "2024-04-01",
        "url": "https://arxiv.org/abs/2404.03683",
        "authors": [
            "kanishk gandhi",
            "denise lee",
            "gabriel grand",
            "muxin liu",
            "winson cheng",
            "archit sharma",
            "noah d. goodman"
        ]
    },
    {
        "id": "2404.03685",
        "title": "cooperative evolutionary pressure and diminishing returns might explain   the fermi paradox: on what super-ais are like",
        "abstract": "with an evolutionary approach, the basis of morality can be explained as adaptations to problems of cooperation. with 'evolution' taken in a broad sense, evolving ais that satisfy the conditions for evolution to apply will be subject to the same cooperative evolutionary pressure as biological entities. here the adaptiveness of increased cooperation as material safety and wealth increase is discussed -- for humans, for other societies, and for ais. diminishing beneficial returns from increased access to material resources also suggests the possibility that, on the whole, there will be no incentive to for instance colonize entire galaxies, thus providing a possible explanation of the fermi paradox, wondering where everybody is. it is further argued that old societies could engender, give way to, super-ais, since it is likely that super-ais are feasible, and fitter. closing is an aside on effective ways for morals and goals to affect life and society, emphasizing environments, cultures, and laws, and exemplified by how to eat.   appended are an algorithm for colonizing for example a galaxy quickly, models of the evolution of cooperation and fairness under diminishing returns, and software for simulating signaling development. it is also noted that there can be no exponential colonization or reproduction, for mathematical reasons, as each entity takes up a certain amount of space.",
        "doi": "",
        "created": "2024-04-01",
        "url": "https://arxiv.org/abs/2404.03685",
        "authors": [
            "daniel vallstrom"
        ]
    },
    {
        "id": "2404.03686",
        "title": "securing social spaces: harnessing deep learning to eradicate   cyberbullying",
        "abstract": "in today's digital world, cyberbullying is a serious problem that can harm the mental and physical health of people who use social media. this paper explains just how serious cyberbullying is and how it really affects indi-viduals exposed to it. it also stresses how important it is to find better ways to detect cyberbullying so that online spaces can be safer. plus, it talks about how making more accurate tools to spot cyberbullying will be really helpful in the future. our paper introduces a deep learning-based ap-proach, primarily employing bert and bilstm architectures, to effective-ly address cyberbullying. this approach is designed to analyse large vol-umes of posts and predict potential instances of cyberbullying in online spaces. our results demonstrate the superiority of the hatebert model, an extension of bert focused on hate speech detection, among the five mod-els, achieving an accuracy rate of 89.16%. this research is a significant con-tribution to \"computational intelligence for social transformation,\" prom-ising a safer and more inclusive digital landscape.",
        "doi": "",
        "created": "2024-04-01",
        "url": "https://arxiv.org/abs/2404.03686",
        "authors": [
            "rohan biswas",
            "kasturi ganguly",
            "arijit das",
            "diganta saha"
        ]
    },
    {
        "id": "2404.03687",
        "title": "drive: dual gradient-based rapid iterative pruning",
        "abstract": "modern deep neural networks (dnns) consist of millions of parameters, necessitating high-performance computing during training and inference. pruning is one solution that significantly reduces the space and time complexities of dnns. traditional pruning methods that are applied post-training focus on streamlining inference, but there are recent efforts to leverage sparsity early on by pruning before training. pruning methods, such as iterative magnitude-based pruning (imp) achieve up to a 90% parameter reduction while retaining accuracy comparable to the original model. however, this leads to impractical runtime as it relies on multiple train-prune-reset cycles to identify and eliminate redundant parameters. in contrast, training agnostic early pruning methods, such as snip and synflow offer fast pruning but fall short of the accuracy achieved by imp at high sparsities. to bridge this gap, we present dual gradient-based rapid iterative pruning (drive), which leverages dense training for initial epochs to counteract the randomness inherent at the initialization. subsequently, it employs a unique dual gradient-based metric for parameter ranking. it has been experimentally demonstrated for vgg and resnet architectures on cifar-10/100 and tiny imagenet, and resnet on imagenet that drive consistently has superior performance over other training-agnostic early pruning methods in accuracy. notably, drive is 43$\\times$ to 869$\\times$ faster than imp for pruning.",
        "doi": "",
        "created": "2024-04-01",
        "url": "https://arxiv.org/abs/2404.03687",
        "authors": [
            "dhananjay saikumar",
            "blesson varghese"
        ]
    },
    {
        "id": "2404.03689",
        "title": "a tutorial on gaussian process learning-based model predictive control",
        "abstract": "this tutorial provides a systematic introduction to gaussian process learning-based model predictive control (gp-mpc), an advanced approach integrating gaussian process (gp) with model predictive control (mpc) for enhanced control in complex systems. it begins with gp regression fundamentals, illustrating how it enriches mpc with enhanced predictive accuracy and robust handling of uncertainties. a central contribution of this tutorial is the first detailed, systematic mathematical formulation of gp-mpc in literature, focusing on deriving the approximation of means and variances propagation for gp multi-step predictions. practical applications in robotics control, such as path-following for mobile robots in challenging terrains and mixed-vehicle platooning, are discussed to demonstrate the real-world effectiveness and adaptability of gp-mpc. this tutorial aims to make gp-mpc accessible to researchers and practitioners, enriching the learning-based control field with in-depth theoretical and practical insights and fostering further innovations in complex system control.",
        "doi": "",
        "created": "2024-04-01",
        "url": "https://arxiv.org/abs/2404.03689",
        "authors": [
            "jie wang",
            "youmin zhang"
        ]
    },
    {
        "id": "2404.03693",
        "title": "improve knowledge distillation via label revision and data selection",
        "abstract": "knowledge distillation (kd) has become a widely used technique in the field of model compression, which aims to transfer knowledge from a large teacher model to a lightweight student model for efficient network development. in addition to the supervision of ground truth, the vanilla kd method regards the predictions of the teacher as soft labels to supervise the training of the student model. based on vanilla kd, various approaches have been developed to further improve the performance of the student model. however, few of these previous methods have considered the reliability of the supervision from teacher models. supervision from erroneous predictions may mislead the training of the student model. this paper therefore proposes to tackle this problem from two aspects: label revision to rectify the incorrect supervision and data selection to select appropriate samples for distillation to reduce the impact of erroneous supervision. in the former, we propose to rectify the teacher's inaccurate predictions using the ground truth. in the latter, we introduce a data selection technique to choose suitable training samples to be supervised by the teacher, thereby reducing the impact of incorrect predictions to some extent. experiment results demonstrate the effectiveness of our proposed method, and show that our method can be combined with other distillation approaches, improving their performance.",
        "doi": "",
        "created": "2024-04-02",
        "url": "https://arxiv.org/abs/2404.03693",
        "authors": [
            "weichao lan",
            "yiu-ming cheung",
            "qing xu",
            "buhua liu",
            "zhikai hu",
            "mengke li",
            "zhenghua chen"
        ]
    },
    {
        "id": "2404.03694",
        "title": "cultural influence on autonomous vehicles acceptance",
        "abstract": "autonomous vehicles and other intelligent transport systems have been evolving rapidly and are being increasingly deployed worldwide. previous work has shown that perceptions of autonomous vehicles and attitudes towards them depend on various attributes, including the respondent's age, education level and background. these findings with respect to age and educational level are generally uniform, such as showing that younger respondents are typically more accepting of autonomous vehicles, as are those with higher education levels. however the influence of factors such as culture are much less clear cut. in this paper we analyse the relationship between acceptance of autonomous vehicles and national culture by means of the well-known hofstede cultural model.",
        "doi": "",
        "created": "2024-04-03",
        "url": "https://arxiv.org/abs/2404.03694",
        "authors": [
            "chowdhury shahriar muzammel",
            "maria spichkova",
            "james harland"
        ]
    },
    {
        "id": "2404.03696",
        "title": "convolutional variational autoencoders for secure lossy image   compression in remote sensing",
        "abstract": "the volume of remote sensing data is experiencing rapid growth, primarily due to the plethora of space and air platforms equipped with an array of sensors. due to limited hardware and battery constraints the data is transmitted back to earth for processing. the large amounts of data along with security concerns call for new compression and encryption techniques capable of preserving reconstruction quality while minimizing the transmission cost of this data back to earth. this study investigates image compression based on convolutional variational autoencoders (cvae), which are capable of substantially reducing the volume of transmitted data while guaranteeing secure lossy image reconstruction. cvaes have been demonstrated to outperform conventional compression methods such as jpeg2000 by a substantial margin on compression benchmark datasets. the proposed model draws on the strength of the cvaes capability to abstract data into highly insightful latent spaces, and combining it with the utilization of an entropy bottleneck is capable of finding an optimal balance between compressibility and reconstruction quality. the balance is reached by optimizing over a composite loss function that represents the rate-distortion curve.",
        "doi": "",
        "created": "2024-04-03",
        "url": "https://arxiv.org/abs/2404.03696",
        "authors": [
            "alessandro giuliano",
            "s. andrew gadsden",
            "waleed hilal",
            "john yawney"
        ]
    },
    {
        "id": "2404.03701",
        "title": "predictive analytics of varieties of potatoes",
        "abstract": "we explore the application of machine learning algorithms to predict the suitability of russet potato clones for advancement in breeding trials. leveraging data from manually collected trials in the state of oregon, we investigate the potential of a wide variety of state-of-the-art binary classification models. we conduct a comprehensive analysis of the dataset that includes preprocessing, feature engineering, and imputation to address missing values. we focus on several key metrics such as accuracy, f1-score, and matthews correlation coefficient (mcc) for model evaluation. the top-performing models, namely the multi-layer perceptron (mlpc), histogram-based gradient boosting classifier (hgbc), and a support vector machine (svc), demonstrate consistent and significant results. variable selection further enhances model performance and identifies influential features in predicting trial outcomes. the findings emphasize the potential of machine learning in streamlining the selection process for potato varieties, offering benefits such as increased efficiency, substantial cost savings, and judicious resource utilization. our study contributes insights into precision agriculture and showcases the relevance of advanced technologies for informed decision-making in breeding programs.",
        "doi": "",
        "created": "2024-04-03",
        "url": "https://arxiv.org/abs/2404.03701",
        "authors": [
            "fabiana ferracina",
            "bala krishnamoorthy",
            "mahantesh halappanavar",
            "shengwei hu",
            "vidyasagar sathuvalli"
        ]
    },
    {
        "id": "2404.03702",
        "title": "personalized federated learning for spatio-temporal forecasting: a dual   semantic alignment-based contrastive approach",
        "abstract": "the existing federated learning (fl) methods for spatio-temporal forecasting fail to capture the inherent spatio-temporal heterogeneity, which calls for personalized fl (pfl) methods to model the spatio-temporally variant patterns. while contrastive learning approach is promising in addressing spatio-temporal heterogeneity, the existing methods are noneffective in determining negative pairs and can hardly apply to pfl paradigm. to tackle this limitation, we propose a novel pfl method, named federated dual semantic alignment-based contrastive learning (fuels), which can adaptively align positive and negative pairs based on semantic similarity, thereby injecting precise spatio-temporal heterogeneity into the latent representation space by auxiliary contrastive tasks. from temporal perspective, a hard negative filtering module is introduced to dynamically align heterogeneous temporal representations for the supplemented intra-client contrastive task. from spatial perspective, we design lightweight-but-efficient prototypes as client-level semantic representations, based on which the server evaluates spatial similarity and yields client-customized global prototypes for the supplemented inter-client contrastive task. extensive experiments demonstrate that fuels outperforms state-of-the-art methods, with communication cost decreasing by around 94%.",
        "doi": "",
        "created": "2024-04-03",
        "url": "https://arxiv.org/abs/2404.03702",
        "authors": [
            "qingxiang liu",
            "sheng sun",
            "yuxuan liang",
            "jingjing xue",
            "min liu"
        ]
    },
    {
        "id": "2404.03703",
        "title": "mitigating analytical variability in fmri results with style transfer",
        "abstract": "we propose a novel approach to improve the reproducibility of neuroimaging results by converting statistic maps across different functional mri pipelines. we make the assumption that pipelines can be considered as a style component of data and propose to use different generative models, among which, diffusion models (dm) to convert data between pipelines. we design a new dm-based unsupervised multi-domain image-to-image transition framework and constrain the generation of 3d fmri statistic maps using the latent space of an auxiliary classifier that distinguishes statistic maps from different pipelines. we extend traditional sampling techniques used in dm to improve the transition performance. our experiments demonstrate that our proposed methods are successful: pipelines can indeed be transferred, providing an important source of data augmentation for future medical studies.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03703",
        "authors": [
            "elodie germani",
            "elisa fromont",
            "camille maumet"
        ]
    },
    {
        "id": "2404.03704",
        "title": "improvement of performance in freezing of gait detection in parkinsons   disease using transformer networks and a single waist worn triaxial   accelerometer",
        "abstract": "freezing of gait (fog) is one of the most incapacitating symptoms in parkinsons disease, affecting more than 50 percent of patients in advanced stages of the disease. the presence of fog may lead to falls and a loss of independence with a consequent reduction in the quality of life. wearable technology and artificial intelligence have been used for automatic fog detection to optimize monitoring. however, differences between laboratory and daily-life conditions present challenges for the implementation of reliable detection systems. consequently, improvement of fog detection methods remains important to provide accurate monitoring mechanisms intended for free-living and real-time use. this paper presents advances in automatic fog detection using a single body-worn triaxial accelerometer and a novel classification algorithm based on transformers and convolutional networks. this study was performed with data from 21 patients who manifested fog episodes while performing activities of daily living in a home setting. results indicate that the proposed fog-transformer can bring a significant improvement in fog detection using leave-one-subject-out cross-validation (loso cv). these results bring opportunities for the implementation of accurate monitoring systems for use in ambulatory or home settings.",
        "doi": "10.1016/j.engappai.2022.105482",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03704",
        "authors": [
            "luis sigcha",
            "luigi borz\u00ec",
            "ignacio pav\u00f3n",
            "n\u00e9lson costa",
            "susana costa",
            "pedro arezes",
            "juan-manuel l\u00f3pez",
            "guillermo de arcas"
        ]
    },
    {
        "id": "2404.03706",
        "title": "bi-level guided diffusion models for zero-shot medical imaging inverse   problems",
        "abstract": "in the realm of medical imaging, inverse problems aim to infer high-quality images from incomplete, noisy measurements, with the objective of minimizing expenses and risks to patients in clinical settings. the diffusion models have recently emerged as a promising approach to such practical challenges, proving particularly useful for the zero-shot inference of images from partially acquired measurements in magnetic resonance imaging (mri) and computed tomography (ct). a central challenge in this approach, however, is how to guide an unconditional prediction to conform to the measurement information. existing methods rely on deficient projection or inefficient posterior score approximation guidance, which often leads to suboptimal performance. in this paper, we propose \\underline{\\textbf{b}}i-level \\underline{g}uided \\underline{d}iffusion \\underline{m}odels ({bgdm}), a zero-shot imaging framework that efficiently steers the initial unconditional prediction through a \\emph{bi-level} guidance strategy. specifically, bgdm first approximates an \\emph{inner-level} conditional posterior mean as an initial measurement-consistent reference point and then solves an \\emph{outer-level} proximal optimization objective to reinforce the measurement consistency. our experimental findings, using publicly available mri and ct medical datasets, reveal that bgdm is more effective and efficient compared to the baselines, faithfully generating high-fidelity medical images and substantially reducing hallucinatory artifacts in cases of severe degradation.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03706",
        "authors": [
            "hossein askari",
            "fred roosta",
            "hongfu sun"
        ]
    },
    {
        "id": "2404.03707",
        "title": "investigating the robustness of counterfactual learning to rank models:   a reproducibility study",
        "abstract": "counterfactual learning to rank (cltr) has attracted extensive attention in the ir community for its ability to leverage massive logged user interaction data to train ranking models. while the cltr models can be theoretically unbiased when the user behavior assumption is correct and the propensity estimation is accurate, their effectiveness is usually empirically evaluated via simulation-based experiments due to a lack of widely-available, large-scale, real click logs. however, the mainstream simulation-based experiments are somewhat limited as they often feature a single, deterministic production ranker and simplified user simulation models to generate the synthetic click logs. as a result, the robustness of cltr models in complex and diverse situations is largely unknown and needs further investigation.   to address this problem, in this paper, we aim to investigate the robustness of existing cltr models in a reproducibility study with extensive simulation-based experiments that (1) use both deterministic and stochastic production rankers, each with different ranking performance, and (2) leverage multiple user simulation models with different user behavior assumptions. we find that the dla models and ips-dcm show better robustness under various simulation settings than ips-pbm and prs with offline propensity estimation. besides, the existing cltr models often fail to outperform the naive click baselines when the production ranker has relatively high ranking performance or certain randomness, which suggests an urgent need for developing new cltr algorithms that work for these settings.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03707",
        "authors": [
            "zechun niu",
            "jiaxin mao",
            "qingyao ai",
            "ji-rong wen"
        ]
    },
    {
        "id": "2404.03708",
        "title": "dendrites endow artificial neural networks with accurate, robust and   parameter-efficient learning",
        "abstract": "artificial neural networks (anns) are at the core of most deep learning (dl) algorithms that successfully tackle complex problems like image recognition, autonomous driving, and natural language processing. however, unlike biological brains who tackle similar problems in a very efficient manner, dl algorithms require a large number of trainable parameters, making them energy-intensive and prone to overfitting. here, we show that a new ann architecture that incorporates the structured connectivity and restricted sampling properties of biological dendrites counteracts these limitations. we find that dendritic anns are more robust to overfitting and outperform traditional anns on several image classification tasks while using significantly fewer trainable parameters. this is achieved through the adoption of a different learning strategy, whereby most of the nodes respond to several classes, unlike classical anns that strive for class-specificity. these findings suggest that the incorporation of dendrites can make learning in anns precise, resilient, and parameter-efficient and shed new light on how biological features can impact the learning strategies of anns.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03708",
        "authors": [
            "spyridon chavlis",
            "panayiota poirazi"
        ]
    },
    {
        "id": "2404.03709",
        "title": "proceedings 12th international workshop on theorem proving components   for educational software",
        "abstract": "the thedu series pursues the smooth transition from an intuitive way of doing mathematics at secondary school to a more formal approach to the subject in stem education, while favouring software support for this transition by exploiting the power of theorem-proving technologies. what follows is a brief description of how the present volume contributes to this enterprise.   the 12th international workshop on theorem proving components for educational software(thedu'23), was a satellite event of the 29th international conference on automated deduction (cade 2023), july 1-4, 2023, rome, italy. thedu'23 was very successful, with one invited talk, by yves bertot (inria, france), \"the challenges of using type theory to teach mathematics\", and seven regular contributions. an open call for papers was then issued, to which eight contributions were submitted. seven submissions have been accepted by our reviewers, who jointly produced at least three careful reports on each of the contributions. the resulting revised papers are collected in the present volume.   we, the volume editors, hope that this collection of papers will further promote the development of theorem-proving based software, and that it will allow to improve the mutual understanding between computer scientists, mathematicians and stakeholders in education.   pc chairs:julien narboux (university of strasbourg, france); walther neuper (jku, johannes kepler university, linz, austria); pedro quaresma (university of coimbra, portugal)",
        "doi": "10.4204/eptcs.400",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03709",
        "authors": [
            "julien narboux",
            "walther neuper",
            "pedro quaresma"
        ]
    },
    {
        "id": "2404.03710",
        "title": "self-organized arrival system for urban air mobility",
        "abstract": "urban air mobility is an innovative mode of transportation in which electric vertical takeoff and landing (evtol) vehicles operate between nodes called vertiports. we outline a self-organized vertiport arrival system based on deep reinforcement learning. the airspace around the vertiport is assumed to be circular, and the vehicles can freely operate inside. each aircraft is considered an individual agent and follows a shared policy, resulting in decentralized actions that are based on local information. we investigate the development of the reinforcement learning policy during training and illustrate how the algorithm moves from suboptimal local holding patterns to a safe and efficient final policy. the latter is validated in simulation-based scenarios and also deployed on small-scale unmanned aerial vehicles to showcase its real-world usability.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03710",
        "authors": [
            "martin waltz",
            "ostap okhrin",
            "michael schultz"
        ]
    },
    {
        "id": "2404.03712",
        "title": "proceedings 15th workshop on programming language approaches to   concurrency and communication-centric software",
        "abstract": "this volume contains the proceedings of places 2024, the 15th edition of the workshop on programming language approaches to concurrency and communication-centric software. the places workshop series offers a forum for researchers from different fields to exchange new ideas about the challenges of modern and future programming, where concurrency and distribution are the norm rather than a marginal concern.   places 2024 was held on 6 april 2024 in luxembourg city, luxembourg. the programme included keynote talks by mariangiola dezani-ciancaglini and peter m\\\"uller, presentations of five research papers, and three talks about preliminary or already-published work that could foster interesting discussion during the workshop.   these proceedings contain the five accepted research papers, the abstracts of the keynote talks, and a list of the other contributions.",
        "doi": "10.4204/eptcs.401",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03712",
        "authors": [
            "diana costa",
            "raymond hu"
        ]
    },
    {
        "id": "2404.03713",
        "title": "explaining explainability: understanding concept activation vectors",
        "abstract": "recent interpretability methods propose using concept-based explanations to translate the internal representations of deep learning models into a language that humans are familiar with: concepts. this requires understanding which concepts are present in the representation space of a neural network. one popular method for finding concepts is concept activation vectors (cavs), which are learnt using a probe dataset of concept exemplars. in this work, we investigate three properties of cavs. cavs may be: (1) inconsistent between layers, (2) entangled with different concepts, and (3) spatially dependent. each property provides both challenges and opportunities in interpreting models. we introduce tools designed to detect the presence of these properties, provide insight into how they affect the derived explanations, and provide recommendations to minimise their impact. understanding these properties can be used to our advantage. for example, we introduce spatially dependent cavs to test if a model is translation invariant with respect to a specific concept and class. our experiments are performed on imagenet and a new synthetic dataset, elements. elements is designed to capture a known ground truth relationship between concepts and classes. we release this dataset to facilitate further research in understanding and evaluating interpretability methods.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03713",
        "authors": [
            "angus nicolson",
            "lisa schut",
            "j. alison noble",
            "yarin gal"
        ]
    },
    {
        "id": "2404.03714",
        "title": "spikeexplorer: hardware-oriented design space exploration for spiking   neural networks on fpga",
        "abstract": "one of today's main concerns is to bring artificial intelligence power to embedded systems for edge applications. the hardware resources and power consumption required by state-of-the-art models are incompatible with the constrained environments observed in edge systems, such as iot nodes and wearable devices. spiking neural networks (snns) can represent a solution in this sense: inspired by neuroscience, they reach unparalleled power and resource efficiency when run on dedicated hardware accelerators. however, when designing such accelerators, the amount of choices that can be taken is huge. this paper presents spikexplorer, a modular and flexible python tool for hardware-oriented automatic design space exploration to automate the configuration of fpga accelerators for snns. using bayesian optimizations, spikerexplorer enables hardware-centric multi-objective optimization, supporting factors such as accuracy, area, latency, power, and various combinations during the exploration process. the tool searches the optimal network architecture, neuron model, and internal and training parameters, trying to reach the desired constraints imposed by the user. it allows for a straightforward network configuration, providing the full set of explored points for the user to pick the trade-off that best fits the needs. the potential of spikexplorer is showcased using three benchmark datasets. it reaches 95.8% accuracy on the mnist dataset, with a power consumption of 180mw/image and a latency of 0.12 ms/image, making it a powerful tool for automatically optimizing snns.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03714",
        "authors": [
            "dario padovano",
            "alessio carpegna",
            "alessandro savino",
            "stefano di carlo"
        ]
    },
    {
        "id": "2404.03715",
        "title": "direct nash optimization: teaching language models to self-improve with   general preferences",
        "abstract": "this paper studies post-training large language models (llms) using preference feedback from a powerful oracle to help a model iteratively improve over itself. the typical approach for post-training llms involves reinforcement learning from human feedback (rlhf), which traditionally separates reward learning and subsequent policy optimization. however, such a reward maximization approach is limited by the nature of \"point-wise\" rewards (such as bradley-terry model), which fails to express complex intransitive or cyclic preference relations. while advances on rlhf show reward learning and policy optimization can be merged into a single contrastive objective for stability, they yet still remain tethered to the reward maximization framework. recently, a new wave of research sidesteps the reward maximization presumptions in favor of directly optimizing over \"pair-wise\" or general preferences. in this paper, we introduce direct nash optimization (dno), a provable and scalable algorithm that marries the simplicity and stability of contrastive learning with theoretical generality from optimizing general preferences. because dno is a batched on-policy algorithm using a regression-based objective, its implementation is straightforward and efficient. moreover, dno enjoys monotonic improvement across iterations that help it improve even over a strong teacher (such as gpt-4). in our experiments, a resulting 7b parameter orca-2.5 model aligned by dno achieves the state-of-the-art win-rate against gpt-4-turbo of 33% on alpacaeval 2.0 (even after controlling for response length), an absolute gain of 26% (7% to 33%) over the initializing model. it outperforms models with far more parameters, including mistral large, self-rewarding lm (70b parameters), and older versions of gpt-4.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03715",
        "authors": [
            "corby rosset",
            "ching-an cheng",
            "arindam mitra",
            "michael santacroce",
            "ahmed awadallah",
            "tengyang xie"
        ]
    },
    {
        "id": "2404.03732",
        "title": "shroom-indelab at semeval-2024 task 6: zero- and few-shot llm-based   classification for hallucination detection",
        "abstract": "we describe the university of amsterdam intelligent data engineering lab team's entry for the semeval-2024 task 6 competition. the shroom-indelab system builds on previous work on using prompt programming and in-context learning with large language models (llms) to build classifiers for hallucination detection, and extends that work through the incorporation of context-specific definition of task, role, and target concept, and automated generation of examples for use in a few-shot prompting approach. the resulting system achieved fourth-best and sixth-best performance in the model-agnostic track and model-aware tracks for task 6, respectively, and evaluation using the validation sets showed that the system's classification decisions were consistent with those of the crowd-sourced human labellers. we further found that a zero-shot approach provided better accuracy than a few-shot approach using automatically generated examples. code for the system described in this paper is available on github.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03732",
        "authors": [
            "bradley p. allen",
            "fina polat",
            "paul groth"
        ]
    },
    {
        "id": "2404.03734",
        "title": "legible and proactive robot planning for prosocial human-robot   interactions",
        "abstract": "humans have a remarkable ability to fluently engage in joint collision avoidance in crowded navigation tasks despite the complexities and uncertainties inherent in human behavior. underlying these interactions is a mutual understanding that (i) individuals are prosocial, that is, there is equitable responsibility in avoiding collisions, and (ii) individuals should behave legibly, that is, move in a way that clearly conveys their intent to reduce ambiguity in how they intend to avoid others. toward building robots that can safely and seamlessly interact with humans, we propose a general robot trajectory planning framework for synthesizing legible and proactive behaviors and demonstrate that our robot planner naturally leads to prosocial interactions. specifically, we introduce the notion of a markup factor to incentivize legible and proactive behaviors and an inconvenience budget constraint to ensure equitable collision avoidance responsibility. we evaluate our approach against well-established multi-agent planning algorithms and show that using our approach produces safe, fluent, and prosocial interactions. we demonstrate the real-time feasibility of our approach with human-in-the-loop simulations. project page can be found at https://uw-ctrl.github.io/phri/.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03734",
        "authors": [
            "jasper geldenbott",
            "karen leung"
        ]
    },
    {
        "id": "2404.03736",
        "title": "sc4d: sparse-controlled video-to-4d generation and motion transfer",
        "abstract": "recent advances in 2d/3d generative models enable the generation of dynamic 3d objects from a single-view video. existing approaches utilize score distillation sampling to form the dynamic scene as dynamic nerf or dense 3d gaussians. however, these methods struggle to strike a balance among reference view alignment, spatio-temporal consistency, and motion fidelity under single-view conditions due to the implicit nature of nerf or the intricate dense gaussian motion prediction. to address these issues, this paper proposes an efficient, sparse-controlled video-to-4d framework named sc4d, that decouples motion and appearance to achieve superior video-to-4d generation. moreover, we introduce adaptive gaussian (ag) initialization and gaussian alignment (ga) loss to mitigate shape degeneration issue, ensuring the fidelity of the learned motion and shape. comprehensive experimental results demonstrate that our method surpasses existing methods in both quality and efficiency. in addition, facilitated by the disentangled modeling of motion and appearance of sc4d, we devise a novel application that seamlessly transfers the learned motion onto a diverse array of 4d entities according to textual descriptions.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03736",
        "authors": [
            "zijie wu",
            "chaohui yu",
            "yanqin jiang",
            "chenjie cao",
            "fan wang",
            "xiang bai"
        ]
    },
    {
        "id": "2404.03740",
        "title": "randomized greedy methods for weak submodular sensor selection with   robustness considerations",
        "abstract": "we study a pair of budget- and performance-constrained weak submodular maximization problems. for computational efficiency, we explore the use of stochastic greedy algorithms which limit the search space via random sampling instead of the standard greedy procedure which explores the entire feasible search space. we propose a pair of stochastic greedy algorithms, namely, modified randomized greedy (mrg) and dual randomized greedy (drg) to approximately solve the budget- and performance-constrained problems, respectively. for both algorithms, we derive approximation guarantees that hold with high probability. we then examine the use of drg in robust optimization problems wherein the objective is to maximize the worst-case of a number of weak submodular objectives and propose the randomized weak submodular saturation algorithm (random-wssa). we further derive a high-probability guarantee for when random-wssa successfully constructs a robust solution. finally, we showcase the effectiveness of these algorithms in a variety of relevant uses within the context of earth-observing leo constellations which estimate atmospheric weather conditions and provide earth coverage.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03740",
        "authors": [
            "ege c. kaya",
            "michael hibbard",
            "takashi tanaka",
            "ufuk topcu",
            "abolfazl hashemi"
        ]
    },
    {
        "id": "2404.03741",
        "title": "a high-fidelity simulation framework for grasping stability analysis in   human casualty manipulation",
        "abstract": "recently, there has been a growing interest in rescue robots due to their vital role in addressing emergency scenarios and providing crucial support in challenging or hazardous situations where human intervention is difficult. however, very few of these robots are capable of actively engaging with humans and undertaking physical manipulation tasks. this limitation is largely attributed to the absence of tools that can realistically simulate physical interactions, especially the contact mechanisms between a robotic gripper and a human body. in this letter, we aim to address key limitations in current developments towards robotic casualty manipulation. firstly, we present an integrative simulation framework for casualty manipulation. we adapt a finite element method (fem) tool into the grasping and manipulation scenario, and the developed framework can provide accurate biomechanical reactions resulting from manipulation. secondly, we conduct a detailed assessment of grasping stability during casualty grasping and manipulation simulations. to validate the necessity and superior performance of the proposed high-fidelity simulation framework, we conducted a qualitative and quantitative comparison of grasping stability analyses between the proposed framework and the state-of-the-art multi-body physics simulations. through these efforts, we have taken the first step towards a feasible solution for robotic casualty manipulation.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03741",
        "authors": [
            "qianwen zhao",
            "rajarshi roy",
            "chad spurlock",
            "kevin lister",
            "long wang"
        ]
    },
    {
        "id": "2404.03742",
        "title": "a general formulation of reweighted least squares fitting",
        "abstract": "we present a generalized formulation for reweighted least squares approximations. the goal of this article is twofold: firstly, to prove that the solution of such problem can be expressed as a convex combination of certain interpolants when the solution is sought in any finite-dimensional vector space; secondly, to provide a general strategy to iteratively update the weights according to the approximation error and apply it to the spline fitting problem. in the experiments, we provide numerical examples for the case of polynomials and splines spaces. subsequently, we evaluate the performance of our fitting scheme for spline curve and surface approximation, including adaptive spline constructions.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03742",
        "authors": [
            "carlotta giannelli",
            "sofia imperatore",
            "lisa maria kreusser",
            "estefan\u00eda loayza-romero",
            "fatemeh mohammadi",
            "nelly villamizar"
        ]
    },
    {
        "id": "2404.03743",
        "title": "test time training for industrial anomaly segmentation",
        "abstract": "anomaly detection and segmentation (ad&s) is crucial for industrial quality control. while existing methods excel in generating anomaly scores for each pixel, practical applications require producing a binary segmentation to identify anomalies. due to the absence of labeled anomalies in many real scenarios, standard practices binarize these maps based on some statistics derived from a validation set containing only nominal samples, resulting in poor segmentation performance. this paper addresses this problem by proposing a test time training strategy to improve the segmentation performance. indeed, at test time, we can extract rich features directly from anomalous samples to train a classifier that can discriminate defects effectively. our general approach can work downstream to any ad&s method that provides an anomaly score map as output, even in multimodal settings. we demonstrate the effectiveness of our approach over baselines through extensive experimentation and evaluation on mvtec ad and mvtec 3d-ad.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03743",
        "authors": [
            "alex costanzino",
            "pierluigi zama ramirez",
            "mirko del moro",
            "agostino aiezzo",
            "giuseppe lisanti",
            "samuele salti",
            "luigi di stefano"
        ]
    },
    {
        "id": "2404.03745",
        "title": "fakes of varying shades: how warning affects human perception and   engagement regarding llm hallucinations",
        "abstract": "the widespread adoption and transformative effects of large language models (llms) have sparked concerns regarding their capacity to produce inaccurate and fictitious content, referred to as `hallucinations'. given the potential risks associated with hallucinations, humans should be able to identify them. this research aims to understand the human perception of llm hallucinations by systematically varying the degree of hallucination (genuine, minor hallucination, major hallucination) and examining its interaction with warning (i.e., a warning of potential inaccuracies: absent vs. present). participants (n=419) from prolific rated the perceived accuracy and engaged with content (e.g., like, dislike, share) in a q/a format. results indicate that humans rank content as truthful in the order genuine > minor hallucination > major hallucination and user engagement behaviors mirror this pattern. more importantly, we observed that warning improves hallucination detection without significantly affecting the perceived truthfulness of genuine content. we conclude by offering insights for future tools to aid human detection of hallucinations.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03745",
        "authors": [
            "mahjabin nahar",
            "haeseung seo",
            "eun-ju lee",
            "aiping xiong",
            "dongwon lee"
        ]
    },
    {
        "id": "2404.03746",
        "title": "genqrensemble: zero-shot llm ensemble prompting for generative query   reformulation",
        "abstract": "query reformulation(qr) is a set of techniques used to transform a user's original search query to a text that better aligns with the user's intent and improves their search experience. recently, zero-shot qr has been shown to be a promising approach due to its ability to exploit knowledge inherent in large language models. by taking inspiration from the success of ensemble prompting strategies which have benefited many tasks, we investigate if they can help improve query reformulation. in this context, we propose an ensemble based prompting technique, genqrensemble which leverages paraphrases of a zero-shot instruction to generate multiple sets of keywords ultimately improving retrieval performance. we further introduce its post-retrieval variant, genqrensemblerf to incorporate pseudo relevant feedback. on evaluations over four ir benchmarks, we find that genqrensemble generates better reformulations with relative ndcg@10 improvements up to 18% and map improvements upto 24% over the previous zero-shot state-of-art. on the msmarco passage ranking task, genqrensemblerf shows relative gains of 5% mrr using pseudo-relevance feedback, and 9% ndcg@10 using relevant feedback documents.",
        "doi": "10.1007/978-3-031-56063-7_24",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03746",
        "authors": [
            "kaustubh dhole",
            "eugene agichtein"
        ]
    },
    {
        "id": "2404.03747",
        "title": "sensitivity, proximity and fpt algorithms for exact matroid problems",
        "abstract": "we consider the problem of finding a basis of a matroid with weight exactly equal to a given target. here weights can be discrete values from $\\{-\\delta,\\ldots,\\delta\\}$ or more generally $m$-dimensional vectors of such discrete values. we resolve the parameterized complexity completely, by presenting an fpt algorithm parameterized by $\\delta$ and $m$ for arbitrary matroids. prior to our work, no such algorithms were known even when weights are in $\\{0,1\\}$, or arbitrary $\\delta$ and $m=1$. our main technical contributions are new proximity and sensitivity bounds for matroid problems, independent of the number of elements. these bounds imply fpt algorithms via matroid intersection.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03747",
        "authors": [
            "friedrich eisenbrand",
            "lars rohwedder",
            "karol w\u0119grzycki"
        ]
    },
    {
        "id": "2404.03749",
        "title": "small-signal dynamics of lossy inverter-based microgrids for generalized   droop controls",
        "abstract": "a network-level small-signal model is developed for lossy microgrids, which considers coupled angle and voltage dynamics of inverter-based microgrids and uses a more general framework of droop controls in the inverter. it is shown that when relative resistances of the lines in the microgrid are reasonably consistent and differences of voltage angles across the lines are small at the operating point, the generalized droop controls can be designed to enforce decoupling between angle dynamics and voltage dynamics. next, structural results for the asymptotic stability of small-signal angle and voltage dynamics are given for the case when generalized droop control achieves decoupling. simulated transient responses of a modified ieee 9-bus system are presented to validate the theoretical findings which show the effectiveness of generalized droop controls in independently shaping the settling times of the angle and voltage responses of the lossy microgrid system.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03749",
        "authors": [
            "abdullah al maruf",
            "anamika dubey",
            "sandip roy"
        ]
    },
    {
        "id": "2404.03751",
        "title": "the maximum clique problem in a disk graph made easy",
        "abstract": "a disk graph is an intersection graph of disks in $\\mathbb{r}^2$. determining the computational complexity of finding a maximum clique in a disk graph is a long-standing open problem. in 1990, clark, colbourn, and johnson gave a polynomial-time algorithm for computing a maximum clique in a unit disk graph. however, finding a maximum clique when disks are of arbitrary size is widely believed to be a challenging open problem. the problem is open even if we restrict the disks to have at most two different sizes of radii, or restrict the radii to be within $[1,1+\\varepsilon]$ for some $\\epsilon>0$. in this paper, we provide a new perspective to examine adjacencies in a disk graph that helps obtain the following results.   - we design an $o(2^k n^{2k} poly(n))$-time algorithm to find a maximum clique in a $n$-vertex disk graph with $k$ different sizes of radii. this is polynomial for every fixed $k$, and thus settles the open question for the case when $k=2$.   - given a set of $n$ unit disks, we show how to compute a maximum clique inside each possible axis-aligned rectangle determined by the disk centers in $o(n^5\\log n)$-time. this is at least a factor of $n^{4/3}$ faster than applying the fastest known algorithm for finding a maximum clique in a unit disk graph for each rectangle independently.   - we give an $o(2^kn^{2rk} poly(n,r))$-time algorithm to find a maximum clique in a $n$-vertex ball graph with $k$ different sizes of radii where the ball centers lie on $r$ parallel planes. this is polynomial for every fixed $k$ and $r$, and thus contrasts the previously known np-hardness result for finding a maximum clique in an arbitrary ball graph.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03751",
        "authors": [
            "j. mark keil",
            "debajyoti mondal"
        ]
    },
    {
        "id": "2404.03753",
        "title": "a reinforcement learning based reset policy for cdcl sat solvers",
        "abstract": "restart policy is an important technique used in modern conflict-driven clause learning (cdcl) solvers, wherein some parts of the solver state are erased at certain intervals during the run of the solver. in most solvers, variable activities are preserved across restart boundaries, resulting in solvers continuing to search parts of the assignment tree that are not far from the one immediately prior to a restart. to enable the solver to search possibly \"distant\" parts of the assignment tree, we study the effect of resets, a variant of restarts which not only erases the assignment trail, but also randomizes the activity scores of the variables of the input formula after reset, thus potentially enabling a better global exploration of the search space.   in this paper, we model the problem of whether to trigger reset as a multi-armed bandit (mab) problem, and propose two reinforcement learning (rl) based adaptive reset policies using the upper confidence bound (ucb) and thompson sampling algorithms. these two algorithms balance the exploration-exploitation tradeoff by adaptively choosing arms (reset vs. no reset) based on their estimated rewards during the solver's run. we implement our reset policies in four baseline sota cdcl solvers and compare the baselines against the reset versions on satcoin benchmarks and sat competition instances. our results show that rl-based reset versions outperform the corresponding baseline solvers on both satcoin and the sat competition instances, suggesting that our rl policy helps to dynamically and profitably adapt the reset frequency for any given input instance. we also introduce the concept of a partial reset, where at least a constant number of variable activities are retained across reset boundaries. building on previous results, we show that there is an exponential separation between o(1) vs. $\\omega(n)$-length partial resets.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03753",
        "authors": [
            "chunxiao li",
            "charlie liu",
            "jonathan chung",
            "n/a zhengyang",
            "n/a lu",
            "piyush jha",
            "vijay ganesh"
        ]
    },
    {
        "id": "2404.03754",
        "title": "data science for geographic information systems",
        "abstract": "the integration of data science into geographic information systems (gis) has facilitated the evolution of these tools into complete spatial analysis platforms. the adoption of machine learning and big data techniques has equipped these platforms with the capacity to handle larger amounts of increasingly complex data, transcending the limitations of more traditional approaches. this work traces the historical and technical evolution of data science and gis as fields of study, highlighting the critical points of convergence between domains, and underlining the many sectors that rely on this integration. a gis application is presented as a case study in the disaster management sector where we utilize aerial data from tr\\'oia, portugal, to emphasize the process of insight extraction from raw data. we conclude by outlining prospects for future research in integration of these fields in general, and the developed application in particular.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03754",
        "authors": [
            "afonso oliveira",
            "nuno fachada",
            "jo\u00e3o p. matos-carvalho"
        ]
    },
    {
        "id": "2404.03756",
        "title": "robust finite element solvers for distributed hyperbolic optimal control   problems",
        "abstract": "we propose, analyze, and test new robust iterative solvers for systems of linear algebraic equations arising from the space-time finite element discretization of reduced optimality systems defining the approximate solution of hyperbolic distributed, tracking-type optimal control problems with both the standard $l^2$ and the more general energy regularizations. in contrast to the usual time-stepping approach, we discretize the optimality system by space-time continuous piecewise-linear finite element basis functions which are defined on fully unstructured simplicial meshes. if we aim at the asymptotically best approximation of the given desired state $y_d$ by the computed finite element state $y_{\\varrho h}$, then the optimal choice of the regularization parameter $\\varrho$ is linked to the space-time finite element mesh-size $h$ by the relations $\\varrho=h^4$ and $\\varrho=h^2$ for the $l^2$ and the energy regularization, respectively. for this setting, we can construct robust (parallel) iterative solvers for the reduced finite element optimality systems. these results can be generalized to variable regularization parameters adapted to the local behavior of the mesh-size that can heavily change in the case of adaptive mesh refinements. the numerical results illustrate the theoretical findings firmly.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03756",
        "authors": [
            "ulrich langer",
            "richard l\u00f6scher",
            "olaf steinbach",
            "huidong yang"
        ]
    },
    {
        "id": "2404.03759",
        "title": "localized distributional robustness in submodular multi-task subset   selection",
        "abstract": "in this work, we approach the problem of multi-task submodular optimization with the perspective of local distributional robustness, within the neighborhood of a reference distribution which assigns an importance score to each task. we initially propose to introduce a regularization term which makes use of the relative entropy to the standard multi-task objective. we then demonstrate through duality that this novel formulation itself is equivalent to the maximization of a submodular function, which may be efficiently carried out through standard greedy selection methods. this approach bridges the existing gap in the optimization of performance-robustness trade-offs in multi-task subset selection. to numerically validate our theoretical results, we test the proposed method in two different setting, one involving the selection of satellites in low earth orbit constellations in the context of a sensor selection problem, and the other involving an image summarization task using neural networks. our method is compared with two other algorithms focused on optimizing the performance of the worst-case task, and on directly optimizing the performance on the reference distribution itself. we conclude that our novel formulation produces a solution that is locally distributional robust, and computationally inexpensive.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03759",
        "authors": [
            "ege c. kaya",
            "abolfazl hashemi"
        ]
    },
    {
        "id": "2404.03761",
        "title": "learning smooth functions in high dimensions: from sparse polynomials to   deep neural networks",
        "abstract": "learning approximations to smooth target functions of many variables from finite sets of pointwise samples is an important task in scientific computing and its many applications in computational science and engineering. despite well over half a century of research on high-dimensional approximation, this remains a challenging problem. yet, significant advances have been made in the last decade towards efficient methods for doing this, commencing with so-called sparse polynomial approximation methods and continuing most recently with methods based on deep neural networks (dnns). in tandem, there have been substantial advances in the relevant approximation theory and analysis of these techniques. in this work, we survey this recent progress. we describe the contemporary motivations for this problem, which stem from parametric models and computational uncertainty quantification; the relevant function classes, namely, classes of infinite-dimensional, banach-valued, holomorphic functions; fundamental limits of learnability from finite data for these classes; and finally, sparse polynomial and dnn methods for efficiently learning such functions from finite data. for the latter, there is currently a significant gap between the approximation theory of dnns and the practical performance of deep learning. aiming to narrow this gap, we develop the topic of practical existence theory, which asserts the existence of dimension-independent dnn architectures and training strategies that achieve provably near-optimal generalization errors in terms of the amount of training data.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03761",
        "authors": [
            "ben adcock",
            "simone brugiapaglia",
            "nick dexter",
            "sebastian moraga"
        ]
    },
    {
        "id": "2404.03764",
        "title": "concert: covariate-elaborated robust local information transfer with   conditional spike-and-slab prior",
        "abstract": "the popularity of transfer learning stems from the fact that it can borrow information from useful auxiliary datasets. existing statistical transfer learning methods usually adopt a global similarity measure between the source data and the target data, which may lead to inefficiency when only local information is shared. in this paper, we propose a novel bayesian transfer learning method named \"concert\" to allow robust local information transfer for high-dimensional data analysis. a novel conditional spike-and-slab prior is introduced in the joint distribution of target and source parameters for information transfer. by incorporating covariate-specific priors, we can characterize the local similarities and make the sources work collaboratively to help improve the performance on the target. distinguished from existing work, concert is a one-step procedure, which achieves variable selection and information transfer simultaneously. variable selection consistency is established for our concert. to make our algorithm scalable, we adopt the variational bayes framework to facilitate implementation. extensive experiments and a genetic data analysis demonstrate the validity and the advantage of concert over existing cutting-edge transfer learning methods. we also extend our concert to the logistical models with numerical studies showing its superiority over other methods.",
        "doi": "",
        "created": "2024-03-30",
        "url": "https://arxiv.org/abs/2404.03764",
        "authors": [
            "ruqian zhang",
            "yijiao zhang",
            "annie qu",
            "zhongyi zhu",
            "juan shen"
        ]
    },
    {
        "id": "2404.03769",
        "title": "on extending the automatic test markup language (atml) for machine   learning",
        "abstract": "this paper addresses the urgent need for messaging standards in the operational test and evaluation (t&e) of machine learning (ml) applications, particularly in edge ml applications embedded in systems like robots, satellites, and unmanned vehicles. it examines the suitability of the ieee standard 1671 (ieee std 1671), known as the automatic test markup language (atml), an xml-based standard originally developed for electronic systems, for ml application testing. the paper explores extending ieee std 1671 to encompass the unique challenges of ml applications, including the use of datasets and dependencies on software. through modeling various tests such as adversarial robustness and drift detection, this paper offers a framework adaptable to specific applications, suggesting that minor modifications to atml might suffice to address the novelties of ml. this paper differentiates atml's focus on testing from other ml standards like predictive model markup language (pmml) or open neural network exchange (onnx), which concentrate on ml model specification. we conclude that atml is a promising tool for effective, near real-time operational t&e of ml applications, an essential aspect of ai lifecycle management, safety, and governance.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03769",
        "authors": [
            "tyler cody",
            "bingtong li",
            "peter a. beling"
        ]
    },
    {
        "id": "2404.03771",
        "title": "r5detect: detecting control-flow attacks from standard risc-v enclaves",
        "abstract": "embedded and internet-of-things (iot) devices are ubiquitous today, and the uprising of several botnets based on them (e.g., mirai, ripple20) raises issues about the security of such devices. especially low-power devices often lack support for modern system security measures, such as stack integrity, non-executable bits or strong cryptography.   in this work, we present r5detect, a security monitoring software that detects and prevents control-flow attacks on unmodified risc-v standard architectures. with a novel combination of different protection techniques, it can run on embedded and low-power iot devices, which may lack proper security features. r5detect implements a memory-protected shadow stack to prevent runtime modifications, as well as a heuristics detection based on hardware performance counters to detect control-flow integrity violations. our results indicate that regular software can be protected against different degrees of control-flow manipulations with an average performance overhead of below 5 %. we implement and evaluate r5detect on standard low-power risc-v devices and show that such security features can be effectively used with minimal hardware support.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03771",
        "authors": [
            "davide bove",
            "lukas panzer"
        ]
    },
    {
        "id": "2404.03774",
        "title": "exploration is harder than prediction: cryptographically separating   reinforcement learning from supervised learning",
        "abstract": "supervised learning is often computationally easy in practice. but to what extent does this mean that other modes of learning, such as reinforcement learning (rl), ought to be computationally easy by extension? in this work we show the first cryptographic separation between rl and supervised learning, by exhibiting a class of block mdps and associated decoding functions where reward-free exploration is provably computationally harder than the associated regression problem. we also show that there is no computationally efficient algorithm for reward-directed rl in block mdps, even when given access to an oracle for this regression problem.   it is known that being able to perform regression in block mdps is necessary for finding a good policy; our results suggest that it is not sufficient. our separation lower bound uses a new robustness property of the learning parities with noise (lpn) hardness assumption, which is crucial in handling the dependent nature of rl data. we argue that separations and oracle lower bounds, such as ours, are a more meaningful way to prove hardness of learning because the constructions better reflect the practical reality that supervised learning by itself is often not the computational bottleneck.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03774",
        "authors": [
            "noah golowich",
            "ankur moitra",
            "dhruv rohatgi"
        ]
    },
    {
        "id": "2404.03775",
        "title": "a systems theoretic approach to online machine learning",
        "abstract": "the machine learning formulation of online learning is incomplete from a systems theoretic perspective. typically, machine learning research emphasizes domains and tasks, and a problem solving worldview. it focuses on algorithm parameters, features, and samples, and neglects the perspective offered by considering system structure and system behavior or dynamics. online learning is an active field of research and has been widely explored in terms of statistical theory and computational algorithms, however, in general, the literature still lacks formal system theoretical frameworks for modeling online learning systems and resolving systems-related concept drift issues. furthermore, while the machine learning formulation serves to classify methods and literature, the systems theoretic formulation presented herein serves to provide a framework for the top-down design of online learning systems, including a novel definition of online learning and the identification of key design parameters. the framework is formulated in terms of input-output systems and is further divided into system structure and system behavior. concept drift is a critical challenge faced in online learning, and this work formally approaches it as part of the system behavior characteristics. healthcare provider fraud detection using machine learning is used as a case study throughout the paper to ground the discussion in a real-world online learning challenge.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03775",
        "authors": [
            "anli du preez",
            "peter a. beling",
            "tyler cody"
        ]
    },
    {
        "id": "2404.03784",
        "title": "layerwise early stopping for test time adaptation",
        "abstract": "test time adaptation (tta) addresses the problem of distribution shift by enabling pretrained models to learn new features on an unseen domain at test time. however, it poses a significant challenge to maintain a balance between learning new features and retaining useful pretrained features. in this paper, we propose layerwise early stopping (least) for tta to address this problem. the key idea is to stop adapting individual layers during tta if the features being learned do not appear beneficial for the new domain. for that purpose, we propose using a novel gradient-based metric to measure the relevance of the current learnt features to the new domain without the need for supervised labels. more specifically, we propose to use this metric to determine dynamically when to stop updating each layer during tta. this enables a more balanced adaptation, restricted to layers benefiting from it, and only for a certain number of steps. such an approach also has the added effect of limiting the forgetting of pretrained features useful for dealing with new domains. through extensive experiments, we demonstrate that layerwise early stopping improves the performance of existing tta approaches across multiple datasets, domain shifts, model architectures, and tta losses.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03784",
        "authors": [
            "sabyasachi sahoo",
            "mostafa elaraby",
            "jonas ngnawe",
            "yann pequignot",
            "frederic precioso",
            "christian gagne"
        ]
    },
    {
        "id": "2404.03787",
        "title": "revisiting categorical color perception in scatterplots: sequential,   diverging, and categorical palettes",
        "abstract": "existing guidelines for categorical color selection are heuristic, often grounded in intuition rather than empirical studies of readers' abilities. while design conventions recommend palettes maximize hue differences, more recent exploratory findings indicate other factors, such as lightness, may play a role in effective categorical palette design. we conducted a crowdsourced experiment on mean value judgments in multi-class scatterplots using five color palette families--single-hue sequential, multi-hue sequential, perceptually-uniform multi-hue sequential, diverging, and multi-hue categorical--that differ in how they manipulate hue and lightness. participants estimated relative mean positions in scatterplots containing 2 to 10 categories using 20 colormaps. our results confirm heuristic guidance that hue-based categorical palettes are most effective. however, they also provide additional evidence that scalable categorical encoding relies on more than hue variance.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03787",
        "authors": [
            "chin tseng",
            "arran zeyu wang",
            "ghulam jilani quadri",
            "danielle albers szafir"
        ]
    },
    {
        "id": "2404.03788",
        "title": "understanding language modeling paradigm adaptations in recommender   systems: lessons learned and open challenges",
        "abstract": "the emergence of large language models (llms) has achieved tremendous success in the field of natural language processing owing to diverse training paradigms that empower llms to effectively capture intricate linguistic patterns and semantic representations. in particular, the recent \"pre-train, prompt and predict\" training paradigm has attracted significant attention as an approach for learning generalizable models with limited labeled data. in line with this advancement, these training paradigms have recently been adapted to the recommendation domain and are seen as a promising direction in both academia and industry. this half-day tutorial aims to provide a thorough understanding of extracting and transferring knowledge from pre-trained models learned through different training paradigms to improve recommender systems from various perspectives, such as generality, sparsity, effectiveness and trustworthiness. in this tutorial, we first introduce the basic concepts and a generic architecture of the language modeling paradigm for recommendation purposes. then, we focus on recent advancements in adapting llm-related training strategies and optimization objectives for different recommendation tasks. after that, we will systematically introduce ethical issues in llm-based recommender systems and discuss possible approaches to assessing and mitigating them. we will also summarize the relevant datasets, evaluation metrics, and an empirical study on the recommendation performance of training paradigms. finally, we will conclude the tutorial with a discussion of open challenges and future directions.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03788",
        "authors": [
            "lemei zhang",
            "peng liu",
            "yashar deldjoo",
            "yong zheng",
            "jon atle gulla"
        ]
    },
    {
        "id": "2404.03789",
        "title": "quantifying uncertainty in motion prediction with variational bayesian   mixture",
        "abstract": "safety and robustness are crucial factors in developing trustworthy autonomous vehicles. one essential aspect of addressing these factors is to equip vehicles with the capability to predict future trajectories for all moving objects in the surroundings and quantify prediction uncertainties. in this paper, we propose the sequential neural variational agent (seneva), a generative model that describes the distribution of future trajectories for a single moving object. our approach can distinguish out-of-distribution data while quantifying uncertainty and achieving competitive performance compared to state-of-the-art methods on the argoverse 2 and interaction datasets. specifically, a 0.446 meters minimum final displacement error, a 0.203 meters minimum average displacement error, and a 5.35% miss rate are achieved on the interaction test set. extensive qualitative and quantitative analysis is also provided to evaluate the proposed model. our open-source code is available at https://github.com/purduedigitaltwin/seneva.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03789",
        "authors": [
            "juanwu lu",
            "can cui",
            "yunsheng ma",
            "aniket bera",
            "ziran wang"
        ]
    },
    {
        "id": "2404.03790",
        "title": "a bimanual teleoperation framework for light duty underwater   vehicle-manipulator systems",
        "abstract": "in an effort to lower the barrier to entry in underwater manipulation, this paper presents an open-source, user-friendly framework for bimanual teleoperation of a light-duty underwater vehicle-manipulator system (uvms). this framework allows for the control of the vehicle along with two manipulators and their end-effectors using two low-cost haptic devices.   the uvms kinematics are derived in order to create an independent resolved motion rate controller for each manipulator, which optimally controls the joint positions to achieve a desired end-effector pose. this desired pose is computed in real-time using a teleoperation controller developed to process the dual haptic device input from the user. a physics-based simulation environment is used to implement this framework for two example tasks as well as provide data for error analysis of user commands. the first task illustrates the functionality of the framework through motion control of the vehicle and manipulators using only the haptic devices. the second task is to grasp an object using both manipulators simultaneously, demonstrating precision and coordination using the framework. the framework code is available at https://github.com/stevens-armlab/uvms_bimanual_sim.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03790",
        "authors": [
            "justin sitler",
            "srikarran sowrirajan",
            "brendan englot",
            "long wang"
        ]
    },
    {
        "id": "2404.03793",
        "title": "some observations regarding the rbf-fd approximation accuracy dependence   on stencil size",
        "abstract": "when solving partial differential equations on scattered nodes using the radial basis function-generated finite difference (rbf-fd) method, one of the parameters that must be chosen is the stencil size. focusing on polyharmonic spline rbfs with monomial augmentation, we observe that it affects the approximation accuracy in a particularly interesting way - the solution error oscillates under increasing stencil size. we find that we can connect this behaviour with the spatial dependence of the signed approximation error. based on this observation we are able to introduce a numerical quantity that could indicate whether a given stencil size is locally optimal. this work is an extension of our iccs 2023 conference paper.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03793",
        "authors": [
            "andrej kolar-po\u017eun",
            "mitja jan\u010di\u010d",
            "miha rot",
            "gregor kosec"
        ]
    },
    {
        "id": "2404.03795",
        "title": "optimization of resources for digital radio transmission over iboc fm   through max-min fairness",
        "abstract": "the equitable distribution of resources in a network is a complex process, considering that not all nodes have the same requirements, and the in-band on-channel (iboc) hybrid transmission system is no exception. the iboc system utilizes a hybrid in-band transmission to simultaneously broadcast analog and digital audio over the fm band. this article proposes the use of a max-min fairness (mmf) algorithm, with a strategy to optimize resource allocation for iboc fm transmission in a multiservice scenario. additionally, the mmf algorithm offers low computational complexity for implementation in low-cost embedded systems, aiming to achieve fair resource distribution and provide adequate quality of service (qos) levels for each node in the rf network, considering channel conditions and traffic types. the article explores a scenario under saturated traffic conditions to assess the optimization capabilities of the mmf algorithm under well-defined traffic and channel conditions. the evaluation process yielded highly favorable results, indicating that themmf algorithm can be considered a viable alternative for bandwidth optimization in digital broadcasting over iboc on fm with 95% confidence, and it holds potential for implementation in other digital broadcasting system.",
        "doi": "10.5121/csit.2024.140511",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03795",
        "authors": [
            "m\u00f3nica rico mart\u00ednez",
            "juan carlos vesga ferreira",
            "joel carroll vargas",
            "mar\u00eda consuelo rodr\u00edguez ni\u00f1o",
            "andr\u00e9s alejandro diaz toro",
            "william alexander cuevas carrero"
        ]
    },
    {
        "id": "2404.03797",
        "title": "asymptotic optimality of dynamic first-fit packing on the half-axis",
        "abstract": "we revisit a classical problem in dynamic storage allocation. items arrive in a linear storage medium, modeled as a half-axis, at a poisson rate $r$ and depart after an independent exponentially distributed unit mean service time. the arriving item sizes are assumed to be independent and identically distributed (i.i.d.) from a common distribution $h$. a widely employed algorithm for allocating the items is the ``first-fit'' discipline, namely, each arriving item is placed in the the left-most vacant interval large enough to accommodate it. in a seminal 1985 paper, coffman, kadota, and shepp [6] proved that in the special case of unit length items (i.e. degenerate $h$), the first-fit algorithm is asymptotically optimal in the following sense: the ratio of expected empty space to expected occupied space tends towards $0$ as the occupied space tends towards infinity. in a sequel to [6], the authors of [5] conjectured that the first-fit discipline is also asymptotically optimal for non-degenerate $h$.   in this paper we provide the first proof of first-fit asymptotic optimality for a non-degenerate distribution $h$, namely the case when items can be of sizes 1 and 2. specifically, we prove that, under first-fit, the steady-state packing configuration, scaled down by $r$, converges in distribution to the optimal limiting packing configuration, i.e. the one with smaller items on the left, larger items on the right, and with no gaps between.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03797",
        "authors": [
            "philip ernst",
            "alexander stolyar"
        ]
    },
    {
        "id": "2404.03799",
        "title": "language-guided instance-aware domain-adaptive panoptic segmentation",
        "abstract": "the increasing relevance of panoptic segmentation is tied to the advancements in autonomous driving and ar/vr applications. however, the deployment of such models has been limited due to the expensive nature of dense data annotation, giving rise to unsupervised domain adaptation (uda). a key challenge in panoptic uda is reducing the domain gap between a labeled source and an unlabeled target domain while harmonizing the subtasks of semantic and instance segmentation to limit catastrophic interference. while considerable progress has been achieved, existing approaches mainly focus on the adaptation of semantic segmentation. in this work, we focus on incorporating instance-level adaptation via a novel instance-aware cross-domain mixing strategy imix. imix significantly enhances the panoptic quality by improving instance segmentation performance. specifically, we propose inserting high-confidence predicted instances from the target domain onto source images, retaining the exhaustiveness of the resulting pseudo-labels while reducing the injected confirmation bias. nevertheless, such an enhancement comes at the cost of degraded semantic performance, attributed to catastrophic forgetting. to mitigate this issue, we regularize our semantic branch by employing clip-based domain alignment (cda), exploiting the domain-robustness of natural language prompts. finally, we present an end-to-end model incorporating these two mechanisms called lidaps, achieving state-of-the-art results on all popular panoptic uda benchmarks.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03799",
        "authors": [
            "elham amin mansour",
            "ozan unal",
            "suman saha",
            "benjamin bejar",
            "luc van gool"
        ]
    },
    {
        "id": "2404.03800",
        "title": "learning social fairness preferences from non-expert stakeholder   opinions in kidney placement",
        "abstract": "modern kidney placement incorporates several intelligent recommendation systems which exhibit social discrimination due to biases inherited from training data. although initial attempts were made in the literature to study algorithmic fairness in kidney placement, these methods replace true outcomes with surgeons' decisions due to the long delays involved in recording such outcomes reliably. however, the replacement of true outcomes with surgeons' decisions disregards expert stakeholders' biases as well as social opinions of other stakeholders who do not possess medical expertise. this paper alleviates the latter concern and designs a novel fairness feedback survey to evaluate an acceptance rate predictor (arp) that predicts a kidney's acceptance rate in a given kidney-match pair. the survey is launched on prolific, a crowdsourcing platform, and public opinions are collected from 85 anonymous crowd participants. a novel social fairness preference learning algorithm is proposed based on minimizing social feedback regret computed using a novel logit-based fairness feedback model. the proposed model and learning algorithm are both validated using simulation experiments as well as prolific data. public preferences towards group fairness notions in the context of kidney placement have been estimated and discussed in detail. the specific arp tested in the prolific survey has been deemed fair by the participants.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03800",
        "authors": [
            "mukund telukunta",
            "sukruth rao",
            "gabriella stickney",
            "venkata sriram siddardh nadendla",
            "casey canfield"
        ]
    },
    {
        "id": "2404.03804",
        "title": "transformerlsr: attentive joint model of longitudinal data, survival,   and recurrent events with concurrent latent structure",
        "abstract": "in applications such as biomedical studies, epidemiology, and social sciences, recurrent events often co-occur with longitudinal measurements and a terminal event, such as death. therefore, jointly modeling longitudinal measurements, recurrent events, and survival data while accounting for their dependencies is critical. while joint models for the three components exist in statistical literature, many of these approaches are limited by heavy parametric assumptions and scalability issues. recently, incorporating deep learning techniques into joint modeling has shown promising results. however, current methods only address joint modeling of longitudinal measurements at regularly-spaced observation times and survival events, neglecting recurrent events. in this paper, we develop transformerlsr, a flexible transformer-based deep modeling and inference framework to jointly model all three components simultaneously. transformerlsr integrates deep temporal point processes into the joint modeling framework, treating recurrent and terminal events as two competing processes dependent on past longitudinal measurements and recurrent event times. additionally, transformerlsr introduces a novel trajectory representation and model architecture to potentially incorporate a priori knowledge of known latent structures among concurrent longitudinal variables. we demonstrate the effectiveness and necessity of transformerlsr through simulation studies and analyzing a real-world medical dataset on patients after kidney transplantation.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03804",
        "authors": [
            "zhiyue zhang",
            "yao zhao",
            "yanxun xu"
        ]
    },
    {
        "id": "2404.03809",
        "title": "sls-brd: a system-level approach to seeking generalised feedback nash   equilibria",
        "abstract": "this work proposes a policy learning algorithm for generalised feedback nash equilibrium seeking in $n_p$-players non-cooperative dynamic games. we consider linear-quadratic games with stochastic dynamics and design a best-response dynamics in which players update and communicate a parametrisation of their state-feedback policies. our approach leverages the system level synthesis (sls) framework to formulate each player's update rule as the solution of a tractable robust optimisation problem. under certain conditions, the conditions and rates of convergence can be established. the algorithm is showcased for an exemplary problem from decentralised control of multi-agent systems.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03809",
        "authors": [
            "otacilio b. l. neto",
            "michela mulas",
            "francesco corona"
        ]
    },
    {
        "id": "2404.03812",
        "title": "additive approximation algorithm for geodesic centers in   $\\delta$-hyperbolic graphs",
        "abstract": "for an integer $k\\geq 1$, the objective of \\textsc{$k$-geodesic center} is to find a set $\\mathcal{c}$ of $k$ isometric paths such that the maximum distance between any vertex $v$ and $\\mathcal{c}$ is minimised. introduced by gromov, \\emph{$\\delta$-hyperbolicity} measures how treelike a graph is from a metric point of view. our main contribution in this paper is to provide an additive $o(\\delta)$-approximation algorithm for \\textsc{$k$-geodesic center} on $\\delta$-hyperbolic graphs. on the way, we define a coarse version of the pairing property introduced by gerstel \\& zaks (networks, 1994) and show it holds for $\\delta$-hyperbolic graphs. this result allows to reduce the \\textsc{$k$-geodesic center} problem to its rooted counterpart, a main idea behind our algorithm. we also adapt a technique of dragan \\& leitert, (tcs, 2017) to show that for every $k\\geq 1$, $k$-\\textsc{geodesic center} is np-hard even on partial grids.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03812",
        "authors": [
            "dibyayan chakraborty",
            "yann vax\u00e8s"
        ]
    },
    {
        "id": "2404.03813",
        "title": "agnostic tomography of stabilizer product states",
        "abstract": "we define a quantum learning task called agnostic tomography, where given copies of an arbitrary state $\\rho$ and a class of quantum states $\\mathcal{c}$, the goal is to output a succinct description of a state that approximates $\\rho$ at least as well as any state in $\\mathcal{c}$ (up to some small error $\\varepsilon$). this task generalizes ordinary quantum tomography of states in $\\mathcal{c}$ and is more challenging because the learning algorithm must be robust to perturbations of $\\rho$.   we give an efficient agnostic tomography algorithm for the class $\\mathcal{c}$ of $n$-qubit stabilizer product states. assuming $\\rho$ has fidelity at least $\\tau$ with a stabilizer product state, the algorithm runs in time $n^{o(1 + \\log(1/\\tau))} / \\varepsilon^2$. this runtime is quasipolynomial in all parameters, and polynomial if $\\tau$ is a constant.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03813",
        "authors": [
            "sabee grewal",
            "vishnu iyer",
            "william kretschmer",
            "daniel liang"
        ]
    },
    {
        "id": "2404.03814",
        "title": "i did not notice: a comparison of immersive analytics with augmented and   virtual reality",
        "abstract": "immersive environments enable users to engage in embodied interaction, enhancing the sensemaking processes involved in completing tasks such as immersive analytics. previous comparative studies on immersive analytics using augmented and virtual realities have revealed that users employ different strategies for data interpretation and text-based analytics depending on the environment. our study seeks to investigate how augmented and virtual reality influences sensemaking processes in quantitative immersive analytics. our results, derived from a diverse group of participants, indicate that users demonstrate comparable performance in both environments. however, it was observed that users exhibit a higher tolerance for cognitive load in vr and travel further in ar. based on our findings, we recommend providing users with the option to switch between ar and vr, thereby enabling them to select an environment that aligns with their preferences and task requirements.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03814",
        "authors": [
            "xiaoyan zhou",
            "anil ufuk batmaz",
            "adam s. williams",
            "dylan schreiber",
            "francisco ortega"
        ]
    },
    {
        "id": "2404.03816",
        "title": "accounting for hysteresis in the forward kinematics of   nonlinearly-routed tendon-driven continuum robots via a learned deep decoder   network",
        "abstract": "tendon-driven continuum robots have been gaining popularity in medical applications due to their ability to curve around complex anatomical structures, potentially reducing the invasiveness of surgery. however, accurate modeling is required to plan and control the movements of these flexible robots. physics-based models have limitations due to unmodeled effects, leading to mismatches between model prediction and actual robot shape. recently proposed learning-based methods have been shown to overcome some of these limitations but do not account for hysteresis, a significant source of error for these robots. to overcome these challenges, we propose a novel deep decoder neural network that predicts the complete shape of tendon-driven robots using point clouds as the shape representation, conditioned on prior configurations to account for hysteresis. we evaluate our method on a physical tendon-driven robot and show that our network model accurately predicts the robot's shape, significantly outperforming a state-of-the-art physics-based model and a learning-based model that does not account for hysteresis.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03816",
        "authors": [
            "brian y. cho",
            "daniel s. esser",
            "jordan thompson",
            "bao thach",
            "robert j. webster",
            "alan kuntz"
        ]
    },
    {
        "id": "2404.03818",
        "title": "probelm: plausibility ranking evaluation for language models",
        "abstract": "this paper introduces probelm (plausibility ranking evaluation for language models), a benchmark designed to assess language models' ability to discern more plausible from less plausible scenarios through their parametric knowledge. while benchmarks such as truthfulqa emphasise factual accuracy or truthfulness, and others such as copa explore plausible scenarios without explicitly incorporating world knowledge, probelm seeks to bridge this gap by evaluating models' capabilities to prioritise plausible scenarios that leverage world knowledge over less plausible alternatives. this design allows us to assess the potential of language models for downstream use cases such as literature-based discovery where the focus is on identifying information that is likely but not yet known. our benchmark is constructed from a dataset curated from wikidata edit histories, tailored to align the temporal bounds of the training data for the evaluated models. probelm facilitates the evaluation of language models across multiple prompting types, including statement, text completion, and question-answering. experiments with 10 models of various sizes and architectures on the relationship between model scales, training recency, and plausibility performance, reveal that factual accuracy does not directly correlate with plausibility performance and that up-to-date training data enhances plausibility assessment across different model architectures.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03818",
        "authors": [
            "zhangdie yuan",
            "chenxi whitehouse",
            "eric chamoun",
            "rami aly",
            "andreas vlachos"
        ]
    },
    {
        "id": "2404.03819",
        "title": "effective lymph nodes detection in ct scans using location debiased   query selection and contrastive query representation in transformer",
        "abstract": "lymph node (ln) assessment is a critical, indispensable yet very challenging task in the routine clinical workflow of radiology and oncology. accurate ln analysis is essential for cancer diagnosis, staging, and treatment planning. finding scatteredly distributed, low-contrast clinically relevant lns in 3d ct is difficult even for experienced physicians under high inter-observer variations. previous automatic ln detection works typically yield limited recall and high false positives (fps) due to adjacent anatomies with similar image intensities, shapes, or textures (vessels, muscles, esophagus, etc). in this work, we propose a new ln detection transformer, named ln-detr, to achieve more accurate performance. by enhancing the 2d backbone with a multi-scale 2.5d feature fusion to incorporate 3d context explicitly, more importantly, we make two main contributions to improve the representation quality of ln queries. 1) considering that ln boundaries are often unclear, an iou prediction head and a location debiased query selection are proposed to select ln queries of higher localization accuracy as the decoder query's initialization. 2) to reduce fps, query contrastive learning is employed to explicitly reinforce ln queries towards their best-matched ground-truth queries over unmatched query predictions. trained and tested on 3d ct scans of 1067 patients (with 10,000+ labeled lns) via combining seven ln datasets from different body parts (neck, chest, and abdomen) and pathologies/cancers, our method significantly improves the performance of previous leading methods by > 4-5% average recall at the same fp rates in both internal and external testing. we further evaluate on the universal lesion detection task using nih deeplesion benchmark, and our method achieves the top performance of 88.46% averaged recall across 0.5 to 4 fps per image, compared with other leading reported results.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03819",
        "authors": [
            "qinji yu",
            "yirui wang",
            "ke yan",
            "haoshen li",
            "dazhou guo",
            "li zhang",
            "le lu",
            "na shen",
            "qifeng wang",
            "xiaowei ding",
            "xianghua ye",
            "dakai jin"
        ]
    },
    {
        "id": "2404.03820",
        "title": "canttalkaboutthis: aligning language models to stay on topic in   dialogues",
        "abstract": "recent advancements in instruction-tuning datasets have predominantly focused on specific tasks like mathematical or logical reasoning. there has been a notable gap in data designed for aligning language models to maintain topic relevance in conversations - a critical aspect for deploying chatbots to production. we introduce the canttalkaboutthis dataset to help language models remain focused on the subject at hand during task-oriented interactions. it consists of synthetic dialogues on a wide range of conversation topics from different domains. these dialogues are interspersed with distractor turns that intentionally divert the chatbot from the predefined topic. fine-tuning language models on this dataset helps make them resilient to deviating from the role assigned and improves their ability to maintain topical coherence compared to general-purpose instruction-tuned llms like gpt-4-turbo and mixtral-instruct. additionally, preliminary observations suggest that training models on this dataset also enhance their performance on fine-grained instruction following tasks.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03820",
        "authors": [
            "makesh narsimhan sreedhar",
            "traian rebedea",
            "shaona ghosh",
            "christopher parisien"
        ]
    },
    {
        "id": "2404.03823",
        "title": "an investigation into misuse of java security apis by large language   models",
        "abstract": "the increasing trend of using large language models (llms) for code generation raises the question of their capability to generate trustworthy code. while many researchers are exploring the utility of code generation for uncovering software vulnerabilities, one crucial but often overlooked aspect is the security application programming interfaces (apis). apis play an integral role in upholding software security, yet effectively integrating security apis presents substantial challenges. this leads to inadvertent misuse by developers, thereby exposing software to vulnerabilities. to overcome these challenges, developers may seek assistance from llms. in this paper, we systematically assess chatgpt's trustworthiness in code generation for security api use cases in java. to conduct a thorough evaluation, we compile an extensive collection of 48 programming tasks for 5 widely used security apis. we employ both automated and manual approaches to effectively detect security api misuse in the code generated by chatgpt for these tasks. our findings are concerning: around 70% of the code instances across 30 attempts per task contain security api misuse, with 20 distinct misuse types identified. moreover, for roughly half of the tasks, this rate reaches 100%, indicating that there is a long way to go before developers can rely on chatgpt to securely implement security api code.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03823",
        "authors": [
            "zahra mousavi",
            "chadni islam",
            "kristen moore",
            "alsharif abuadbba",
            "muhammad ali babar"
        ]
    },
    {
        "id": "2404.03825",
        "title": "parametricity via cohesion",
        "abstract": "parametricity is a key metatheoretic property of type systems, which implies strong uniformity & modularity properties of the structure of types within systems possessing it. in recent years, various systems of dependent type theory have emerged with the aim of expressing such parametric reasoning in their internal logic, toward the end of solving various problems arising from the complexity of higher-dimensional coherence conditions in type theory. this paper presents a first step toward the unification, simplification, and extension of these various methods for internalizing parametricity. specifically, i argue that there is an essentially modal aspect of parametricity, which is intimately connected with the category-theoretic concept of cohesion. on this basis, i describe a general categorical semantics for modal parametricity, develop a corresponding framework of axioms (with computational interpretations) in dependent type theory that can be used to internally represent and reason about such parametricity, and show this in practice by implementing these axioms in agda and using them to verify parametricity theorems therein. i then demonstrate the utility of these axioms in managing the complexity of higher-dimensional coherence by deriving induction principles for higher inductive types, and in closing, i sketch the outlines of a more general synthetic theory of parametricity, with applications in domains ranging from homotopy type theory to the analysis of program modules.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03825",
        "authors": [
            "c. b. aberl\u00e9"
        ]
    },
    {
        "id": "2404.03827",
        "title": "uniform memory retrieval with larger capacity for modern hopfield models",
        "abstract": "we propose a two-stage memory retrieval dynamics for modern hopfield models, termed $\\mathtt{u\\text{-}hop}$, with enhanced memory capacity. our key contribution is a learnable feature map $\\phi$ which transforms the hopfield energy function into a kernel space. this transformation ensures convergence between the local minima of energy and the fixed points of retrieval dynamics within the kernel space. consequently, the kernel norm induced by $\\phi$ serves as a novel similarity measure. it utilizes the stored memory patterns as learning data to enhance memory capacity across all modern hopfield models. specifically, we accomplish this by constructing a separation loss $\\mathcal{l}_\\phi$ that separates the local minima of kernelized energy by separating stored memory patterns in kernel space. methodologically, $\\mathtt{u\\text{-}hop}$ memory retrieval process consists of: \\textbf{(stage~i.)} minimizing separation loss for a more uniformed memory (local minimum) distribution, followed by \\textbf{(stage~ii.)} standard hopfield energy minimization for memory retrieval. this results in a significant reduction of possible meta-stable states in the hopfield energy function, thus enhancing memory capacity by preventing memory confusion. empirically, with real-world datasets, we demonstrate that $\\mathtt{u\\text{-}hop}$ outperforms all existing modern hopfield models and sota similarity measures, achieving substantial improvements in both associative memory retrieval and deep learning tasks.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03827",
        "authors": [
            "dennis wu",
            "jerry yao-chieh hu",
            "teng-yun hsiao",
            "han liu"
        ]
    },
    {
        "id": "2404.03828",
        "title": "outlier-efficient hopfield layers for large transformer-based models",
        "abstract": "we introduce an outlier-efficient modern hopfield model (termed $\\mathtt{outeffhop}$) and use it to address the outlier-induced challenge of quantizing gigantic transformer-based models. our main contribution is a novel associative memory model facilitating \\textit{outlier-efficient} associative memory retrievals. interestingly, this memory model manifests a model-based interpretation of an outlier-efficient attention mechanism ($\\text{softmax}_1$): it is an approximation of the memory retrieval process of $\\mathtt{outeffhop}$. methodologically, this allows us to debut novel outlier-efficient hopfield layers a powerful attention alternative with superior post-quantization performance. theoretically, the outlier-efficient modern hopfield model retains and improves the desirable properties of the standard modern hopfield models, including fixed point convergence and exponential storage capacity. empirically, we demonstrate the proposed model's efficacy across large-scale transformer-based and hopfield-based models (including bert, opt, vit and stanhop-net), benchmarking against state-of-the-art methods including $\\mathtt{clipped\\_softmax}$ and $\\mathtt{gated\\_attention}$. notably, $\\mathtt{outeffhop}$ achieves on average $\\sim$22+\\% reductions in both average kurtosis and maximum infinity norm of model outputs accross 4 models.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03828",
        "authors": [
            "jerry yao-chieh hu",
            "pei-hsuan chang",
            "robin luo",
            "hong-yu chen",
            "weijian li",
            "wei-po wang",
            "han liu"
        ]
    },
    {
        "id": "2404.03830",
        "title": "bishop: bi-directional cellular learning for tabular data with   generalized sparse modern hopfield model",
        "abstract": "we introduce the \\textbf{b}i-directional \\textbf{s}parse \\textbf{hop}field network (\\textbf{bishop}), a novel end-to-end framework for deep tabular learning. bishop handles the two major challenges of deep tabular learning: non-rotationally invariant data structure and feature sparsity in tabular data. our key motivation comes from the recent established connection between associative memory and attention mechanisms. consequently, bishop uses a dual-component approach, sequentially processing data both column-wise and row-wise through two interconnected directional learning modules. computationally, these modules house layers of generalized sparse modern hopfield layers, a sparse extension of the modern hopfield model with adaptable sparsity. methodologically, bishop facilitates multi-scale representation learning, capturing both intra-feature and inter-feature interactions, with adaptive sparsity at each scale. empirically, through experiments on diverse real-world datasets, we demonstrate that bishop surpasses current sota methods with significantly less hpo runs, marking it a robust solution for deep tabular learning.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03830",
        "authors": [
            "chenwei xu",
            "yu-chao huang",
            "jerry yao-chieh hu",
            "weijian li",
            "ammar gilani",
            "hsi-sheng goan",
            "han liu"
        ]
    },
    {
        "id": "2404.03831",
        "title": "sleepvst: sleep staging from near-infrared video signals using   pre-trained transformers",
        "abstract": "advances in camera-based physiological monitoring have enabled the robust, non-contact measurement of respiration and the cardiac pulse, which are known to be indicative of the sleep stage. this has led to research into camera-based sleep monitoring as a promising alternative to \"gold-standard\" polysomnography, which is cumbersome, expensive to administer, and hence unsuitable for longer-term clinical studies. in this paper, we introduce sleepvst, a transformer model which enables state-of-the-art performance in camera-based sleep stage classification (sleep staging). after pre-training on contact sensor data, sleepvst outperforms existing methods for cardio-respiratory sleep staging on the shhs and mesa datasets, achieving total cohen's kappa scores of 0.75 and 0.77 respectively. we then show that sleepvst can be successfully transferred to cardio-respiratory waveforms extracted from video, enabling fully contact-free sleep staging. using a video dataset of 50 nights, we achieve a total accuracy of 78.8\\% and a cohen's $\\kappa$ of 0.71 in four-class video-based sleep staging, setting a new state-of-the-art in the domain.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03831",
        "authors": [
            "jonathan f. carter",
            "jo\u00e3o jorge",
            "oliver gibson",
            "lionel tarassenko"
        ]
    },
    {
        "id": "2404.03833",
        "title": "an explainablefair framework for prediction of substance use disorder   treatment completion",
        "abstract": "fairness of machine learning models in healthcare has drawn increasing attention from clinicians, researchers, and even at the highest level of government. on the other hand, the importance of developing and deploying interpretable or explainable models has been demonstrated, and is essential to increasing the trustworthiness and likelihood of adoption of these models. the objective of this study was to develop and implement a framework for addressing both these issues - fairness and explainability. we propose an explainable fairness framework, first developing a model with optimized performance, and then using an in-processing approach to mitigate model biases relative to the sensitive attributes of race and sex. we then explore and visualize explanations of the model changes that lead to the fairness enhancement process through exploring the changes in importance of features. our resulting-fairness enhanced models retain high sensitivity with improved fairness and explanations of the fairness-enhancement that may provide helpful insights for healthcare providers to guide clinical decision-making and resource allocation.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03833",
        "authors": [
            "mary m. lucas",
            "xiaoyang wang",
            "chia-hsuan chang",
            "christopher c. yang",
            "jacqueline e. braughton",
            "quyen m. ngo"
        ]
    },
    {
        "id": "2404.03834",
        "title": "fast k-connectivity restoration in multi-robot systems for robust   communication maintenance",
        "abstract": "maintaining a robust communication network plays an important role in the success of a multi-robot team jointly performing an optimization task. a key characteristic of a robust cooperative multi-robot system is the ability to repair the communication topology in the case of robot failure. in this paper, we focus on the fast k-connectivity restoration (fcr) problem, which aims to repair a network to make it k-connected with minimum robot movement. we develop a quadratically constrained program (qcp) formulation of the fcr problem, which provides a way to optimally solve the problem, but cannot handle large instances due to high computational overhead. we therefore present a scalable algorithm, called ea-scr, for the fcr problem using graph theoretic concepts. by conducting empirical studies, we demonstrate that the ea-scr algorithm performs within 10 percent of the optimal while being orders of magnitude faster. we also show that ea-scr outperforms existing solutions by 30 percent in terms of the fcr distance metric.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03834",
        "authors": [
            "md ishat-e-rabban",
            "guangyao shi",
            "griffin bonner",
            "pratap tokekar"
        ]
    },
    {
        "id": "2404.03836",
        "title": "paris3d: reasoning-based 3d part segmentation using large multimodal   model",
        "abstract": "recent advancements in 3d perception systems have significantly improved their ability to perform visual recognition tasks such as segmentation. however, these systems still heavily rely on explicit human instruction to identify target objects or categories, lacking the capability to actively reason and comprehend implicit user intentions. we introduce a novel segmentation task known as reasoning part segmentation for 3d objects, aiming to output a segmentation mask based on complex and implicit textual queries about specific parts of a 3d object. to facilitate evaluation and benchmarking, we present a large 3d dataset comprising over 60k instructions paired with corresponding ground-truth part segmentation annotations specifically curated for reasoning-based 3d part segmentation. we propose a model that is capable of segmenting parts of 3d objects based on implicit textual queries and generating natural language explanations corresponding to 3d object segmentation requests. experiments show that our method achieves competitive performance to models that use explicit queries, with the additional abilities to identify part concepts, reason about them, and complement them with world knowledge. our source code, dataset, and trained models are available at https://github.com/amrinkareem/paris3d.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03836",
        "authors": [
            "amrin kareem",
            "jean lahoud",
            "hisham cholakkal"
        ]
    },
    {
        "id": "2404.03842",
        "title": "the low-degree hardness of finding large independent sets in sparse   random hypergraphs",
        "abstract": "we study the algorithmic task of finding large independent sets in erdos-renyi $r$-uniform hypergraphs on $n$ vertices having average degree $d$. krivelevich and sudakov showed that the maximum independent set has density $\\left(\\frac{r\\log d}{(r-1)d}\\right)^{1/(r-1)}$. we show that the class of low-degree polynomial algorithms can find independent sets of density $\\left(\\frac{\\log d}{(r-1)d}\\right)^{1/(r-1)}$ but no larger. this extends and generalizes earlier results of gamarnik and sudan, rahman and virag, and wein on graphs, and answers a question of bal and bennett. we conjecture that this statistical-computational gap holds for this problem.   additionally, we explore the universality of this gap by examining $r$-partite hypergraphs. a hypergraph $h=(v,e)$ is $r$-partite if there is a partition $v=v_1\\cup\\cdots\\cup v_r$ such that each edge contains exactly one vertex from each set $v_i$. we consider the problem of finding large balanced independent sets (independent sets containing the same number of vertices in each partition) in random $r$-partite hypergraphs with $n$ vertices in each partition and average degree $d$. we prove that the maximum balanced independent set has density $\\left(\\frac{r\\log d}{(r-1)d}\\right)^{1/(r-1)}$ asymptotically. furthermore, we prove an analogous low-degree computational threshold of $\\left(\\frac{\\log d}{(r-1)d}\\right)^{1/(r-1)}$. our results recover and generalize recent work of perkins and the second author on bipartite graphs.   while the graph case has been extensively studied, this work is the first to consider statistical-computational gaps of optimization problems on random hypergraphs. our results suggest that these gaps persist for larger uniformities as well as across many models. a somewhat surprising aspect of the gap for balanced independent sets is that the algorithm achieving the lower bound is a simple degree-1 polynomial.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03842",
        "authors": [
            "abhishek dhawan",
            "yuzhou wang"
        ]
    },
    {
        "id": "2404.03843",
        "title": "scaling motion forecasting models with ensemble distillation",
        "abstract": "motion forecasting has become an increasingly critical component of autonomous robotic systems. onboard compute budgets typically limit the accuracy of real-time systems. in this work we propose methods of improving motion forecasting systems subject to limited compute budgets by combining model ensemble and distillation techniques. the use of ensembles of deep neural networks has been shown to improve generalization accuracy in many application domains. we first demonstrate significant performance gains by creating a large ensemble of optimized single models. we then develop a generalized framework to distill motion forecasting model ensembles into small student models which retain high performance with a fraction of the computing cost. for this study we focus on the task of motion forecasting using real world data from autonomous driving systems. we develop ensemble models that are very competitive on the waymo open motion dataset (womd) and argoverse leaderboards. from these ensembles, we train distilled student models which have high performance at a fraction of the compute costs. these experiments demonstrate distillation from ensembles as an effective method for improving accuracy of predictive models for robotic systems with limited compute budgets.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03843",
        "authors": [
            "scott ettinger",
            "kratarth goel",
            "avikalp srivastava",
            "rami al-rfou"
        ]
    },
    {
        "id": "2404.03844",
        "title": "$\\pi_{2}^{p}$ vs pspace dichotomy for the quantified constraint   satisfaction problem",
        "abstract": "the quantified constraint satisfaction problem is the problem of evaluating a sentence with both quantifiers, over relations from some constraint language, with conjunction as the only connective. we show that for any constraint language on a finite domain the quantified constraint satisfaction problem is either in $\\pi_{2}^{p}$, or pspace-complete. additionally, we build a constraint language on a 6-element domain such that the quantified constraint satisfaction problem over this language is $\\pi_{2}^{p}$-complete.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03844",
        "authors": [
            "dmitriy zhuk"
        ]
    },
    {
        "id": "2404.03845",
        "title": "buck you: designing easy-to-onboard blockchain applications with   zero-knowledge login and sponsored transactions on sui",
        "abstract": "in this paper, we developed a blockchain application to demonstrate the functionality of sui's recent innovations: zero knowledge login and sponsored transactions. zero knowledge login allows users to create and access their blockchain wallets just with their oauth accounts (e.g., google, facebook, twitch), while sponsored transactions eliminate the need for users to prepare transaction fees, as they can delegate fees to sponsors' accounts. additionally, thanks to sui's storage rebate feature, sponsors in sponsored transactions can profit from the sponsorship, achieving a win-win and sustainable service model. zero knowledge login and sponsored transactions are pivotal in overcoming key challenges novice blockchain users face, particularly in managing private keys and depositing initial transaction fees. by addressing these challenges in the user experience of blockchain, sui makes the blockchain more accessible and engaging for novice users and paves the way for the broader adoption of blockchain applications in everyday life.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03845",
        "authors": [
            "eason chen",
            "zimo xiao",
            "justa liang",
            "damien chen",
            "pierce hung",
            "kostas kryptos chalkias"
        ]
    },
    {
        "id": "2404.03847",
        "title": "optimal quantile estimation: beyond the comparison model",
        "abstract": "estimating quantiles is one of the foundational problems of data sketching. given $n$ elements $x_1, x_2, \\dots, x_n$ from some universe of size $u$ arriving in a data stream, a quantile sketch estimates the rank of any element with additive error at most $\\varepsilon n$. a low-space algorithm solving this task has applications in database systems, network measurement, load balancing, and many other practical scenarios.   current quantile estimation algorithms described as optimal include the gk sketch (greenwald and khanna 2001) using $o(\\varepsilon^{-1} \\log n)$ words (deterministic) and the kll sketch (karnin, lang, and liberty 2016) using $o(\\varepsilon^{-1} \\log\\log(1/\\delta))$ words (randomized, with failure probability $\\delta$). however, both algorithms are only optimal in the comparison-based model, whereas most typical applications involve streams of integers that the sketch can use aside from making comparisons.   if we go beyond the comparison-based model, the deterministic q-digest sketch (shrivastava, buragohain, agrawal, and suri 2004) achieves a space complexity of $o(\\varepsilon^{-1}\\log u)$ words, which is incomparable to the previously-mentioned sketches. it has long been asked whether there is a quantile sketch using $o(\\varepsilon^{-1})$ words of space (which is optimal as long as $n \\leq \\mathrm{poly}(u)$). in this work, we present a deterministic algorithm using $o(\\varepsilon^{-1})$ words, resolving this line of work.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03847",
        "authors": [
            "meghal gupta",
            "mihir singhal",
            "hongxun wu"
        ]
    },
    {
        "id": "2404.03854",
        "title": "mitigating heterogeneity in federated multimodal learning with   biomedical vision-language pre-training",
        "abstract": "vision-language pre-training (vlp) has arised as an efficient scheme for multimodal representation learning, but it requires large-scale multimodal data for pre-training, making it an obstacle especially for biomedical applications. to overcome the data limitation, federated learning (fl) can be a promising strategy to scale up the dataset for biomedical vlp while protecting data privacy. however, client data are often heterogeneous in real-world scenarios, and we observe that local training on heterogeneous client data would distort the multimodal representation learning and lead to biased cross-modal alignment. to address this challenge, we propose federated distributional robust guidance-based (fedrgb) learning framework for federated vlp with robustness to data heterogeneity. specifically, we utilize a guidance-based local training scheme to reduce feature distortions, and employ a distribution-based min-max optimization to learn unbiased cross-modal alignment. the experiments on real-world datasets show our method successfully promotes efficient federated multimodal learning for biomedical vlp with data heterogeneity.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03854",
        "authors": [
            "zitao shuai",
            "liyue shen"
        ]
    },
    {
        "id": "2404.03862",
        "title": "verifiable by design: aligning language models to quote from   pre-training data",
        "abstract": "for humans to trust the fluent generations of large language models (llms), they must be able to verify their correctness against trusted, external sources. recent efforts aim to increase verifiability through citations of retrieved documents or post-hoc provenance. however, such citations are prone to mistakes that further complicate their verifiability. to address these limitations, we tackle the verifiability goal with a different philosophy: we trivialize the verification process by developing models that quote verbatim statements from trusted sources in pre-training data. we propose quote-tuning, which demonstrates the feasibility of aligning llms to leverage memorized information and quote from pre-training data. quote-tuning quantifies quoting against large corpora with efficient membership inference tools, and uses the amount of quotes as an implicit reward signal to construct a synthetic preference dataset for quoting, without any human annotation. next, the target model is aligned to quote using preference optimization algorithms. experimental results show that quote-tuning significantly increases the percentage of llm generation quoted verbatim from high-quality pre-training documents by 55% to 130% relative to untuned models while maintaining response quality. further experiments demonstrate that quote-tuning generalizes quoting to out-of-domain data, is applicable in different tasks, and provides additional benefits to truthfulness. quote-tuning not only serves as a hassle-free method to increase quoting but also opens up avenues for improving llm trustworthiness through better verifiability.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03862",
        "authors": [
            "jingyu zhang",
            "marc marone",
            "tianjian li",
            "benjamin van durme",
            "daniel khashabi"
        ]
    },
    {
        "id": "2404.03865",
        "title": "ffn-skipllm: a hidden gem for autoregressive decoding with adaptive feed   forward skipping",
        "abstract": "autoregressive large language models (e.g., llama, gpts) are omnipresent achieving remarkable success in language understanding and generation. however, such impressive capability typically comes with a substantial model size, which presents significant challenges for autoregressive token-by-token generation. to mitigate computation overload incurred during generation, several early-exit and layer-dropping strategies have been proposed. despite some promising success due to the redundancy across llms layers on metrics like rough-l/blue, our careful knowledge-intensive evaluation unveils issues such as generation collapse, hallucination of wrong facts, and noticeable performance drop even at the trivial exit ratio of 10-15% of layers. we attribute these errors primarily to ineffective handling of the kv cache through state copying during early-exit. in this work, we observed the saturation of computationally expensive feed-forward blocks of llm layers and proposed ffn-skipllm, which is a novel fine-grained skip strategy of autoregressive llms. more specifically, ffn-skipllm is an input-adaptive feed-forward skipping strategy that can skip 25-30% of ffn blocks of llms with marginal change in performance on knowledge-intensive generation tasks without any requirement to handle kv cache. our extensive experiments and ablation across benchmarks like mt-bench, factoid-qa, and variable-length text summarization illustrate how our simple and ease-at-use method can facilitate faster autoregressive decoding.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03865",
        "authors": [
            "ajay jaiswal",
            "bodun hu",
            "lu yin",
            "yeonju ro",
            "shiwei liu",
            "tianlong chen",
            "aditya akella"
        ]
    },
    {
        "id": "2404.03868",
        "title": "extract, define, canonicalize: an llm-based framework for knowledge   graph construction",
        "abstract": "in this work, we are interested in automated methods for knowledge graph creation (kgc) from input text. progress on large language models (llms) has prompted a series of recent works applying them to kgc, e.g., via zero/few-shot prompting. despite successes on small domain-specific datasets, these models face difficulties scaling up to text common in many real-world applications. a principal issue is that in prior methods, the kg schema has to be included in the llm prompt to generate valid triplets; larger and more complex schema easily exceed the llms' context window length. to address this problem, we propose a three-phase framework named extract-define-canonicalize (edc): open information extraction followed by schema definition and post-hoc canonicalization. edc is flexible in that it can be applied to settings where a pre-defined target schema is available and when it is not; in the latter case, it constructs a schema automatically and applies self-canonicalization. to further improve performance, we introduce a trained component that retrieves schema elements relevant to the input text; this improves the llms' extraction performance in a retrieval-augmented generation-like manner. we demonstrate on three kgc benchmarks that edc is able to extract high-quality triplets without any parameter tuning and with significantly larger schemas compared to prior works.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03868",
        "authors": [
            "bowen zhang",
            "harold soh"
        ]
    },
    {
        "id": "2404.03869",
        "title": "heterogeneous multi-agent reinforcement learning for zero-shot scalable   collaboration",
        "abstract": "the rise of multi-agent systems, especially the success of multi-agent reinforcement learning (marl), is reshaping our future across diverse domains like autonomous vehicle networks. however, marl still faces significant challenges, particularly in achieving zero-shot scalability, which allows trained marl models to be directly applied to unseen tasks with varying numbers of agents. in addition, real-world multi-agent systems usually contain agents with different functions and strategies, while the existing scalable marl methods only have limited heterogeneity. to address this, we propose a novel marl framework named scalable and heterogeneous proximal policy optimization (shppo), integrating heterogeneity into parameter-shared ppo-based marl networks. we first leverage a latent network to adaptively learn strategy patterns for each agent. second, we introduce a heterogeneous layer for decision-making, whose parameters are specifically generated by the learned latent variables. our approach is scalable as all the parameters are shared except for the heterogeneous layer, and gains both inter-individual and temporal heterogeneity at the same time. we implement our approach based on the state-of-the-art backbone ppo-based algorithm as shppo, while our approach is agnostic to the backbone and can be seamlessly plugged into any parameter-shared marl method. shppo exhibits superior performance over the baselines such as mappo and happo in classic marl environments like starcraft multi-agent challenge (smac) and google research football (grf), showcasing enhanced zero-shot scalability and offering insights into the learned latent representation's impact on team performance by visualization.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03869",
        "authors": [
            "xudong guo",
            "daming shi",
            "junjie yu",
            "wenhui fan"
        ]
    },
    {
        "id": "2404.03870",
        "title": "optimizing convolutional neural networks for identifying invasive   pollinator apis mellifera and finding a ligand drug to protect california's   biodiversity",
        "abstract": "in north america, there are many diverse species of native bees crucial for the environment, who are the primary pollinators of most native floral species. the californian agriculture industry imports european honeybees (apis mellifera) primarily for pollinating almonds. unfortunately, this has resulted in the unintended consequence of disrupting the native ecosystem and threatening many native bee species as they are outcompeted for food. our first step for protecting the native species is identification with the use of a convolutional neural network (cnn) to differentiate common native bee species from invasive ones. removing invasive colonies efficiently without harming native species is difficult as pesticides cause myriad diseases in native species. our approach seeks to prevent the formation of new queens, causing the colony's collapse. workers secrete royal jelly, a substance that causes fertility and longevity; it is fed to future honeybee queens. targeting the production of this substance is safe as no native species use it; small organic molecules (ligands) prevent the proteins apisimin and mrjp1 from combining and producing an oligomer used to form the substance. ideal ligands bind to only one of these proteins preventing them from joining together: they have a high affinity for one receptor and a significantly lower affinity for the other. we optimized the cnn to provide a framework for creating machine learning models that excel at differentiating between subspecies of insects by measuring the effects of image alteration and class grouping on model performance. the cnn is able to achieve an accuracy of 82% in differentiating between invasive and native bee species; 3 ligands have been identified as effective. our new approach offers a promising solution to curb the spread of invasive bees within california through an identification and neutralization method.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03870",
        "authors": [
            "arnav swaroop"
        ]
    },
    {
        "id": "2404.03873",
        "title": "privshape: extracting shapes in time series under user-level local   differential privacy",
        "abstract": "time series have numerous applications in finance, healthcare, iot, and smart city. in many of these applications, time series typically contain personal data, so privacy infringement may occur if they are released directly to the public. recently, local differential privacy (ldp) has emerged as the state-of-the-art approach to protecting data privacy. however, existing works on ldp-based collections cannot preserve the shape of time series. a recent work, patternldp, attempts to address this problem, but it can only protect a finite group of elements in a time series due to {\\omega}-event level privacy guarantee. in this paper, we propose privshape, a trie-based mechanism under user-level ldp to protect all elements. privshape first transforms a time series to reduce its length, and then adopts trie-expansion and two-level refinement to improve utility. by extensive experiments on real-world datasets, we demonstrate that privshape outperforms patternldp when adapted for offline use, and can effectively extract frequent shapes.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03873",
        "authors": [
            "yulian mao",
            "qingqing ye",
            "haibo hu",
            "qi wang",
            "kai huang"
        ]
    },
    {
        "id": "2404.03874",
        "title": "vellet: verifiable embedded wallet for securing authenticity and   integrity",
        "abstract": "the blockchain ecosystem, particularly with the rise of web3 and non-fungible tokens (nfts), has experienced a significant increase in users and applications. however, this expansion is challenged by the need to connect early adopters with a wider user base. a notable difficulty in this process is the complex interfaces of blockchain wallets, which can be daunting for those familiar with traditional payment methods. to address this issue, the category of \"embedded wallets\" has emerged as a promising solution. these wallets are seamlessly integrated into the front-end of decentralized applications (dapps), simplifying the onboarding process for users and making access more widely available. however, our insights indicate that this simplification introduces a trade-off between ease of use and security. embedded wallets lack transparency and auditability, leading to obscured transactions by the front end and a pronounced risk of fraud and phishing attacks. this paper proposes a new protocol to enhance the security of embedded wallets. our vellet protocol introduces a wallet verifier that can match the audit trail of embedded wallets on smart contracts, incorporating a process to verify authenticity and integrity. in the implementation architecture of the vellet protocol, we suggest using the text record feature of the ethereum name service (ens), known as a decentralized domain name service, to serve as a repository for managing the audit trails of smart contracts. this approach has been demonstrated to reduce the necessity for new smart contract development and operational costs, proving cost-effective through a proof-of-concept. this protocol is a vital step in reducing security risks associated with embedded wallets, ensuring their convenience does not undermine user security and trust.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03874",
        "authors": [
            "hiroki watanabe",
            "kohei ichihara",
            "takumi aita"
        ]
    },
    {
        "id": "2404.03876",
        "title": "increasing fairness in classification of out of distribution data for   facial recognition",
        "abstract": "standard classification theory assumes that the distribution of images in the test and training sets are identical. unfortunately, real-life scenarios typically feature unseen data (\"out-of-distribution data\") which is different from data in the training distribution(\"in-distribution\"). this issue is most prevalent in social justice problems where data from under-represented groups may appear in the test data without representing an equal proportion of the training data. this may result in a model returning confidently wrong decisions and predictions. we are interested in the following question: can the performance of a neural network improve on facial images of out-of-distribution data when it is trained simultaneously on multiple datasets of in-distribution data? we approach this problem by incorporating the outlier exposure model and investigate how the model's performance changes when other datasets of facial images were implemented. we observe that the accuracy and other metrics of the model can be increased by applying outlier exposure, incorporating a trainable weight parameter to increase the machine's emphasis on outlier images, and by re-weighting the importance of different class labels. we also experimented with whether sorting the images and determining outliers via image features would have more of an effect on the metrics than sorting by average pixel value. our goal was to make models not only more accurate but also more fair by scanning a more expanded range of images. we also tested the datasets in reverse order to see whether a more fair dataset with balanced features has an effect on the model's accuracy.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03876",
        "authors": [
            "gianluca barone",
            "aashrit cunchala",
            "rudy nunez"
        ]
    },
    {
        "id": "2404.03877",
        "title": "beyond the bridge: contention-based covert and side channel attacks on   multi-gpu interconnect",
        "abstract": "high-speed interconnects, such as nvlink, are integral to modern multi-gpu systems, acting as a vital link between cpus and gpus. this study highlights the vulnerability of multi-gpu systems to covert and side channel attacks due to congestion on interconnects. an adversary can infer private information about a victim's activities by monitoring nvlink congestion without needing special permissions. leveraging this insight, we develop a covert channel attack across two gpus with a bandwidth of 45.5 kbps and a low error rate, and introduce a side channel attack enabling attackers to fingerprint applications through the shared nvlink interconnect.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.03877",
        "authors": [
            "yicheng zhang",
            "ravan nazaraliyev",
            "sankha baran dutta",
            "nael abu-ghazaleh",
            "andres marquez",
            "kevin barker"
        ]
    },
    {
        "id": "2404.03880",
        "title": "semantic sql -- combining and optimizing semantic predicates in sql",
        "abstract": "in recent years, the surge in unstructured data analysis, facilitated by advancements in machine learning (ml), has prompted diverse approaches for handling images, text documents, and videos. analysts, leveraging ml models, can extract meaningful information from unstructured data and store it in relational databases, allowing the execution of sql queries for further analysis. simultaneously, vector databases have emerged, embedding unstructured data for efficient top-k queries based on textual queries. this paper introduces a novel framework ssql - semantic sql that utilizes these two approaches, enabling the incorporation of semantic queries within sql statements. our approach extends sql queries with dedicated keywords for specifying semantic queries alongside predicates related to ml model results and metadata. our experimental results show that using just semantic queries fails catastrophically to answer count and spatial queries in more than 60% of the cases. our proposed method jointly optimizes the queries containing both semantic predicates and predicates on structured tables, such as those generated by ml models or other metadata. further, to improve the query results, we incorporated human-in-the-loop feedback to determine the optimal similarity score threshold for returning results.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03880",
        "authors": [
            "akash mittal",
            "anshul bheemreddy",
            "huili tao"
        ]
    },
    {
        "id": "2404.03881",
        "title": "a bi-consolidating model for joint relational triple extraction",
        "abstract": "current methods to extract relational triples directly make a prediction based on a possible entity pair in a raw sentence without depending on entity recognition. the task suffers from a serious semantic overlapping problem, in which several relation triples may share one or two entities in a sentence. it is weak to learn discriminative semantic features relevant to a relation triple. in this paper, based on a two-dimensional sentence representation, a bi-consolidating model is proposed to address this problem by simultaneously reinforcing the local and global semantic features relevant to a relation triple. this model consists of a local consolidation component and a global consolidation component. the first component uses a pixel difference convolution to enhance semantic information of a possible triple representation from adjacent regions and mitigate noise in neighbouring neighbours. the second component strengthens the triple representation based a channel attention and a spatial attention, which has the advantage to learn remote semantic dependencies in a sentence. they are helpful to improve the performance of both entity identification and relation type classification in relation triple extraction. after evaluated on several publish datasets, it achieves competitive performance. analytical experiments demonstrate the effectiveness of our model for relational triple extraction and give motivation for other natural language processing tasks.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03881",
        "authors": [
            "xiaocheng luo",
            "yanping chen",
            "ruixue tang",
            "ruizhang huang",
            "yongbin qin"
        ]
    },
    {
        "id": "2404.03883",
        "title": "lidar-guided cross-attention fusion for hyperspectral band selection and   image classification",
        "abstract": "the fusion of hyperspectral and lidar data has been an active research topic. existing fusion methods have ignored the high-dimensionality and redundancy challenges in hyperspectral images, despite that band selection methods have been intensively studied for hyperspectral image (hsi) processing. this paper addresses this significant gap by introducing a cross-attention mechanism from the transformer architecture for the selection of hsi bands guided by lidar data. lidar provides high-resolution vertical structural information, which can be useful in distinguishing different types of land cover that may have similar spectral signatures but different structural profiles. in our approach, the lidar data are used as the \"query\" to search and identify the \"key\" from the hsi to choose the most pertinent bands for lidar. this method ensures that the selected hsi bands drastically reduce redundancy and computational requirements while working optimally with the lidar data. extensive experiments have been undertaken on three paired hsi and lidar data sets: houston 2013, trento and muufl. the results highlight the superiority of the cross-attention mechanism, underlining the enhanced classification accuracy of the identified hsi bands when fused with the lidar features. the results also show that the use of fewer bands combined with lidar surpasses the performance of state-of-the-art fusion models.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03883",
        "authors": [
            "judy x yang",
            "jun zhou",
            "jing wang",
            "hui tian",
            "wee chung liew"
        ]
    },
    {
        "id": "2404.03885",
        "title": "the esprit algorithm under high noise: optimal error scaling and noisy   super-resolution",
        "abstract": "subspace-based signal processing techniques, such as the estimation of signal parameters via rotational invariant techniques (esprit) algorithm, are popular methods for spectral estimation. these algorithms can achieve the so-called super-resolution scaling under low noise conditions, surpassing the well-known nyquist limit. however, the performance of these algorithms under high-noise conditions is not as well understood. existing state-of-the-art analysis indicates that esprit and related algorithms can be resilient even for signals where each observation is corrupted by statistically independent, mean-zero noise of size $\\mathcal{o}(1)$, but these analyses only show that the error $\\epsilon$ decays at a slow rate $\\epsilon=\\mathcal{\\tilde{o}}(n^{-1/2})$ with respect to the cutoff frequency $n$. in this work, we prove that under certain assumptions of bias and high noise, the esprit algorithm can attain a significantly improved error scaling $\\epsilon = \\mathcal{\\tilde{o}}(n^{-3/2})$, exhibiting noisy super-resolution scaling beyond the nyquist limit. we further establish a theoretical lower bound and show that this scaling is optimal. our analysis introduces novel matrix perturbation results, which could be of independent interest.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03885",
        "authors": [
            "zhiyan ding",
            "ethan n. epperly",
            "lin lin",
            "ruizhe zhang"
        ]
    },
    {
        "id": "2404.03888",
        "title": "a proximal policy optimization based intelligent home solar management",
        "abstract": "in the smart grid, the prosumers can sell unused electricity back to the power grid, assuming the prosumers own renewable energy sources and storage units. the maximizing of their profits under a dynamic electricity market is a problem that requires intelligent planning. to address this, we propose a framework based on proximal policy optimization (ppo) using recurrent rewards. by using the information about the rewards modeled effectively with ppo to maximize our objective, we were able to get over 30\\% improvement over the other naive algorithms in accumulating total profits. this shows promise in getting reinforcement learning algorithms to perform tasks required to plan their actions in complex domains like financial markets. we also introduce a novel method for embedding longs based on soliton waves that outperformed normal embedding in our use case with random floating point data augmentation.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03888",
        "authors": [
            "kode creer",
            "imitiaz parvez"
        ]
    },
    {
        "id": "2404.03891",
        "title": "can only llms do reasoning?: potential of small language models in task   planning",
        "abstract": "in robotics, the use of large language models (llms) is becoming prevalent, especially for understanding human commands. in particular, llms are utilized as domain-agnostic task planners for high-level human commands. llms are capable of chain-of-thought (cot) reasoning, and this allows llms to be task planners. however, we need to consider that modern robots still struggle to perform complex actions, and the domains where robots can be deployed are limited in practice. this leads us to pose a question: if small lms can be trained to reason in chains within a single domain, would even small lms be good task planners for the robots? to train smaller lms to reason in chains, we build `command-steps datasets' (cost) consisting of high-level commands along with corresponding actionable low-level steps, via llms. we release not only our datasets but also the prompt templates used to generate them, to allow anyone to build datasets for their domain. we compare gpt3.5 and gpt4 with the finetuned gpt2 for task domains, in tabletop and kitchen environments, and the result shows that gpt2-medium is comparable to gpt3.5 for task planning in a specific domain. our dataset, code, and more output samples can be found in https://github.com/gawon-choi/small-lms-task-planning",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03891",
        "authors": [
            "gawon choi",
            "hyemin ahn"
        ]
    },
    {
        "id": "2404.03893",
        "title": "kgexplainer: towards exploring connected subgraph explanations for   knowledge graph completion",
        "abstract": "knowledge graph completion (kgc) aims to alleviate the inherent incompleteness of knowledge graphs (kgs), which is a critical task for various applications, such as recommendations on the web. although knowledge graph embedding (kge) models have demonstrated superior predictive performance on kgc tasks, these models infer missing links in a black-box manner that lacks transparency and accountability, preventing researchers from developing accountable models. existing kge-based explanation methods focus on exploring key paths or isolated edges as explanations, which is information-less to reason target prediction. additionally, the missing ground truth leads to these explanation methods being ineffective in quantitatively evaluating explored explanations. to overcome these limitations, we propose kgexplainer, a model-agnostic method that identifies connected subgraph explanations and distills an evaluator to assess them quantitatively. kgexplainer employs a perturbation-based greedy search algorithm to find key connected subgraphs as explanations within the local structure of target predictions. to evaluate the quality of the explored explanations, kgexplainer distills an evaluator from the target kge model. by forwarding the explanations to the evaluator, our method can examine the fidelity of them. extensive experiments on benchmark datasets demonstrate that kgexplainer yields promising improvement and achieves an optimal ratio of 83.3% in human evaluation.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03893",
        "authors": [
            "tengfei ma",
            "xiang song",
            "wen tao",
            "mufei li",
            "jiani zhang",
            "xiaoqin pan",
            "jianxin lin",
            "bosheng song",
            "xiangxiang zeng"
        ]
    },
    {
        "id": "2404.03894",
        "title": "holon: a cybernetic interface for bio-semiotics",
        "abstract": "this paper presents an interactive artwork, \"holon\", a collection of 130 autonomous, cybernetic organisms that listen and make sound in collaboration with the natural environment. the work was developed for installation on water at a heritage-listed dock in melbourne, australia. conceptual issues informing the work are presented, along with a detailed technical overview of the implementation. individual holons are of three types, inspired by biological models of animal communication: composer/generators, collector/critics and disruptors. collectively, holon integrates and occupies elements of the acoustic spectrum in collaboration with human and non-human agents.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03894",
        "authors": [
            "jon mccormack",
            "elliott wilson"
        ]
    },
    {
        "id": "2404.03898",
        "title": "voltavision: a transfer learning model for electronic component   classification",
        "abstract": "in this paper, we analyze the effectiveness of transfer learning on classifying electronic components. transfer learning reuses pre-trained models to save time and resources in building a robust classifier rather than learning from scratch. our work introduces a lightweight cnn, coined as voltavision, and compares its performance against more complex models. we test the hypothesis that transferring knowledge from a similar task to our target domain yields better results than state-of-the-art models trained on general datasets. our dataset and code for this work are available at https://github.com/anasishfaque/voltavision.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03898",
        "authors": [
            "anas mohammad ishfaqul muktadir osmani",
            "taimur rahman",
            "salekul islam"
        ]
    },
    {
        "id": "2404.03899",
        "title": "effects of multisensory feedback on the perception and performance of   virtual reality hand-retargeted interaction",
        "abstract": "retargeting methods that modify the visual representation of real movements have been widely used to expand the interaction space and create engaging virtual reality experiences. for optimal user experience and performance, it is essential to specify the perception of retargeting and utilize the appropriate range of modification parameters. however, previous studies mostly concentrated on whether users perceived the target sense or not and rarely examined the perceptual accuracy and sensitivity to retargeting. moreover, it is unknown how the perception and performance in hand-retargeted interactions are influenced by multisensory feedback. in this study, we used rigorous psychophysical methods to specify users' perceptual accuracy and sensitivity to hand-retargeting and provide acceptable ranges of retargeting parameters. we also presented different multisensory feedback simultaneously with the retargeting to probe its effect on users' perception and task performance. the experimental results showed that providing continuous multisensory feedback, proportionate to the distance between the virtual hand and the targeted destination, heightened the accuracy of users' perception of hand retargeting without altering their perceptual sensitivity. furthermore, the utilization of multisensory feedback considerably improved the precision of task performance, particularly at lower gain factors. based on these findings, we propose design guidelines and potential applications of vr hand-retargeted interactions and multisensory feedback for optimal user experience and performance.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03899",
        "authors": [
            "hyunyoung jang",
            "jinwook kim",
            "jeongmi lee"
        ]
    },
    {
        "id": "2404.03900",
        "title": "nonparametric modern hopfield models",
        "abstract": "we present a nonparametric construction for deep learning compatible modern hopfield models and utilize this framework to debut an efficient variant. our key contribution stems from interpreting the memory storage and retrieval processes in modern hopfield models as a nonparametric regression problem subject to a set of query-memory pairs. crucially, our framework not only recovers the known results from the original dense modern hopfield model but also fills the void in the literature regarding efficient modern hopfield models, by introducing \\textit{sparse-structured} modern hopfield models with sub-quadratic complexity. we establish that this sparse model inherits the appealing theoretical properties of its dense analogue -- connection with transformer attention, fixed point convergence and exponential memory capacity -- even without knowing details of the hopfield energy function. additionally, we showcase the versatility of our framework by constructing a family of modern hopfield models as extensions, including linear, random masked, top-$k$ and positive random feature modern hopfield models. empirically, we validate the efficacy of our framework in both synthetic and realistic settings.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03900",
        "authors": [
            "jerry yao-chieh hu",
            "bo-yu chen",
            "dennis wu",
            "feng ruan",
            "han liu"
        ]
    },
    {
        "id": "2404.03906",
        "title": "deep phase coded image prior",
        "abstract": "phase-coded imaging is a computational imaging method designed to tackle tasks such as passive depth estimation and extended depth of field (edof) using depth cues inserted during image capture. most of the current deep learning-based methods for depth estimation or all-in-focus imaging require a training dataset with high-quality depth maps and an optimal focus point at infinity for all-in-focus images. such datasets are difficult to create, usually synthetic, and require external graphic programs. we propose a new method named \"deep phase coded image prior\" (dpcip) for jointly recovering the depth map and all-in-focus image from a coded-phase image using solely the captured image and the optical information of the imaging system. our approach does not depend on any specific dataset and surpasses prior supervised techniques utilizing the same imaging system. this improvement is achieved through the utilization of a problem formulation based on implicit neural representation (inr) and deep image prior (dip). due to our zero-shot method, we overcome the barrier of acquiring accurate ground-truth data of depth maps and all-in-focus images for each new phase-coded system introduced. this allows focusing mainly on developing the imaging system, and not on ground-truth data collection.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03906",
        "authors": [
            "nimrod shabtay",
            "eli schwartz",
            "raja giryes"
        ]
    },
    {
        "id": "2404.03908",
        "title": "multi-task learning for lung sound & lung disease classification",
        "abstract": "in recent years, advancements in deep learning techniques have considerably enhanced the efficiency and accuracy of medical diagnostics. in this work, a novel approach using multi-task learning (mtl) for the simultaneous classification of lung sounds and lung diseases is proposed. our proposed model leverages mtl with four different deep learning models such as 2d cnn, resnet50, mobilenet and densenet to extract relevant features from the lung sound recordings. the icbhi 2017 respiratory sound database was employed in the current study. the mtl for mobilenet model performed better than the other models considered, with an accuracy of74\\% for lung sound analysis and 91\\% for lung diseases classification. results of the experimentation demonstrate the efficacy of our approach in classifying both lung sounds and lung diseases concurrently.   in this study,using the demographic data of the patients from the database, risk level computation for chronic obstructive pulmonary disease is also carried out. for this computation, three machine learning algorithms namely logistic regression, svm and random forest classifierswere employed. among these ml algorithms, the random forest classifier had the highest accuracy of 92\\%.this work helps in considerably reducing the physician's burden of not just diagnosing the pathology but also effectively communicating to the patient about the possible causes or outcomes.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03908",
        "authors": [
            "suma k",
            "deepali koppad",
            "preethi kumar",
            "neha a kantikar",
            "surabhi ramesh"
        ]
    },
    {
        "id": "2404.03911",
        "title": "under-canopy navigation using aerial lidar maps",
        "abstract": "autonomous navigation in unstructured natural environments poses a significant challenge. in goal navigation tasks without prior information, the limited look-ahead of onboard sensors utilised by robots compromises path efficiency. we propose a novel approach that leverages an above-the-canopy aerial map for improved ground robot navigation. our system utilises aerial lidar scans to create a 3d probabilistic occupancy map, uniquely incorporating the uncertainty in the aerial vehicle's trajectory for improved accuracy. novel path planning cost functions are introduced, combining path length with obstruction risk estimated from the probabilistic map. the d-star lite algorithm then calculates an optimal (minimum-cost) path to the goal. this system also allows for dynamic replanning upon encountering unforeseen obstacles on the ground. extensive experiments and ablation studies in simulated and real forests demonstrate the effectiveness of our system.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03911",
        "authors": [
            "lucas carvalho de lima",
            "nicholas lawrance",
            "kasra khosoussi",
            "paulo borges",
            "michael bruenig"
        ]
    },
    {
        "id": "2404.03912",
        "title": "forget nli, use a dictionary: zero-shot topic classification for   low-resource languages with application to luxembourgish",
        "abstract": "in nlp, zero-shot classification (zsc) is the task of assigning labels to textual data without any labeled examples for the target classes. a common method for zsc is to fine-tune a language model on a natural language inference (nli) dataset and then use it to infer the entailment between the input document and the target labels. however, this approach faces certain challenges, particularly for languages with limited resources. in this paper, we propose an alternative solution that leverages dictionaries as a source of data for zsc. we focus on luxembourgish, a low-resource language spoken in luxembourg, and construct two new topic relevance classification datasets based on a dictionary that provides various synonyms, word translations and example sentences. we evaluate the usability of our dataset and compare it with the nli-based approach on two topic classification tasks in a zero-shot manner. our results show that by using the dictionary-based dataset, the trained models outperform the ones following the nli-based approach for zsc. while we focus on a single low-resource language in this study, we believe that the efficacy of our approach can also transfer to other languages where such a dictionary is available.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03912",
        "authors": [
            "fred philippy",
            "shohreh haddadan",
            "siwen guo"
        ]
    },
    {
        "id": "2404.03913",
        "title": "concept weaver: enabling multi-concept fusion in text-to-image models",
        "abstract": "while there has been significant progress in customizing text-to-image generation models, generating images that combine multiple personalized concepts remains challenging. in this work, we introduce concept weaver, a method for composing customized text-to-image diffusion models at inference time. specifically, the method breaks the process into two steps: creating a template image aligned with the semantics of input prompts, and then personalizing the template using a concept fusion strategy. the fusion strategy incorporates the appearance of the target concepts into the template image while retaining its structural details. the results indicate that our method can generate multiple custom concepts with higher identity fidelity compared to alternative approaches. furthermore, the method is shown to seamlessly handle more than two concepts and closely follow the semantic meaning of the input prompt without blending appearances across different subjects.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03913",
        "authors": [
            "gihyun kwon",
            "simon jenni",
            "dingzeyu li",
            "joon-young lee",
            "jong chul ye",
            "fabian caba heilbron"
        ]
    },
    {
        "id": "2404.03914",
        "title": "open vocabulary keyword spotting through transfer learning from speech   synthesis",
        "abstract": "identifying keywords in an open-vocabulary context is crucial for personalizing interactions with smart devices. previous approaches to open vocabulary keyword spotting dependon a shared embedding space created by audio and text encoders. however, these approaches suffer from heterogeneous modality representations (i.e., audio-text mismatch). to address this issue, our proposed framework leverages knowledge acquired from a pre-trained text-to-speech (tts) system. this knowledge transfer allows for the incorporation of awareness of audio projections into the text representations derived from the text encoder. the performance of the proposed approach is compared with various baseline methods across four different datasets. the robustness of our proposed model is evaluated by assessing its performance across different word lengths and in an out-of-vocabulary (oov) scenario. additionally, the effectiveness of transfer learning from the tts system is investigated by analyzing its different intermediate representations. the experimental results indicate that, in the challenging libriphrase hard dataset, the proposed approach outperformed the cross-modality correspondence detector (cmcd) method by a significant improvement of 8.22% in area under the curve (auc) and 12.56% in equal error rate (eer).",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03914",
        "authors": [
            "kesavaraj v",
            "anil kumar vuppala"
        ]
    },
    {
        "id": "2404.03915",
        "title": "nonlinear kalman filtering based on self-attention mechanism and lattice   trajectory piecewise linear approximation",
        "abstract": "the traditional kalman filter (kf) is widely applied in control systems, but it relies heavily on the accuracy of the system model and noise parameters, leading to potential performance degradation when facing inaccuracies. to address this issue, introducing neural networks into the kf framework offers a data-driven solution to compensate for these inaccuracies, improving the filter's performance while maintaining interpretability. nevertheless, existing studies mostly employ recurrent neural network (rnn), which fails to fully capture the dependencies among state sequences and lead to an unstable training process. in this paper, we propose a novel kalman filtering algorithm named the attention kalman filter (atkf), which incorporates a self-attention network to capture the dependencies among state sequences. to address the instability in the recursive training process, a parallel pre-training strategy is devised. specifically, this strategy involves piecewise linearizing the system via lattice trajectory piecewise linear (ltpwl) expression, and generating pre-training data through a batch estimation algorithm, which exploits the self-attention mechanism's parallel processing ability. experimental results on a two-dimensional nonlinear system demonstrate that atkf outperforms other filters under noise disturbances and model mismatches.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03915",
        "authors": [
            "jiaming wang",
            "xinyu geng",
            "jun xu"
        ]
    },
    {
        "id": "2404.03916",
        "title": "estimating mixed memberships in multi-layer networks",
        "abstract": "community detection in multi-layer networks has emerged as a crucial area of modern network analysis. however, conventional approaches often assume that nodes belong exclusively to a single community, which fails to capture the complex structure of real-world networks where nodes may belong to multiple communities simultaneously. to address this limitation, we propose novel spectral methods to estimate the common mixed memberships in the multi-layer mixed membership stochastic block model. the proposed methods leverage the eigen-decomposition of three aggregate matrices: the sum of adjacency matrices, the debiased sum of squared adjacency matrices, and the sum of squared adjacency matrices. we establish rigorous theoretical guarantees for the consistency of our methods. specifically, we derive per-node error rates under mild conditions on network sparsity, demonstrating their consistency as the number of nodes and/or layers increases under the multi-layer mixed membership stochastic block model. our theoretical results reveal that the method leveraging the sum of adjacency matrices generally performs poorer than the other two methods for mixed membership estimation in multi-layer networks. we conduct extensive numerical experiments to empirically validate our theoretical findings. for real-world multi-layer networks with unknown community information, we introduce two novel modularity metrics to quantify the quality of mixed membership community detection. finally, we demonstrate the practical applications of our algorithms and modularity metrics by applying them to real-world multi-layer networks, demonstrating their effectiveness in extracting meaningful community structures.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03916",
        "authors": [
            "huan qing"
        ]
    },
    {
        "id": "2404.03917",
        "title": "recovery of differential operators from a noisy fourier transform",
        "abstract": "the paper concerns problems of the recovery of differential operators from a noisy fourier transform. in particular, optimal methods are obtained for the recovery of powers of generalized laplace operators from a noisy fourier transform in the $l_2$-metric.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03917",
        "authors": [
            "konstantin yu. osipenko"
        ]
    },
    {
        "id": "2404.03919",
        "title": "understanding the impact of coalitions between ev charging stations",
        "abstract": "the rapid growth of electric vehicles (evs) is driving the expansion of charging infrastructure globally. this expansion, however, places significant charging demand on the electricity grid, impacting grid operations and electricity pricing. while coordination among all charging stations is beneficial, it may not be always feasible. however, a subset of charging stations, which could be jointly operated by a company, could coordinate to decide their charging profile. in this paper we investigate whether such coalitions between charging stations is better than no coordination.   we model ev charging as a non-cooperative aggregative game, where each station's cost is determined by both monetary payments tied to reactive electricity prices on the grid and its sensitivity to deviations from a nominal charging profile. we consider a solution concept that we call $\\mathcal{c}$-nash equilibrium, which is tied to a coalition $\\mathcal{c}$ of charging stations coordinating to reduce their cumulative costs. we provide sufficient conditions, in terms of the demand and sensitivity of charging stations, to determine when independent (uncoordinated) operation of charging stations could result in lower overall costs to charging stations, the coalition, and charging stations outside the coalition. somewhat counter to intuition, we demonstrate scenarios where allowing charging stations to operate independently is better than coordinating as a coalition. jointly, these results provide operators of charging stations insights into how to coordinate their charging behavior, and open several research directions.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03919",
        "authors": [
            "sukanya kudva",
            "kshitij kulkarni",
            "chinmay maheshwari",
            "anil aswani",
            "shankar sastry"
        ]
    },
    {
        "id": "2404.03921",
        "title": "simple techniques for enhancing sentence embeddings in generative   language models",
        "abstract": "sentence embedding stands as a fundamental task within the realm of natural language processing, finding extensive application in search engines, expert systems, and question-and-answer platforms. with the continuous evolution of large language models such as llama and mistral, research on sentence embedding has recently achieved notable breakthroughs. however, these advancements mainly pertain to fine-tuning scenarios, leaving explorations into computationally efficient direct inference methods for sentence representation in a nascent stage. this paper endeavors to bridge this research gap. through comprehensive experimentation, we challenge the widely held belief in the necessity of an explicit one-word limitation for deriving sentence embeddings from pre-trained language models (plms). we demonstrate that this approach, while beneficial for generative models under direct inference scenario, is not imperative for discriminative models or the fine-tuning of generative plms. this discovery sheds new light on the design of manual templates in future studies. building upon this insight, we propose two innovative prompt engineering techniques capable of further enhancing the expressive power of plms' raw embeddings: pretended chain of thought and knowledge enhancement. we confirm their effectiveness across various plm types and provide a detailed exploration of the underlying factors contributing to their success.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03921",
        "authors": [
            "bowen zhang",
            "kehua chang",
            "chunping li"
        ]
    },
    {
        "id": "2404.03923",
        "title": "quand rechercher c'est faire des vagues : dans et {\\`a} partir des   images algorithmiques",
        "abstract": "in search of the wave is a computer-generated film made in 2013, highlighting the computation of images through computer simulation, and through text and voice. originating from a screening of the film at the gustave eiffel university, the article presents a reflection on research-creation in and from algorithmic images. fundamentally, what is it in this research-creation -- especially in research on algorithmic imagery -- that can be set in motion? without fully distinguishing between what would be research on one hand and creation on the other, we focus on characterizing forms, aesthetics, or theories that contribute to possible shifts. the inventory of these possibilities is precisely the challenge of the text: from mathematics to image and visualization, from the birth of generative aesthetics to the coding related to pioneering works (recoding), or from indexing new aesthetics to new forms of critical production.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03923",
        "authors": [
            "ga\u00ebtan robillard"
        ]
    },
    {
        "id": "2404.03924",
        "title": "learning correlation structures for vision transformers",
        "abstract": "we introduce a new attention mechanism, dubbed structural self-attention (structsa), that leverages rich correlation patterns naturally emerging in key-query interactions of attention. structsa generates attention maps by recognizing space-time structures of key-query correlations via convolution and uses them to dynamically aggregate local contexts of value features. this effectively leverages rich structural patterns in images and videos such as scene layouts, object motion, and inter-object relations. using structsa as a main building block, we develop the structural vision transformer (structvit) and evaluate its effectiveness on both image and video classification tasks, achieving state-of-the-art results on imagenet-1k, kinetics-400, something-something v1 & v2, diving-48, and finegym.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03924",
        "authors": [
            "manjin kim",
            "paul hongsuck seo",
            "cordelia schmid",
            "minsu cho"
        ]
    },
    {
        "id": "2404.03925",
        "title": "lightoctree: lightweight 3d spatially-coherent indoor lighting   estimation",
        "abstract": "we present a lightweight solution for estimating spatially-coherent indoor lighting from a single rgb image. previous methods for estimating illumination using volumetric representations have overlooked the sparse distribution of light sources in space, necessitating substantial memory and computational resources for achieving high-quality results. we introduce a unified, voxel octree-based illumination estimation framework to produce 3d spatially-coherent lighting. additionally, a differentiable voxel octree cone tracing rendering layer is proposed to eliminate regular volumetric representation throughout the entire process and ensure the retention of features across different frequency domains. this reduction significantly decreases spatial usage and required floating-point operations without substantially compromising precision. experimental results demonstrate that our approach achieves high-quality coherent estimation with minimal cost compared to previous methods.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03925",
        "authors": [
            "xuecan wang",
            "shibang xiao",
            "xiaohui liang"
        ]
    },
    {
        "id": "2404.03929",
        "title": "slsm : an efficient strategy for lazy schema migration on shared-nothing   databases",
        "abstract": "by introducing intermediate states for metadata changes and ensuring that at most two versions of metadata exist in the cluster at the same time, shared-nothing databases are capable of making online, asynchronous schema changes. however, this method leads to delays in the deployment of new schemas since it requires waiting for massive data backfill. to shorten the service vacuum period before the new schema is available, this paper proposes a strategy named slsm for zero-downtime schema migration on shared-nothing databases. based on the lazy migration of stand-alone databases, slsm keeps the old and new schemas with the same data distribution, reducing the node communication overhead of executing migration transactions for shared-nothing databases. further, slsm combines migration transactions with user transactions by extending the distributed execution plan to allow the data involved in migration transactions to directly serve user transactions, greatly reducing the waiting time of user transactions. experiments demonstrate that our strategy can greatly reduce the latency of user transactions and improve the efficiency of data migration compared to existing schemes.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03929",
        "authors": [
            "zhilin zeng",
            "hui li",
            "xiyue gao",
            "hui zhang",
            "huiquan zhang",
            "jiangtao cui"
        ]
    },
    {
        "id": "2404.03930",
        "title": "real-gdsr: real-world guided dsm super-resolution via edge-enhancing   residual network",
        "abstract": "a low-resolution digital surface model (dsm) features distinctive attributes impacted by noise, sensor limitations and data acquisition conditions, which failed to be replicated using simple interpolation methods like bicubic. this causes super-resolution models trained on synthetic data does not perform effectively on real ones. training a model on real low and high resolution dsms pairs is also a challenge because of the lack of information. on the other hand, the existence of other imaging modalities of the same scene can be used to enrich the information needed for large-scale super-resolution. in this work, we introduce a novel methodology to address the intricacies of real-world dsm super-resolution, named real-gdsr, breaking down this ill-posed problem into two steps. the first step involves the utilization of a residual local refinement network. this strategic approach departs from conventional methods that trained to directly predict height values instead of the differences (residuals) and utilize large receptive fields in their networks. the second step introduces a diffusion-based technique that enhances the results on a global scale, with a primary focus on smoothing and edge preservation. our experiments underscore the effectiveness of the proposed method. we conduct a comprehensive evaluation, comparing it to recent state-of-the-art techniques in the domain of real-world dsm super-resolution (sr). our approach consistently outperforms these existing methods, as evidenced through qualitative and quantitative assessments.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03930",
        "authors": [
            "daniel panangian",
            "ksenia bittner"
        ]
    },
    {
        "id": "2404.03932",
        "title": "on quantum learning algorithms for noisy linear problems",
        "abstract": "quantum algorithms have shown successful results in solving noisy linear problems with quantum samples in which cryptographic hard problems are relevant. in this paper the previous results are investigated in detail, leading to new quantum and classical algorithms under the same assumptions as in the earlier works. to be specific, we present a polynomial-time quantum algorithm for solving the ring learning with errors problem with quantum samples which was deemed to be infeasible in [12], as well as polynomial-time classical algorithms that are more efficient than the corresponding quantum algorithms in solving the short integer solution problem with quantum samples and the learning with errors problem with size-reduced quantum samples.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03932",
        "authors": [
            "minkyu kim",
            "panjin kim"
        ]
    },
    {
        "id": "2404.03938",
        "title": "data augmentation with in-context learning and comparative evaluation in   math word problem solving",
        "abstract": "math word problem (mwp) solving presents a challenging task in natural language processing (nlp). this study aims to provide mwp solvers with a more diverse training set, ultimately improving their ability to solve various math problems. we propose several methods for data augmentation by modifying the problem texts and equations, such as synonym replacement, rule-based: question replacement, and rule based: reversing question methodologies over two english mwp datasets. this study extends by introducing a new in-context learning augmentation method, employing the llama-7b language model. this approach involves instruction-based prompting for rephrasing the math problem texts. performance evaluations are conducted on 9 baseline models, revealing that augmentation methods outperform baseline models. moreover, concatenating examples generated by various augmentation methods further improves performance.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03938",
        "authors": [
            "gulsum yigit",
            "mehmet fatih amasyali"
        ]
    },
    {
        "id": "2404.03940",
        "title": "towards introspective loop closure in 4d radar slam",
        "abstract": "imaging radar is an emerging sensor modality in the context of localization and mapping (slam), especially suitable for vision-obstructed environments. this article investigates the use of 4d imaging radars for slam and analyzes the challenges in robust loop closure. previous work indicates that 4d radars, together with inertial measurements, offer ample information for accurate odometry estimation. however, the low field of view, limited resolution, and sparse and noisy measurements render loop closure a significantly more challenging problem. our work builds on the previous work - tbv slam - which was proposed for robust loop closure with 360$^\\circ$ spinning radars. this article highlights and addresses challenges inherited from a directional 4d radar, such as sparsity, noise, and reduced field of view, and discusses why the common definition of a loop closure is unsuitable. by combining multiple quality measures for accurate loop closure detection adapted to 4d radar data, significant results in trajectory estimation are achieved; the absolute trajectory error is as low as 0.46 m over a distance of 1.8 km, with consistent operation over multiple environments.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03940",
        "authors": [
            "maximilian hilger",
            "vladim\u00edr kubelka",
            "daniel adolfsson",
            "henrik andreasson",
            "achim j. lilienthal"
        ]
    },
    {
        "id": "2404.03943",
        "title": "pomdp-guided active force-based search for robotic insertion",
        "abstract": "in robotic insertion tasks where the uncertainty exceeds the allowable tolerance, a good search strategy is essential for successful insertion and significantly influences efficiency. the commonly used blind search method is time-consuming and does not exploit the rich contact information. in this paper, we propose a novel search strategy that actively utilizes the information contained in the contact configuration and shows high efficiency. in particular, we formulate this problem as a partially observable markov decision process (pomdp) with carefully designed primitives based on an in-depth analysis of the contact configuration's static stability. from the formulated pomdp, we can derive a novel search strategy. thanks to its simplicity, this search strategy can be incorporated into a finite-state-machine (fsm) controller. the behaviors of the fsm controller are realized through a low-level cartesian impedance controller. our method is based purely on the robot's proprioceptive sensing and does not need visual or tactile sensors. to evaluate the effectiveness of our proposed strategy and control framework, we conduct extensive comparison experiments in simulation, where we compare our method with the baseline approach. the results demonstrate that our proposed method achieves a higher success rate with a shorter search time and search trajectory length compared to the baseline method. additionally, we show that our method is robust to various initial displacement errors.",
        "doi": "10.1109/iros55552.2023.10342421",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03943",
        "authors": [
            "chen wang",
            "haoxiang luo",
            "kun zhang",
            "hua chen",
            "jia pan",
            "wei zhang"
        ]
    },
    {
        "id": "2404.03948",
        "title": "re-pseudonymization strategies for smart meter data are not robust to   deep learning profiling attacks",
        "abstract": "smart meters, devices measuring the electricity and gas consumption of a household, are currently being deployed at a fast rate throughout the world. the data they collect are extremely useful, including in the fight against climate change. however, these data and the information that can be inferred from them are highly sensitive. re-pseudonymization, i.e., the frequent replacement of random identifiers over time, is widely used to share smart meter data while mitigating the risk of re-identification. we here show how, in spite of re-pseudonymization, households' consumption records can be pieced together with high accuracy in large-scale datasets. we propose the first deep learning-based profiling attack against re-pseudonymized smart meter data. our attack combines neural network embeddings, which are used to extract features from weekly consumption records and are tailored to the smart meter identification task, with a nearest neighbor classifier. we evaluate six neural networks architectures as the embedding model. our results suggest that the transformer and cnn-lstm architectures vastly outperform previous methods as well as other architectures, successfully identifying the correct household 73.4% of the time among 5139 households based on electricity and gas consumption records (54.5% for electricity only). we further show that the features extracted by the embedding model maintain their effectiveness when transferred to a set of users disjoint from the one used to train the model. finally, we extensively evaluate the robustness of our results. taken together, our results strongly suggest that even frequent re-pseudonymization strategies can be reversed, strongly limiting their ability to prevent re-identification in practice.",
        "doi": "10.1145/3626232.3653272",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03948",
        "authors": [
            "ana-maria cretu",
            "miruna rusu",
            "yves-alexandre de montjoye"
        ]
    },
    {
        "id": "2404.03951",
        "title": "a conceptual design of in-game real and virtual currency tracker",
        "abstract": "the gaming industry is earning huge revenues from incorporating virtual currencies into the game design experience. even if it is a useful approach for the game industry to boost up their earnings, the unidirectional and bidirectional in-game virtual currencies can invoke inadequate gaming behaviors and additions among players. the market lacks gaming and customer protection regulations to avoid the financial, behavioral, and psychological exploitation of users. therefore, it is needed to develop visual or textual interface design recommendations that help the game players keep balance in their spending and improve their gaming behavior. this paper presents a conceptual design of an in-game purchasing module that allows the user to observe their real time spendings in relation to virtual currency buying.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03951",
        "authors": [
            "dennis barzanoff",
            "amna asif"
        ]
    },
    {
        "id": "2404.03953",
        "title": "towards understanding the impact of code modifications on software   quality metrics",
        "abstract": "context: in the realm of software development, maintaining high software quality is a persistent challenge. however, this challenge is often impeded by the lack of comprehensive understanding of how specific code modifications influence quality metrics.   objective: this study ventures to bridge this gap through an approach that aspires to assess and interpret the impact of code modifications. the underlying hypothesis posits that code modifications inducing similar changes in software quality metrics can be grouped into distinct clusters, which can be effectively described using an ai language model, thus providing a simple understanding of code changes and their quality implications.   method: to validate this hypothesis, we built and analyzed a dataset from popular github repositories, segmented into individual code modifications. each project was evaluated against software quality metrics pre and post-application. machine learning techniques were utilized to cluster these modifications based on the induced changes in the metrics. simultaneously, an ai language model was employed to generate descriptions of each modification's function.   results: the results reveal distinct clusters of code modifications, each accompanied by a concise description, revealing their collective impact on software quality metrics.   conclusions: the findings suggest that this research is a significant step towards a comprehensive understanding of the complex relationship between code changes and software quality, which has the potential to transform software maintenance strategies and enable the development of more accurate quality prediction models.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03953",
        "authors": [
            "thomas karanikiotis",
            "andreas l. symeonidis"
        ]
    },
    {
        "id": "2404.03958",
        "title": "minor containment and disjoint paths in almost-linear time",
        "abstract": "we give an algorithm that, given graphs $g$ and $h$, tests whether $h$ is a minor of $g$ in time ${\\cal o}_h(n^{1+o(1)})$; here, $n$ is the number of vertices of $g$ and the ${\\cal o}_h(\\cdot)$-notation hides factors that depend on $h$ and are computable. by the graph minor theorem, this implies the existence of an $n^{1+o(1)}$-time membership test for every minor-closed class of graphs.   more generally, we give an ${\\cal o}_{h,|x|}(m^{1+o(1)})$-time algorithm for the rooted version of the problem, in which $g$ comes with a set of roots $x\\subseteq v(g)$ and some of the branch sets of the sought minor model of $h$ are required to contain prescribed subsets of $x$; here, $m$ is the total number of vertices and edges of $g$. this captures the disjoint paths problem, for which we obtain an ${\\cal o}_{k}(m^{1+o(1)})$-time algorithm, where $k$ is the number of terminal pairs. for all the mentioned problems, the fastest algorithms known before are due to kawarabayashi, kobayashi, and reed [jctb 2012], and have a time complexity that is quadratic in the number of vertices of $g$.   our algorithm has two main ingredients: first, we show that by using the dynamic treewidth data structure of korhonen, majewski, nadara, pilipczuk, and soko{\\l}owski [focs 2023], the irrelevant vertex technique of robertson and seymour can be implemented in almost-linear time on apex-minor-free graphs. then, we apply the recent advances in almost-linear time flow/cut algorithms to give an almost-linear time implementation of the recursive understanding technique, which effectively reduces the problem to apex-minor-free graphs.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03958",
        "authors": [
            "tuukka korhonen",
            "micha\u0142 pilipczuk",
            "giannos stamoulis"
        ]
    },
    {
        "id": "2404.03962",
        "title": "rasim: a range-aware high-fidelity rgb-d data simulation pipeline for   real-world applications",
        "abstract": "in robotic vision, a de-facto paradigm is to learn in simulated environments and then transfer to real-world applications, which poses an essential challenge in bridging the sim-to-real domain gap. while mainstream works tackle this problem in the rgb domain, we focus on depth data synthesis and develop a range-aware rgb-d data simulation pipeline (rasim). in particular, high-fidelity depth data is generated by imitating the imaging principle of real-world sensors. a range-aware rendering strategy is further introduced to enrich data diversity. extensive experiments show that models trained with rasim can be directly applied to real-world scenarios without any finetuning and excel at downstream rgb-d perception tasks.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03962",
        "authors": [
            "xingyu liu",
            "chenyangguang zhang",
            "gu wang",
            "ruida zhang",
            "xiangyang ji"
        ]
    },
    {
        "id": "2404.03964",
        "title": "a mean correction for improved phase-averaging accuracy in oscillatory,   multiscale, differential equations",
        "abstract": "this paper introduces a new algorithm to improve the accuracy of numerical phase-averaging in oscillatory, multiscale, differential equations. phase-averaging is a technique that applies averaging to a mapped variable to remove highly oscillatory linear terms from the differential equation. this retains the main contribution of fast oscillations on the low frequencies without needing to resolve the rapid oscillations themselves. however, this comes at the cost of an averaging error, which we aim to offset with a modified mapping. the new mapping includes a mean correction which encodes an average measure of the nonlinear interactions. this mapping was introduced in tao (2019) for weak nonlinearity and relied on classical time averaging. our algorithm extends this work to the case where 1) the nonlinearity is not weak but the linear oscillations are fast and 2) finite averaging windows are applied via a smooth kernel, which has the advantage of retaining low frequencies whilst still eliminating the fastest oscillations. we show that the new algorithm reduces phase errors in the mapped variable for the swinging spring ode. we also demonstrate accuracy improvements compared to standard phase-averaging in numerical experiments with the one-dimensional rotating shallow water equations, a useful test case for weather and climate applications. as the mean correction term can be computed in parallel, this new mapping has potential as a more accurate, yet still computationally cheap, coarse propagator for the oscillatory parareal method.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03964",
        "authors": [
            "timothy charles andrews",
            "beth a. wingate"
        ]
    },
    {
        "id": "2404.03965",
        "title": "tensions between preference and performance: designing for visual   exploration of multi-frequency medical network data",
        "abstract": "the analysis of complex high-dimensional data is a common task in many domains, resulting in bespoke visual exploration tools. expectations and practices of domain experts as users do not always align with visualization theory. in this paper, we report on a design study in the medical domain where we developed two high-fidelity prototypes encoding eeg-derived brain network data with different types of visualizations. we evaluate these prototypes regarding effectiveness, efficiency, and preference with two groups: participants with domain knowledge (domain experts in medical research) and those without domain knowledge, both groups having little or no visualization experience. a requirement analysis and study of low-fidelity prototypes revealed a strong preference for a novel and aesthetically pleasing visualization design, as opposed to a design that is considered more optimal based on visualization theory. our study highlights the pros and cons of both approaches, discussing trade-offs between task-specific measurements and subjective preference. while the aesthetically pleasing and novel low-fidelity prototype was favored, the results of our evaluation show that, in most cases, this was not reflected in participants' performance or subjective preference for the high-fidelity prototypes.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03965",
        "authors": [
            "christian knoll",
            "laura koesten",
            "isotta rigoni",
            "serge vulli\u00e9moz",
            "torsten m\u00f6ller"
        ]
    },
    {
        "id": "2404.03969",
        "title": "transformers for molecular property prediction: lessons learned from the   past five years",
        "abstract": "molecular property prediction (mpp) is vital for drug discovery, crop protection, and environmental science. over the last decades, diverse computational techniques have been developed, from using simple physical and chemical properties and molecular fingerprints in statistical models and classical machine learning to advanced deep learning approaches. in this review, we aim to distill insights from current research on employing transformer models for mpp. we analyze the currently available models and explore key questions that arise when training and fine-tuning a transformer model for mpp. these questions encompass the choice and scale of the pre-training data, optimal architecture selections, and promising pre-training objectives. our analysis highlights areas not yet covered in current research, inviting further exploration to enhance the field's understanding. additionally, we address the challenges in comparing different models, emphasizing the need for standardized data splitting and robust statistical analysis.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03969",
        "authors": [
            "afnan sultan",
            "jochen sieg",
            "miriam mathea",
            "andrea volkamer"
        ]
    },
    {
        "id": "2404.03974",
        "title": "game-theoretic distributed learning approach for heterogeneous-cost task   allocation with budget constraints",
        "abstract": "this paper investigates heterogeneous-cost task allocation with budget constraints (hctab), wherein heterogeneity is manifested through the varying capabilities and costs associated with different agents for task execution. different from the centralized optimization-based method, the hctab problem is solved using a fully distributed framework, and a coalition formation game is introduced to provide a theoretical guarantee for this distributed framework. to solve the coalition formation game, a convergence-guaranteed log-linear learning algorithm based on heterogeneous cost is proposed. this algorithm incorporates two improvement strategies, namely, a cooperative exchange strategy and a heterogeneous-cost log-linear learning strategy. these strategies are specifically designed to be compatible with the heterogeneous cost and budget constraints characteristic of the hctab problem. through ablation experiments, we demonstrate the effectiveness of these two improvements. finally, numerical results show that the proposed algorithm outperforms existing task allocation algorithms and learning algorithms in terms of solving the hctab problem.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03974",
        "authors": [
            "weiyi yang",
            "xiaolu liu",
            "lei he",
            "yonghao du",
            "yingwu chen"
        ]
    },
    {
        "id": "2404.03977",
        "title": "seme at semeval-2024 task 2: comparing masked and generative language   models on natural language inference for clinical trials",
        "abstract": "this paper describes our submission to task 2 of semeval-2024: safe biomedical natural language inference for clinical trials. the multi-evidence natural language inference for clinical trial data (nli4ct) consists of a textual entailment (te) task focused on the evaluation of the consistency and faithfulness of natural language inference (nli) models applied to clinical trial reports (ctr). we test 2 distinct approaches, one based on finetuning and ensembling masked language models and the other based on prompting large language models using templates, in particular, using chain-of-thought and contrastive chain-of-thought. prompting flan-t5-large in a 2-shot setting leads to our best system that achieves 0.57 f1 score, 0.64 faithfulness, and 0.56 consistency.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03977",
        "authors": [
            "mathilde aguiar",
            "pierre zweigenbaum",
            "nona naderi"
        ]
    },
    {
        "id": "2404.03978",
        "title": "random walk in random permutation set theory",
        "abstract": "random walk is an explainable approach for modeling natural processes at the molecular level. the random permutation set theory (rpst) serves as a framework for uncertainty reasoning, extending the applicability of dempster-shafer theory. recent explorations indicate a promising link between rpst and random walk. in this study, we conduct an analysis and construct a random walk model based on the properties of rpst, with monte carlo simulations of such random walk. our findings reveal that the random walk generated through rpst exhibits characteristics similar to those of a gaussian random walk and can be transformed into a wiener process through a specific limiting scaling procedure. this investigation establishes a novel connection between rpst and random walk theory, thereby not only expanding the applicability of rpst, but also demonstrating the potential for combining the strengths of both approaches to improve problem-solving abilities.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03978",
        "authors": [
            "jiefeng zhou",
            "zhen li",
            "yong deng"
        ]
    },
    {
        "id": "2404.03979",
        "title": "stability in graphs with matroid constraints",
        "abstract": "we study the following independent stable set problem. let g be an undirected graph and m = (v(g),i) be a matroid whose elements are the vertices of g. for an integer k\\geq 1, the task is to decide whether g contains a set s\\subseteq v(g) of size at least k which is independent (stable) in g and independent in m. this problem generalizes several well-studied algorithmic problems, including rainbow independent set, rainbow matching, and bipartite matching with separation. we show that   - when the matroid m is represented by the independence oracle, then for any computable function f, no algorithm can solve independent stable set using f(k)n^{o(k)} calls to the oracle.   - on the other hand, when the graph g is of degeneracy d, then the problem is solvable in time o((d+1)^kn), and hence is fpt parameterized by d+k. moreover, when the degeneracy d is a constant (which is not a part of the input), the problem admits a kernel polynomial in k. more precisely, we prove that for every integer d\\geq 0, the problem admits a kernelization algorithm that in time n^{o(d)} outputs an equivalent framework with a graph on dk^{o(d)} vertices. a lower bound complements this when d is part of the input: independent stable set does not admit a polynomial kernel when parameterized by k+d unless np \\subseteq conp/poly. this lower bound holds even when m is a partition matroid.   - another set of results concerns the scenario when the graph g is chordal. in this case, our computational lower bound excludes an fpt algorithm when the input matroid is given by its independence oracle. however, we demonstrate that independent stable set can be solved in 2^{o(k)}||m||^{o(1)} time when m is a linear matroid given by its representation. in the same setting, independent stable set does not have a polynomial kernel when parameterized by k unless np\\subseteq conp/poly.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03979",
        "authors": [
            "fedor v. fomin",
            "petr a. golovach",
            "tuukka korhonen",
            "saket saurabh"
        ]
    },
    {
        "id": "2404.03981",
        "title": "approximation schemes for geometric knapsack for packing spheres and fat   objects",
        "abstract": "we study the geometric knapsack problem in which we are given a set of $d$-dimensional objects (each with associated profits) and the goal is to find the maximum profit subset that can be packed non-overlappingly into a given $d$-dimensional (unit hypercube) knapsack. even if $d=2$ and all input objects are disks, this problem is known to be np-hard [demaine, fekete, lang, 2010]. in this paper, we give polynomial-time $(1+\\varepsilon)$-approximation algorithms for the following types of input objects in any constant dimension $d$:   - disks and hyperspheres,   - a class of fat convex polygons that generalizes regular $k$-gons for $k\\ge 5$ (formally, polygons with a constant number of edges, whose lengths are in a bounded range, and in which each angle is strictly larger than $\\pi/2$)   - arbitrary fat convex objects that are sufficiently small compared to the knapsack.   we remark that in our \\textsf{ptas} for disks and hyperspheres, we output the computed set of objects, but for a $o_\\varepsilon(1)$ of them we determine their coordinates only up to an exponentially small error. however, it is not clear whether there always exists a $(1+\\varepsilon)$-approximate solution that uses only rational coordinates for the disks' centers. we leave this as an open problem which is related to well-studied geometric questions in the realm of circle packing.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03981",
        "authors": [
            "pritam acharya",
            "sujoy bhore",
            "aaryan gupta",
            "arindam khan",
            "bratin mondal",
            "andreas wiese"
        ]
    },
    {
        "id": "2404.03984",
        "title": "roma-iqss: an objective alignment approach via state-based value   learning and round-robin multi-agent scheduling",
        "abstract": "effective multi-agent collaboration is imperative for solving complex, distributed problems. in this context, two key challenges must be addressed: first, autonomously identifying optimal objectives for collective outcomes; second, aligning these objectives among agents. traditional frameworks, often reliant on centralized learning, struggle with scalability and efficiency in large multi-agent systems. to overcome these issues, we introduce a decentralized state-based value learning algorithm that enables agents to independently discover optimal states. furthermore, we introduce a novel mechanism for multi-agent interaction, wherein less proficient agents follow and adopt policies from more experienced ones, thereby indirectly guiding their learning process. our theoretical analysis shows that our approach leads decentralized agents to an optimal collective policy. empirical experiments further demonstrate that our method outperforms existing decentralized state-based and action-based value learning strategies by effectively identifying and aligning optimal objectives.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03984",
        "authors": [
            "chi-hui lin",
            "joewie j. koh",
            "alessandro roncone",
            "lijun chen"
        ]
    },
    {
        "id": "2404.03985",
        "title": "implicit automata in {\\lambda}-calculi iii: affine planar   string-to-string functions",
        "abstract": "we prove a characterization of first-order string-to-string transduction via $\\lambda$-terms typed in non-commutative affine logic that compute with church encoding, extending the analogous known characterization of star-free languages. we show that every first-order transduction can be computed by a $\\lambda$-term using a known krohn-rhodes-style decomposition lemma. the converse direction is given by compiling $\\lambda$-terms into two-way reversible planar transducers. the soundness of this translation involves showing that the transition functions of those transducers live in a monoidal closed category of diagrams in which we can interpret purely affine $\\lambda$-terms. one challenge is that the unit of the tensor of the category in question is not a terminal object. as a result, our interpretation does not identify $\\beta$-equivalent terms, but it does turn $\\beta$-reductions into inequalities in a poset-enrichment of the category of diagrams.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03985",
        "authors": [
            "c\u00e9cilia pradic",
            "ian price"
        ]
    },
    {
        "id": "2404.03987",
        "title": "investigating the robustness of modelling decisions for few-shot   cross-topic stance detection: a preregistered study",
        "abstract": "for a viewpoint-diverse news recommender, identifying whether two news articles express the same viewpoint is essential. one way to determine \"same or different\" viewpoint is stance detection. in this paper, we investigate the robustness of operationalization choices for few-shot stance detection, with special attention to modelling stance across different topics. our experiments test pre-registered hypotheses on stance detection. specifically, we compare two stance task definitions (pro/con versus same side stance), two llm architectures (bi-encoding versus cross-encoding), and adding natural language inference knowledge, with pre-trained roberta models trained with shots of 100 examples from 7 different stance detection datasets. some of our hypotheses and claims from earlier work can be confirmed, while others give more inconsistent results. the effect of the same side stance definition on performance differs per dataset and is influenced by other modelling choices. we found no relationship between the number of training topics in the training shots and performance. in general, cross-encoding out-performs bi-encoding, and adding nli training to our models gives considerable improvement, but these results are not consistent across all datasets. our results indicate that it is essential to include multiple datasets and systematic modelling experiments when aiming to find robust modelling choices for the concept `stance'.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03987",
        "authors": [
            "myrthe reuver",
            "suzan verberne",
            "antske fokkens"
        ]
    },
    {
        "id": "2404.03988",
        "title": "model selection with model zoo via graph learning",
        "abstract": "pre-trained deep learning (dl) models are increasingly accessible in public repositories, i.e., model zoos. given a new prediction task, finding the best model to fine-tune can be computationally intensive and costly, especially when the number of pre-trained models is large. selecting the right pre-trained models is crucial, yet complicated by the diversity of models from various model families (like resnet, vit, swin) and the hidden relationships between models and datasets. existing methods, which utilize basic information from models and datasets to compute scores indicating model performance on target datasets, overlook the intrinsic relationships, limiting their effectiveness in model selection. in this study, we introduce transfergraph, a novel framework that reformulates model selection as a graph learning problem. transfergraph constructs a graph using extensive metadata extracted from models and datasets, while capturing their inherent relationships. through comprehensive experiments across 16 real datasets, both images and texts, we demonstrate transfergraph's effectiveness in capturing essential model-dataset relationships, yielding up to a 32% improvement in correlation between predicted performance and the actual fine-tuning results compared to the state-of-the-art methods.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03988",
        "authors": [
            "ziyu li",
            "hilco van der wilk",
            "danning zhan",
            "megha khosla",
            "alessandro bozzon",
            "rihan hai"
        ]
    },
    {
        "id": "2404.03990",
        "title": "a bound preserving energy stable scheme for a nonlocal cahn-hilliard   equation",
        "abstract": "we present a finite-volume based numerical scheme for a nonlocal cahn-hilliard equation which combines ideas from recent numerical schemes for gradient flow equations and nonlocal cahn-hilliard equations. the equation of interest is a special case of a previously derived and studied system of equations which describes phase separation in ternary mixtures. we prove the scheme is both energy stable and respects the analytical bounds of the solution. furthermore, we present numerical demonstrations of the theoretical results using both the flory-huggins (fh) and ginzburg-landau (gl) free-energy potentials.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03990",
        "authors": [
            "rainey lyons",
            "grigor nika",
            "adrian muntean"
        ]
    },
    {
        "id": "2404.03991",
        "title": "towards efficient and accurate ct segmentation via edge-preserving   probabilistic downsampling",
        "abstract": "downsampling images and labels, often necessitated by limited resources or to expedite network training, leads to the loss of small objects and thin boundaries. this undermines the segmentation network's capacity to interpret images accurately and predict detailed labels, resulting in diminished performance compared to processing at original resolutions. this situation exemplifies the trade-off between efficiency and accuracy, with higher downsampling factors further impairing segmentation outcomes. preserving information during downsampling is especially critical for medical image segmentation tasks. to tackle this challenge, we introduce a novel method named edge-preserving probabilistic downsampling (epd). it utilizes class uncertainty within a local window to produce soft labels, with the window size dictating the downsampling factor. this enables a network to produce quality predictions at low resolutions. beyond preserving edge details more effectively than conventional nearest-neighbor downsampling, employing a similar algorithm for images, it surpasses bilinear interpolation in image downsampling, enhancing overall performance. our method significantly improved intersection over union (iou) to 2.85%, 8.65%, and 11.89% when downsampling data to 1/2, 1/4, and 1/8, respectively, compared to conventional interpolation methods.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03991",
        "authors": [
            "shahzad ali",
            "yu rim lee",
            "soo young park",
            "won young tak",
            "soon ki jung"
        ]
    },
    {
        "id": "2404.03992",
        "title": "rolling the dice for better deep learning performance: a study of   randomness techniques in deep neural networks",
        "abstract": "this paper investigates how various randomization techniques impact deep neural networks (dnns). randomization, like weight noise and dropout, aids in reducing overfitting and enhancing generalization, but their interactions are poorly understood. the study categorizes randomness techniques into four types and proposes new methods: adding noise to the loss function and random masking of gradient updates. using particle swarm optimizer (pso) for hyperparameter optimization, it explores optimal configurations across mnist, fashion-mnist, cifar10, and cifar100 datasets. over 30,000 configurations are evaluated, revealing data augmentation and weight initialization randomness as main performance contributors. correlation analysis shows different optimizers prefer distinct randomization types. the complete implementation and dataset are available on github.",
        "doi": "10.1016/j.ins.2024.120500",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03992",
        "authors": [
            "mohammed ghaith altarabichi",
            "s\u0142awomir nowaczyk",
            "sepideh pashami",
            "peyman sheikholharam mashhadi",
            "julia handl"
        ]
    },
    {
        "id": "2404.03994",
        "title": "pros and cons! evaluating chatgpt on software vulnerability",
        "abstract": "this paper proposes a pipeline for quantitatively evaluating interactive llms such as chatgpt using publicly available dataset. we carry out an extensive technical evaluation of chatgpt using big-vul covering five different common software vulnerability tasks. we evaluate the multitask and multilingual aspects of chatgpt based on this dataset. we found that the existing state-of-the-art methods are generally superior to chatgpt in software vulnerability detection. although chatgpt improves accuracy when providing context information, it still has limitations in accurately predicting severity ratings for certain cwe types. in addition, chatgpt demonstrates some ability in locating vulnerabilities for certain cwe types, but its performance varies among different cwe types. chatgpt exhibits limited vulnerability repair capabilities in both providing and not providing context information. finally, chatgpt shows uneven performance in generating cve descriptions for various cwe types, with limited accuracy in detailed information. overall, though chatgpt performs well in some aspects, it still needs improvement in understanding the subtle differences in code vulnerabilities and the ability to describe vulnerabilities in order to fully realize its potential. our evaluation framework provides valuable insights for further enhancing chatgpt' s software vulnerability handling capabilities.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03994",
        "authors": [
            "xin yin"
        ]
    },
    {
        "id": "2404.03995",
        "title": "balancing progress and responsibility: a synthesis of sustainability   trade-offs of ai-based systems",
        "abstract": "recent advances in artificial intelligence (ai) capabilities have increased the eagerness of companies to integrate ai into software systems. while ai can be used to have a positive impact on several dimensions of sustainability, this is often overshadowed by its potential negative influence. while many studies have explored sustainability factors in isolation, there is insufficient holistic coverage of potential sustainability benefits or costs that practitioners need to consider during decision-making for ai adoption. we therefore aim to synthesize trade-offs related to sustainability in the context of integrating ai into software systems. we want to make the sustainability benefits and costs of integrating ai more transparent and accessible for practitioners.   the study was conducted in collaboration with a dutch financial organization. we first performed a rapid review that led to the inclusion of 151 research papers. afterward, we conducted six semi-structured interviews to enrich the data with industry perspectives. the combined results showcase the potential sustainability benefits and costs of integrating ai. the labels synthesized from the review regarding potential sustainability benefits were clustered into 16 themes, with \"energy management\" being the most frequently mentioned one. 11 themes were identified in the interviews, with the top mentioned theme being \"employee wellbeing\". regarding sustainability costs, the review discovered seven themes, with \"deployment issues\" being the most popular one, followed by \"ethics & society\". \"environmental issues\" was the top theme from the interviews. our results provide valuable insights to organizations and practitioners for understanding the potential sustainability implications of adopting ai.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03995",
        "authors": [
            "apoorva nalini pradeep kumar",
            "justus bogner",
            "markus funke",
            "patricia lago"
        ]
    },
    {
        "id": "2404.03996",
        "title": "fast genetic algorithm for feature selection -- a qualitative   approximation approach",
        "abstract": "evolutionary algorithms (eas) are often challenging to apply in real-world settings since evolutionary computations involve a large number of evaluations of a typically expensive fitness function. for example, an evaluation could involve training a new machine learning model. an approximation (also known as meta-model or a surrogate) of the true function can be used in such applications to alleviate the computation cost. in this paper, we propose a two-stage surrogate-assisted evolutionary approach to address the computational issues arising from using genetic algorithm (ga) for feature selection in a wrapper setting for large datasets. we define 'approximation usefulness' to capture the necessary conditions to ensure correctness of the ea computations when an approximation is used. based on this definition, we propose a procedure to construct a lightweight qualitative meta-model by the active selection of data instances. we then use a meta-model to carry out the feature selection task. we apply this procedure to the ga-based algorithm chc (cross generational elitist selection, heterogeneous recombination and cataclysmic mutation) to create a qualitative approximations variant, chcqx. we show that chcqx converges faster to feature subset solutions of significantly higher accuracy (as compared to chc), particularly for large datasets with over 100k instances. we also demonstrate the applicability of the thinking behind our approach more broadly to swarm intelligence (si), another branch of the evolutionary computation (ec) paradigm with results of psoqx, a qualitative approximation adaptation of the particle swarm optimization (pso) method. a github repository with the complete implementation is available.",
        "doi": "10.1016/j.eswa.2022.118528",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03996",
        "authors": [
            "mohammed ghaith altarabichi",
            "s\u0142awomir nowaczyk",
            "sepideh pashami",
            "peyman sheikholharam mashhadi"
        ]
    },
    {
        "id": "2404.03997",
        "title": "demonstration guided multi-objective reinforcement learning",
        "abstract": "multi-objective reinforcement learning (morl) is increasingly relevant due to its resemblance to real-world scenarios requiring trade-offs between multiple objectives. catering to diverse user preferences, traditional reinforcement learning faces amplified challenges in morl. to address the difficulty of training policies from scratch in morl, we introduce demonstration-guided multi-objective reinforcement learning (dg-morl). this novel approach utilizes prior demonstrations, aligns them with user preferences via corner weight support, and incorporates a self-evolving mechanism to refine suboptimal demonstrations. our empirical studies demonstrate dg-morl's superiority over existing morl algorithms, establishing its robustness and efficacy, particularly under challenging conditions. we also provide an upper bound of the algorithm's sample complexity.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03997",
        "authors": [
            "junlin lu",
            "patrick mannion",
            "karl mason"
        ]
    },
    {
        "id": "2404.03998",
        "title": "physics-inspired synthesized underwater image dataset",
        "abstract": "this paper introduces the physics-inspired synthesized underwater image dataset (phiswid), a dataset tailored for enhancing underwater image processing through physics-inspired image synthesis. deep learning approaches to underwater image enhancement typically demand extensive datasets, yet acquiring paired clean and degraded underwater ones poses significant challenges. while several underwater image datasets have been proposed using physics-based synthesis, a publicly accessible collection has been lacking. additionally, most underwater image synthesis approaches do not intend to reproduce atmospheric scenes, resulting in incomplete enhancement. phiswid addresses this gap by offering a set of paired ground-truth (atmospheric) and synthetically degraded underwater images, showcasing not only color degradation but also the often-neglected effects of marine snow, a composite of organic matter and sand particles that considerably impairs underwater image clarity. the dataset applies these degradations to atmospheric rgb-d images, enhancing the dataset's realism and applicability. phiswid is particularly valuable for training deep neural networks in a supervised learning setting and for objectively assessing image quality in benchmark analyses. our results reveal that even a basic u-net architecture, when trained with phiswid, substantially outperforms existing methods in underwater image enhancement. we intend to release phiswid publicly, contributing a significant resource to the advancement of underwater imaging technology.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03998",
        "authors": [
            "reina kaneko",
            "hiroshi higashi",
            "yuichi tanaka"
        ]
    },
    {
        "id": "2404.03999",
        "title": "finsler-laplace-beltrami operators with application to shape analysis",
        "abstract": "the laplace-beltrami operator (lbo) emerges from studying manifolds equipped with a riemannian metric. it is often called the swiss army knife of geometry processing as it allows to capture intrinsic shape information and gives rise to heat diffusion, geodesic distances, and a multitude of shape descriptors. it also plays a central role in geometric deep learning. in this work, we explore finsler manifolds as a generalization of riemannian manifolds. we revisit the finsler heat equation and derive a finsler heat kernel and a finsler-laplace-beltrami operator (flbo): a novel theoretically justified anisotropic laplace-beltrami operator (albo). in experimental evaluations we demonstrate that the proposed flbo is a valuable alternative to the traditional riemannian-based lbo and albos for spatial filtering and shape correspondence estimation. we hope that the proposed finsler heat kernel and the flbo will inspire further exploration of finsler geometry in the computer vision community.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.03999",
        "authors": [
            "simon weber",
            "thomas dag\u00e8s",
            "maolin gao",
            "daniel cremers"
        ]
    },
    {
        "id": "2404.04001",
        "title": "approximate umap allows for high-rate online visualization of   high-dimensional data streams",
        "abstract": "in the bci field, introspection and interpretation of brain signals are desired for providing feedback or to guide rapid paradigm prototyping but are challenging due to the high noise level and dimensionality of the signals. deep neural networks are often introspected by transforming their learned feature representations into 2- or 3-dimensional subspace visualizations using projection algorithms like uniform manifold approximation and projection (umap). unfortunately, these methods are computationally expensive, making the projection of data streams in real-time a non-trivial task. in this study, we introduce a novel variant of umap, called approximate umap (aumap). it aims at generating rapid projections for real-time introspection. to study its suitability for real-time projecting, we benchmark the methods against standard umap and its neural network counterpart parametric umap. our results show that approximate umap delivers projections that replicate the projection space of standard umap while decreasing projection speed by an order of magnitude and maintaining the same training time.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04001",
        "authors": [
            "peter wassenaar",
            "pierre guetschel",
            "michael tangermann"
        ]
    },
    {
        "id": "2404.04003",
        "title": "buddie: a business document dataset for multi-task information   extraction",
        "abstract": "the field of visually rich document understanding (vrdu) aims to solve a multitude of well-researched nlp tasks in a multi-modal domain. several datasets exist for research on specific tasks of vrdu such as document classification (dc), key entity extraction (kee), entity linking, visual question answering (vqa), inter alia. these datasets cover documents like invoices and receipts with sparse annotations such that they support one or two co-related tasks (e.g., entity extraction and entity linking). unfortunately, only focusing on a single specific of documents or task is not representative of how documents often need to be processed in the wild - where variety in style and requirements is expected. in this paper, we introduce buddie (business document dataset for information extraction), the first multi-task dataset of 1,665 real-world business documents that contains rich and dense annotations for dc, kee, and vqa. our dataset consists of publicly available business entity documents from us state government websites. the documents are structured and vary in their style and layout across states and types (e.g., forms, certificates, reports, etc.). we provide data variety and quality metrics for buddie as well as a series of baselines for each task. our baselines cover traditional textual, multi-modal, and large language model approaches to vrdu.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04003",
        "authors": [
            "ran zmigrod",
            "dongsheng wang",
            "mathieu sibue",
            "yulong pei",
            "petr babkin",
            "ivan brugere",
            "xiaomo liu",
            "nacho navarro",
            "antony papadimitriou",
            "william watson",
            "zhiqiang ma",
            "armineh nourbakhsh",
            "sameena shah"
        ]
    },
    {
        "id": "2404.04004",
        "title": "towards safe robot use with edged or pointed objects: a surrogate study   assembling a human hand injury protection database",
        "abstract": "the use of pointed or edged tools or objects is one of the most challenging aspects of today's application of physical human-robot interaction (phri). one reason for this is that the severity of harm caused by such edged or pointed impactors is less well studied than for blunt impactors. consequently, the standards specify well-reasoned force and pressure thresholds for blunt impactors and advise avoiding any edges and corners in contacts. nevertheless, pointed or edged impactor geometries cannot be completely ruled out in real phri applications. for example, to allow edged or pointed tools such as screwdrivers near human operators, the knowledge of injury severity needs to be extended so that robot integrators can perform well-reasoned, time-efficient risk assessments. in this paper, we provide the initial datasets on injury prevention for the human hand based on drop tests with surrogates for the human hand, namely pig claws and chicken drumsticks. we then demonstrate the ease and efficiency of robot use using the dataset for contact on two examples. finally, our experiments provide a set of injuries that may also be expected for human subjects under certain robot mass-velocity constellations in collisions. to extend this work, testing on human samples and a collaborative effort from research institutes worldwide is needed to create a comprehensive human injury avoidance database for any phri scenario and thus for safe phri applications including edged and pointed geometries.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04004",
        "authors": [
            "robin jeanne kirschner",
            "carina m. micheler",
            "yangcan zhou",
            "sebastian siegner",
            "mazin hamad",
            "claudio glowalla",
            "jan neumann",
            "nader rajaei",
            "rainer burgkart",
            "sami haddadin"
        ]
    },
    {
        "id": "2404.04006",
        "title": "from theory to comprehension: a comparative study of differential   privacy and $k$-anonymity",
        "abstract": "the notion of $\\varepsilon$-differential privacy is a widely used concept of providing quantifiable privacy to individuals. however, it is unclear how to explain the level of privacy protection provided by a differential privacy mechanism with a set $\\varepsilon$. in this study, we focus on users' comprehension of the privacy protection provided by a differential privacy mechanism. to do so, we study three variants of explaining the privacy protection provided by differential privacy: (1) the original mathematical definition; (2) $\\varepsilon$ translated into a specific privacy risk; and (3) an explanation using the randomized response technique. we compare users' comprehension of privacy protection employing these explanatory models with their comprehension of privacy protection of $k$-anonymity as baseline comprehensibility. our findings suggest that participants' comprehension of differential privacy protection is enhanced by the privacy risk model and the randomized response-based model. moreover, our results confirm our intuition that privacy protection provided by $k$-anonymity is more comprehensible.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04006",
        "authors": [
            "saskia nu\u00f1ez von voigt",
            "luise mehner",
            "florian tschorsch"
        ]
    },
    {
        "id": "2404.04007",
        "title": "neural-symbolic videoqa: learning compositional spatio-temporal   reasoning for real-world video question answering",
        "abstract": "compositional spatio-temporal reasoning poses a significant challenge in the field of video question answering (videoqa). existing approaches struggle to establish effective symbolic reasoning structures, which are crucial for answering compositional spatio-temporal questions. to address this challenge, we propose a neural-symbolic framework called neural-symbolic videoqa (ns-videoqa), specifically designed for real-world videoqa tasks. the uniqueness and superiority of ns-videoqa are two-fold: 1) it proposes a scene parser network (spn) to transform static-dynamic video scenes into symbolic representation (sr), structuralizing persons, objects, relations, and action chronologies. 2) a symbolic reasoning machine (srm) is designed for top-down question decompositions and bottom-up compositional reasonings. specifically, a polymorphic program executor is constructed for internally consistent reasoning from sr to the final answer. as a result, our ns-videoqa not only improves the compositional spatio-temporal reasoning in real-world videoqa task, but also enables step-by-step error analysis by tracing the intermediate results. experimental evaluations on the agqa decomp benchmark demonstrate the effectiveness of the proposed ns-videoqa framework. empirical studies further confirm that ns-videoqa exhibits internal consistency in answering compositional questions and significantly improves the capability of spatio-temporal and logical inference for videoqa tasks.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04007",
        "authors": [
            "lili liang",
            "guanglu sun",
            "jin qiu",
            "lizhong zhang"
        ]
    },
    {
        "id": "2404.04011",
        "title": "validation of critical maneuvers based on shared control",
        "abstract": "this paper presents the validation of shared control strategies for critical maneuvers in automated driving systems. shared control involves collaboration between the driver and automation, allowing both parties to actively engage and cooperate at different levels of the driving task. the involvement of the driver adds complexity to the control loop, necessitating comprehensive validation methodologies. the proposed approach focuses on two critical maneuvers: overtaking in low visibility scenarios and lateral evasive actions. a modular architecture with an arbitration module and shared control algorithms is implemented, primarily focusing on the lateral control of the vehicle. the validation is conducted using a dynamic simulator, involving 8 real drivers interacting with a virtual environment. the results demonstrate improved safety and user acceptance, indicating the effectiveness of the shared control strategies in comparison with no shared-control support. future work involves implementing shared control in drive-by-wire systems to enhance safety and driver comfort during critical maneuvers. overall, this research contributes to the development and validation of shared control approaches in automated driving systems.",
        "doi": "10.1109/itsc57777.2023.10422347",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04011",
        "authors": [
            "mauricio marcano",
            "joseba sarabia",
            "asier zubizarreta",
            "sergio d\u00edaz"
        ]
    },
    {
        "id": "2404.04012",
        "title": "next generation multiple access for imt towards 2030 and beyond",
        "abstract": "multiple access techniques are fundamental to the design of wireless communication systems, since many crucial components of such systems depend on the choice of the multiple access technique. because of the importance of multiple access, there has been an ongoing quest during the past decade to develop next generation multiple access (ngma). among those potential candidates for ngma, non-orthogonal multiple access (noma) has received significant attention from both the industrial and academic research communities, and has been highlighted in the recently published international mobile telecommunications (imt)-2030 framework. however, there is still no consensus in the research community about how exactly noma assisted ngma should be designed. this perspective is to outline three important features of noma assisted ngma, namely multi-domain utilization, multi-mode compatibility, and multi-dimensional optimality, where important directions for future research into the design of noma assisted ngma are also discussed.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04012",
        "authors": [
            "zhiguo ding",
            "robert schober",
            "pingzhi fan",
            "h. vincent poor"
        ]
    },
    {
        "id": "2404.04015",
        "title": "a flexible evolutionary algorithm with dynamic mutation rate archive",
        "abstract": "we propose a new, flexible approach for dynamically maintaining successful mutation rates in evolutionary algorithms using $k$-bit flip mutations. the algorithm adds successful mutation rates to an archive of promising rates that are favored in subsequent steps. rates expire when their number of unsuccessful trials has exceeded a threshold, while rates currently not present in the archive can enter it in two ways: (i) via user-defined minimum selection probabilities for rates combined with a successful step or (ii) via a stagnation detection mechanism increasing the value for a promising rate after the current bit-flip neighborhood has been explored with high probability. for the minimum selection probabilities, we suggest different options, including heavy-tailed distributions.   we conduct rigorous runtime analysis of the flexible evolutionary algorithm on the onemax and jump functions, on general unimodal functions, on minimum spanning trees, and on a class of hurdle-like functions with varying hurdle width that benefit particularly from the archive of promising mutation rates. in all cases, the runtime bounds are close to or even outperform the best known results for both stagnation detection and heavy-tailed mutations.",
        "doi": "10.1145/3638529.3654076",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04015",
        "authors": [
            "martin s. krejca",
            "carsten witt"
        ]
    },
    {
        "id": "2404.04017",
        "title": "highly efficient nurbs-based isogeometric analysis for coupled nonlinear   diffusion-reaction equations with and without advection",
        "abstract": "nonlinear diffusion-reaction systems model a multitude of physical phenomena. a common situation is biological development modeling where such systems have been widely used to study spatiotemporal phenomena in cell biology. systems of coupled diffusion-reaction equations are usually subject to some complicated features directly related to their multiphysics nature. moreover, the presence of advection is source of numerical instabilities, in general, and adds another challenge to these systems. in this study, we propose a nurbs-based isogeometric analysis (iga) combined with a second-order strang operator splitting to deal with the multiphysics nature of the problem. the advection part is treated in a semi-lagrangian framework and the resulting diffusion-reaction equations are then solved using an efficient time-stepping algorithm based on operator splitting. the accuracy of the method is studied by means of a advection-diffusion-reaction system with analytical solution. to further examine the performance of the new method on complex geometries, the well-known schnakenberg-turing problem is considered with and without advection. finally, a gray-scott system on a circular domain is also presented. the results obtained demonstrate the efficiency of our new algorithm to accurately reproduce the solution in the presence of complex patterns on complex geometries. moreover, the new method clarifies the effect of geometry on turing patterns.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04017",
        "authors": [
            "ilham asmouh",
            "alexander ostermann"
        ]
    },
    {
        "id": "2404.04018",
        "title": "superior genetic algorithms for the target set selection problem based   on power-law parameter choices and simple greedy heuristics",
        "abstract": "the target set selection problem (tss) asks for a set of vertices such that an influence spreading process started in these vertices reaches the whole graph. the current state of the art for this np-hard problem are three recently proposed randomized search heuristics, namely a biased random-key genetic algorithm (brkga) obtained from extensive parameter tuning, a max-min ant system (mmas), and a mmas using q-learning with a graph convolutional network.   we show that the brkga with two simple modifications and without the costly parameter tuning obtains significantly better results. our first modification is to simply choose all parameters of the brkga in each iteration randomly from a power-law distribution. the resulting parameterless brkga is already competitive with the tuned brkga, as our experiments on the previously used benchmarks show.   we then add a natural greedy heuristic, namely to repeatedly discard small-degree vertices that are not necessary for reaching the whole graph. the resulting algorithm consistently outperforms all of the state-of-the-art algorithms.   besides providing a superior algorithm for the tss problem, this work shows that randomized parameter choices and elementary greedy heuristics can give better results than complex algorithms and costly parameter tuning.",
        "doi": "10.1145/3638529.3654140",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04018",
        "authors": [
            "benjamin doerr",
            "martin s. krejca",
            "nguyen vu"
        ]
    },
    {
        "id": "2404.04022",
        "title": "good books are complex matters: gauging complexity profiles across   diverse categories of perceived literary quality",
        "abstract": "in this study, we employ a classification approach to show that different categories of literary \"quality\" display unique linguistic profiles, leveraging a corpus that encompasses titles from the norton anthology, penguin classics series, and the open syllabus project, contrasted against contemporary bestsellers, nobel prize winners and recipients of prestigious literary awards. our analysis reveals that canonical and so called high-brow texts exhibit distinct textual features when compared to other quality categories such as bestsellers and popular titles as well as to control groups, likely responding to distinct (but not mutually exclusive) models of quality. we apply a classic machine learning approach, namely random forest, to distinguish quality novels from \"control groups\", achieving up to 77\\% f1 scores in differentiating between the categories. we find that quality category tend to be easier to distinguish from control groups than from other quality categories, suggesting than literary quality features might be distinguishable but shared through quality proxies.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04022",
        "authors": [
            "yuri bizzoni",
            "pascale feldkamp",
            "ida marie lassen",
            "mia jacobsen",
            "mads rosendahl thomsen",
            "kristoffer nielbo"
        ]
    },
    {
        "id": "2404.04025",
        "title": "framework to generate perfusion map from ct and cta images in patients   with acute ischemic stroke: a longitudinal and cross-sectional study",
        "abstract": "stroke is a leading cause of disability and death. effective treatment decisions require early and informative vascular imaging. 4d perfusion imaging is ideal but rarely available within the first hour after stroke, whereas plain ct and cta usually are. hence, we propose a framework to extract a predicted perfusion map (ppm) derived from ct and cta images. in all eighteen patients, we found significantly high spatial similarity (with average spearman's correlation = 0.7893) between our predicted perfusion map (ppm) and the t-max map derived from 4d-ctp. voxelwise correlations between the ppm and national institutes of health stroke scale (nihss) subscores for l/r hand motor, gaze, and language on a large cohort of 2,110 subjects reliably mapped symptoms to expected infarct locations. therefore our ppm could serve as an alternative for 4d perfusion imaging, if the latter is unavailable, to investigate blood perfusion in the first hours after hospital admission.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04025",
        "authors": [
            "chayanin tangwiriyasakul",
            "pedro borges",
            "stefano moriconi",
            "paul wright",
            "yee-haur mah",
            "james teo",
            "parashkev nachev",
            "sebastien ourselin",
            "m. jorge cardoso"
        ]
    },
    {
        "id": "2404.04026",
        "title": "mm-gaussian: 3d gaussian-based multi-modal fusion for localization and   reconstruction in unbounded scenes",
        "abstract": "localization and mapping are critical tasks for various applications such as autonomous vehicles and robotics. the challenges posed by outdoor environments present particular complexities due to their unbounded characteristics. in this work, we present mm-gaussian, a lidar-camera multi-modal fusion system for localization and mapping in unbounded scenes. our approach is inspired by the recently developed 3d gaussians, which demonstrate remarkable capabilities in achieving high rendering quality and fast rendering speed. specifically, our system fully utilizes the geometric structure information provided by solid-state lidar to address the problem of inaccurate depth encountered when relying solely on visual solutions in unbounded, outdoor scenarios. additionally, we utilize 3d gaussian point clouds, with the assistance of pixel-level gradient descent, to fully exploit the color information in photos, thereby achieving realistic rendering effects. to further bolster the robustness of our system, we designed a relocalization module, which assists in returning to the correct trajectory in the event of a localization failure. experiments conducted in multiple scenarios demonstrate the effectiveness of our method.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04026",
        "authors": [
            "chenyang wu",
            "yifan duan",
            "xinran zhang",
            "yu sheng",
            "jianmin ji",
            "yanyong zhang"
        ]
    },
    {
        "id": "2404.04031",
        "title": "willkommens-merkel, chaos-johnson, and tore-klose: modeling the   evaluative meaning of german personal name compounds",
        "abstract": "we present a comprehensive computational study of the under-investigated phenomenon of personal name compounds (pncs) in german such as willkommens-merkel ('welcome-merkel'). prevalent in news, social media, and political discourse, pncs are hypothesized to exhibit an evaluative function that is reflected in a more positive or negative perception as compared to the respective personal full name (such as angela merkel). we model 321 pncs and their corresponding full names at discourse level, and show that pncs bear an evaluative nature that can be captured through a variety of computational methods. specifically, we assess through valence information whether a pnc is more positively or negatively evaluative than the person's name, by applying and comparing two approaches using (i) valence norms and (ii) pretrained language models (plms). we further enrich our data with personal, domain-specific, and extra-linguistic information and perform a range of regression analyses revealing that factors including compound and modifier valence, domain, and political party membership influence how a pnc is evaluated.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04031",
        "authors": [
            "annerose eichel",
            "tana deeg",
            "andr\u00e9 blessing",
            "milena belosevic",
            "sabine arndt-lappe",
            "sabine schulte im walde"
        ]
    },
    {
        "id": "2404.04035",
        "title": "a dataset for physical and abstract plausibility and sources of human   disagreement",
        "abstract": "we present a novel dataset for physical and abstract plausibility of events in english. based on naturally occurring sentences extracted from wikipedia, we infiltrate degrees of abstractness, and automatically generate perturbed pseudo-implausible events. we annotate a filtered and balanced subset for plausibility using crowd-sourcing, and perform extensive cleansing to ensure annotation quality. in-depth quantitative analyses indicate that annotators favor plausibility over implausibility and disagree more on implausible events. furthermore, our plausibility dataset is the first to capture abstractness in events to the same extent as concreteness, and we find that event abstractness has an impact on plausibility ratings: more concrete event participants trigger a perception of implausibility.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04035",
        "authors": [
            "annerose eichel",
            "sabine schulte im walde"
        ]
    },
    {
        "id": "2404.04036",
        "title": "which experimental design is better suited for vqa tasks? eye tracking   study on cognitive load, performance, and gaze allocations",
        "abstract": "we conducted an eye-tracking user study with 13 participants to investigate the influence of stimulus-question ordering and question modality on participants using visual question-answering (vqa) tasks. we examined cognitive load, task performance, and gaze allocations across five distinct experimental designs, aiming to identify setups that minimize the cognitive burden on participants. the collected performance and gaze data were analyzed using quantitative and qualitative methods. our results indicate a significant impact of stimulus-question ordering on cognitive load and task performance, as well as a noteworthy effect of question modality on task performance. these findings offer insights for the experimental design of controlled user studies in visualization research.",
        "doi": "10.1145/3649902.3653519",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04036",
        "authors": [
            "sita a. vriend",
            "sandeep vidyapu",
            "amer rama",
            "kun-ting chen",
            "daniel weiskopf"
        ]
    },
    {
        "id": "2404.04037",
        "title": "instructhumans: editing animated 3d human textures with instructions",
        "abstract": "we present instructhumans, a novel framework for instruction-driven 3d human texture editing. existing text-based editing methods use score distillation sampling (sds) to distill guidance from generative models. this work shows that naively using such scores is harmful to editing as they destroy consistency with the source avatar. instead, we propose an alternate sds for editing (sds-e) that selectively incorporates subterms of sds across diffusion timesteps. we further enhance sds-e with spatial smoothness regularization and gradient-based viewpoint sampling to achieve high-quality edits with sharp and high-fidelity detailing. instructhumans significantly outperforms existing 3d editing methods, consistent with the initial avatar while faithful to the textual instructions. project page: https://jyzhu.top/instruct-humans .",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04037",
        "authors": [
            "jiayin zhu",
            "linlin yang",
            "angela yao"
        ]
    },
    {
        "id": "2404.04038",
        "title": "refutability as recursive as provability",
        "abstract": "godel numbering is an arithmetization of sintax which defines provability by coding a primitive recursive predicate, pf(x,v). a multiplicity of researches and results all around this well-known recursive predicate are today widespread in many areas of logic and ai. not equally investigated is the refutability predicate defined by godel numbering within the same primitive recursive status. rf(x,v) can be defined as a recursive predicate meaning that x is the godel number of a refutation in pa of the formula with godel number v. this article proposes a logical investigation of the interactive links between provability and refutability predicates when defined within the same recursive status. the resulting lemmas are clarifying and open new perspectives for the incompleteness argument and the codings of its underlying notions.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04038",
        "authors": [
            "paola cattabriga"
        ]
    },
    {
        "id": "2404.04040",
        "title": "dynamic risk assessment methodology with an ldm-based system for parking   scenarios",
        "abstract": "this paper describes the methodology for building a dynamic risk assessment for adas (advanced driving assistance systems) algorithms in parking scenarios, fusing exterior and interior perception for a better understanding of the scene and a more comprehensive risk estimation. this includes the definition of a dynamic risk methodology that depends on the situation from inside and outside the vehicle, the creation of a multi-sensor dataset of risk assessment for adas benchmarking purposes, and a local dynamic map (ldm) that fuses data from the exterior and interior of the car to build an ldm-based dynamic risk assessment system (dras).",
        "doi": "10.1109/itsc57777.2023.10422385",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04040",
        "authors": [
            "paola natalia ca\u00f1as",
            "mikel garc\u00eda",
            "nerea aranjuelo",
            "marcos nieto",
            "aitor iglesias",
            "igor rodr\u00edguez"
        ]
    },
    {
        "id": "2404.04042",
        "title": "teaching llama a new language through cross-lingual knowledge transfer",
        "abstract": "this paper explores cost-efficient methods to adapt pretrained large language models (llms) to new lower-resource languages, with a specific focus on estonian. leveraging the llama 2 model, we investigate the impact of combining cross-lingual instruction-tuning with additional monolingual pretraining. our results demonstrate that even a relatively small amount of additional monolingual pretraining followed by cross-lingual instruction-tuning significantly enhances results on estonian. furthermore, we showcase cross-lingual knowledge transfer from high-quality english instructions to estonian, resulting in improvements in commonsense reasoning and multi-turn conversation capabilities. our best model, named \\textsc{llammas}, represents the first open-source instruction-following llm for estonian. additionally, we publish alpaca-est, the first general task instruction dataset for estonia. these contributions mark the initial progress in the direction of developing open-source llms for estonian.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04042",
        "authors": [
            "hele-andra kuulmets",
            "taido purason",
            "agnes luhtaru",
            "mark fishel"
        ]
    },
    {
        "id": "2404.04049",
        "title": "cycle life prediction for lithium-ion batteries: machine learning and   more",
        "abstract": "batteries are dynamic systems with complicated nonlinear aging, highly dependent on cell design, chemistry, manufacturing, and operational conditions. prediction of battery cycle life and estimation of aging states is important to accelerate battery r&d, testing, and to further the understanding of how batteries degrade. beyond testing, battery management systems rely on real-time models and onboard diagnostics and prognostics for safe operation. estimating the state of health and remaining useful life of a battery is important to optimize performance and use resources optimally.   this tutorial begins with an overview of first-principles, machine learning, and hybrid battery models. then, a typical pipeline for the development of interpretable machine learning models is explained and showcased for cycle life prediction from laboratory testing data. we highlight the challenges of machine learning models, motivating the incorporation of physics in hybrid modeling approaches, which are needed to decipher the aging trajectory of batteries but require more data and further work on the physics of battery degradation. the tutorial closes with a discussion on generalization and further research directions.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04049",
        "authors": [
            "joachim schaeffer",
            "giacomo galuppini",
            "jinwook rhyu",
            "patrick a. asinger",
            "robin droop",
            "rolf findeisen",
            "richard d. braatz"
        ]
    },
    {
        "id": "2404.04050",
        "title": "no time to train: empowering non-parametric networks for few-shot 3d   scene segmentation",
        "abstract": "to reduce the reliance on large-scale datasets, recent works in 3d segmentation resort to few-shot learning. current 3d few-shot segmentation methods first pre-train models on 'seen' classes, and then evaluate their generalization performance on 'unseen' classes. however, the prior pre-training stage not only introduces excessive time overhead but also incurs a significant domain gap on 'unseen' classes. to tackle these issues, we propose a non-parametric network for few-shot 3d segmentation, seg-nn, and its parametric variant, seg-pn. without training, seg-nn extracts dense representations by hand-crafted filters and achieves comparable performance to existing parametric models. due to the elimination of pre-training, seg-nn can alleviate the domain gap issue and save a substantial amount of time. based on seg-nn, seg-pn only requires training a lightweight query-support transferring (quest) module, which enhances the interaction between the support set and query set. experiments suggest that seg-pn outperforms previous state-of-the-art method by +4.19% and +7.71% miou on s3dis and scannet datasets respectively, while reducing training time by -90%, indicating its effectiveness and efficiency.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04050",
        "authors": [
            "xiangyang zhu",
            "renrui zhang",
            "bowei he",
            "ziyu guo",
            "jiaming liu",
            "han xiao",
            "chaoyou fu",
            "hao dong",
            "peng gao"
        ]
    },
    {
        "id": "2404.04054",
        "title": "constructive proofs for some semilinear pdes on   $h^2(e^{|x|^2/4},\\mathbb{r}^d)$",
        "abstract": "we develop computer-assisted tools to study semilinear equations of the form \\begin{equation*} -\\delta u -\\frac{x}{2}\\cdot \\nabla{u}= f(x,u,\\nabla u) ,\\quad x\\in\\mathbb{r}^d. \\end{equation*} such equations appear naturally in several contexts, and in particular when looking for self-similar solutions of parabolic pdes. we develop a general methodology, allowing us not only to prove the existence of solutions, but also to describe them very precisely. we introduce a spectral approach based on an eigenbasis of $\\mathcal{l}:= -\\delta -\\frac{x}{2}\\cdot \\nabla$ in spherical coordinates, together with a quadrature rule allowing to deal with nonlinearities, in order to get accurate approximate solutions. we then use a newton-kantorovich argument, in an appropriate weighted sobolev space, to prove the existence of a nearby exact solution. we apply our approach to nonlinear heat equations, to nonlinear schr\\\"odinger equations and to a generalised viscous burgers equation, and obtain both radial and non-radial self-similar profiles.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04054",
        "authors": [
            "maxime breden",
            "hugo chu"
        ]
    },
    {
        "id": "2404.04057",
        "title": "score identity distillation: exponentially fast distillation of   pretrained diffusion models for one-step generation",
        "abstract": "we introduce score identity distillation (sid), an innovative data-free method that distills the generative capabilities of pretrained diffusion models into a single-step generator. sid not only facilitates an exponentially fast reduction in fr\\'echet inception distance (fid) during distillation but also approaches or even exceeds the fid performance of the original teacher diffusion models. by reformulating forward diffusion processes as semi-implicit distributions, we leverage three score-related identities to create an innovative loss mechanism. this mechanism achieves rapid fid reduction by training the generator using its own synthesized images, eliminating the need for real data or reverse-diffusion-based generation, all accomplished within significantly shortened generation time. upon evaluation across four benchmark datasets, the sid algorithm demonstrates high iteration efficiency during distillation and surpasses competing distillation approaches, whether they are one-step or few-step, data-free, or dependent on training data, in terms of generation quality. this achievement not only redefines the benchmarks for efficiency and effectiveness in diffusion distillation but also in the broader field of diffusion-based generation. our pytorch implementation will be publicly accessible on github.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04057",
        "authors": [
            "mingyuan zhou",
            "huangjie zheng",
            "zhendong wang",
            "mingzhang yin",
            "hai huang"
        ]
    },
    {
        "id": "2404.04059",
        "title": "on the quest for effectiveness in human oversight: interdisciplinary   perspectives",
        "abstract": "human oversight is currently discussed as a potential safeguard to counter some of the negative aspects of high-risk ai applications. this prompts a critical examination of the role and conditions necessary for what is prominently termed effective or meaningful human oversight of these systems. this paper investigates effective human oversight by synthesizing insights from psychological, legal, philosophical, and technical domains. based on the claim that the main objective of human oversight is risk mitigation, we propose a viable understanding of effectiveness in human oversight: for human oversight to be effective, the human overseer has to have (a) sufficient causal power with regards to the system and its effects, (b) suitable epistemic access to relevant aspects of the situation, (c) self-control over their own actions, and (d) fitting intentions for their role. furthermore, we argue that this is equivalent to saying that a human overseer is effective if and only if they are morally responsible and have fitting intentions. against this backdrop, we suggest facilitators and inhibitors of effectiveness in human oversight when striving for practical applicability. we discuss factors in three domains, namely, the technical design of the system, individual factors of human overseers, and the environmental circumstances in which the overseer operates. finally, this paper scrutinizes the upcoming ai act of the european union -- in particular article 14 on human oversight -- as an exemplary regulatory framework in which we study the practicality of our understanding of effective human oversight. by analyzing the provisions and implications of the european ai act proposal, we pinpoint in how far that proposal aligns with our analyses regarding effective human oversight as well as how it might get enriched by our conceptual understanding of effectiveness in human oversight.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04059",
        "authors": [
            "sarah sterz",
            "kevin baum",
            "sebastian biewer",
            "holger hermanns",
            "anne lauber-r\u00f6nsberg",
            "philip meinel",
            "markus langer"
        ]
    },
    {
        "id": "2404.04062",
        "title": "derivative-free tree optimization for complex systems",
        "abstract": "a tremendous range of design tasks in materials, physics, and biology can be formulated as finding the optimum of an objective function depending on many parameters without knowing its closed-form expression or the derivative. traditional derivative-free optimization techniques often rely on strong assumptions about objective functions, thereby failing at optimizing non-convex systems beyond 100 dimensions. here, we present a tree search method for derivative-free optimization that enables accelerated optimal design of high-dimensional complex systems. specifically, we introduce stochastic tree expansion, dynamic upper confidence bound, and short-range backpropagation mechanism to evade local optimum, iteratively approximating the global optimum using machine learning models. this development effectively confronts the dimensionally challenging problems, achieving convergence to global optima across various benchmark functions up to 2,000 dimensions, surpassing the existing methods by 10- to 20-fold. our method demonstrates wide applicability to a wide range of real-world complex systems spanning materials, physics, and biology, considerably outperforming state-of-the-art algorithms. this enables efficient autonomous knowledge discovery and facilitates self-driving virtual laboratories. although we focus on problems within the realm of natural science, the advancements in optimization techniques achieved herein are applicable to a broader spectrum of challenges across all quantitative disciplines.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04062",
        "authors": [
            "ye wei",
            "bo peng",
            "ruiwen xie",
            "yangtao chen",
            "yu qin",
            "peng wen",
            "stefan bauer",
            "po-yen tung"
        ]
    },
    {
        "id": "2404.04064",
        "title": "fusing dictionary learning and support vector machines for unsupervised   anomaly detection",
        "abstract": "we study in this paper the improvement of one-class support vector machines (oc-svm) through sparse representation techniques for unsupervised anomaly detection. as dictionary learning (dl) became recently a common analysis technique that reveals hidden sparse patterns of data, our approach uses this insight to endow unsupervised detection with more control on pattern finding and dimensions. we introduce a new anomaly detection model that unifies the oc-svm and dl residual functions into a single composite objective, subsequently solved through k-svd-type iterative algorithms. a closed-form of the alternating k-svd iteration is explicitly derived for the new composite model and practical implementable schemes are discussed. the standard dl model is adapted for the dictionary pair learning (dpl) context, where the usual sparsity constraints are naturally eliminated. finally, we extend both objectives to the more general setting that allows the use of kernel functions. the empirical convergence properties of the resulting algorithms are provided and an in-depth analysis of their parametrization is performed while also demonstrating their numerical performance in comparison with existing methods.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04064",
        "authors": [
            "paul irofti",
            "iulian-andrei h\u00eeji",
            "andrei p\u0103tra\u015fcu",
            "nicolae cleju"
        ]
    },
    {
        "id": "2404.04065",
        "title": "discrete fr\\'echet distance oracles",
        "abstract": "it is unlikely that the discrete fr\\'echet distance between two curves of length $n$ can be computed in strictly subquadratic time. we thus consider the setting where one of the curves, $p$, is known in advance. in particular, we wish to construct data structures (distance oracles) of near-linear size that support efficient distance queries with respect to $p$ in sublinear time. since there is evidence that this is impossible for query curves of length $\\theta(n^\\alpha)$, for any $\\alpha > 0$, we focus on query curves of (small) constant length, for which we are able to devise distance oracles with the desired bounds.   we extend our tools to handle subcurves of the given curve, and even arbitrary vertex-to-vertex subcurves of a given geometric tree. that is, we construct an oracle that can quickly compute the distance between a short polygonal path (the query) and a path in the preprocessed tree between two query-specified vertices. moreover, we define a new family of geometric graphs, $t$-local graphs (which strictly contains the family of geometric spanners with constant stretch), for which a similar oracle exists: we can preprocess a graph $g$ in the family, so that, given a query segment and a pair $u,v$ of vertices in $g$, one can quickly compute the smallest discrete fr\\'echet distance between the segment and any $(u,v)$-path in $g$. the answer is exact, if $t=1$, and approximate if $t>1$.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04065",
        "authors": [
            "boris aronov",
            "tsuri farhana",
            "matthew j. katz",
            "indu ramesh"
        ]
    },
    {
        "id": "2404.04066",
        "title": "voicepilot: harnessing llms as speech interfaces for physically   assistive robots",
        "abstract": "physically assistive robots present an opportunity to significantly increase the well-being and independence of individuals with motor impairments or other forms of disability who are unable to complete activities of daily living. speech interfaces, especially ones that utilize large language models (llms), can enable individuals to effectively and naturally communicate high-level commands and nuanced preferences to robots. frameworks for integrating llms as interfaces to robots for high level task planning and code generation have been proposed, but fail to incorporate human-centric considerations which are essential while developing assistive interfaces. in this work, we present a framework for incorporating llms as speech interfaces for physically assistive robots, constructed iteratively with 3 stages of testing involving a feeding robot, culminating in an evaluation with 11 older adults at an independent living facility. we use both quantitative and qualitative data from the final study to validate our framework and additionally provide design guidelines for using llms as speech interfaces for assistive robots. videos and supporting files are located on our project website: https://sites.google.com/andrew.cmu.edu/voicepilot/",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04066",
        "authors": [
            "akhil padmanabha",
            "jessie yuan",
            "janavi gupta",
            "zulekha karachiwalla",
            "carmel majidi",
            "henny admoni",
            "zackory erickson"
        ]
    },
    {
        "id": "2404.04068",
        "title": "assessing the quality of information extraction",
        "abstract": "advances in large language models have notably enhanced the efficiency of information extraction from unstructured and semi-structured data sources. as these technologies become integral to various applications, establishing an objective measure for the quality of information extraction becomes imperative. however, the scarcity of labeled data presents significant challenges to this endeavor. in this paper, we introduce an automatic framework to assess the quality of the information extraction and its completeness. the framework focuses on information extraction in the form of entity and its properties. we discuss how to handle the input/output size limitations of the large language models and analyze their performance when iteratively extracting the information. finally, we introduce metrics to evaluate the quality of the extraction and provide an extensive discussion on how to interpret the metrics.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04068",
        "authors": [
            "filip seitl",
            "tom\u00e1\u0161 kov\u00e1\u0159\u00edk",
            "soheyla mirshahi",
            "jan kry\u0161t\u016ffek",
            "rastislav dujava",
            "mat\u00fa\u0161 ondrei\u010dka",
            "herbert ullrich",
            "petr gronat"
        ]
    },
    {
        "id": "2404.04069",
        "title": "bidirectional human interactive ai framework for social robot navigation",
        "abstract": "trustworthiness is a crucial concept in the context of human-robot interaction. cooperative robots must be transparent regarding their decision-making process, especially when operating in a human-oriented environment. this paper presents a comprehensive end-to-end framework aimed at fostering trustworthy bidirectional human-robot interaction in collaborative environments for the social navigation of mobile robots. our method enables a mobile robot to predict the trajectory of people and adjust its route in a socially-aware manner. in case of conflict between human and robot decisions, detected through visual examination, the route is dynamically modified based on human preference while verbal communication is maintained. we present our pipeline, framework design, and preliminary experiments that form the foundation of our proposition.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04069",
        "authors": [
            "tuba girgin",
            "emre girgin",
            "yigit yildirim",
            "emre ugur",
            "mehmet haklidir"
        ]
    },
    {
        "id": "2404.04070",
        "title": "hierarchical neural additive models for interpretable demand forecasts",
        "abstract": "demand forecasts are the crucial basis for numerous business decisions, ranging from inventory management to strategic facility planning. while machine learning (ml) approaches offer accuracy gains, their interpretability and acceptance are notoriously lacking. addressing this dilemma, we introduce hierarchical neural additive models for time series (hnam). hnam expands upon neural additive models (nam) by introducing a time-series specific additive model with a level and interacting covariate components.   covariate interactions are only allowed according to a user-specified interaction hierarchy. for example, weekday effects may be estimated independently of other covariates, whereas a holiday effect may depend on the weekday and an additional promotion may depend on both former covariates that are lower in the interaction hierarchy.   thereby, hnam yields an intuitive forecasting interface in which analysts can observe the contribution for each known covariate. we evaluate the proposed approach and benchmark its performance against other state-of-the-art machine learning and statistical models extensively on real-world retail data. the results reveal that hnam offers competitive prediction performance whilst providing plausible explanations.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04070",
        "authors": [
            "leif feddersen",
            "catherine cleophas"
        ]
    },
    {
        "id": "2404.04072",
        "title": "label propagation for zero-shot classification with vision-language   models",
        "abstract": "vision-language models (vlms) have demonstrated impressive performance on zero-shot classification, i.e. classification when provided merely with a list of class names. in this paper, we tackle the case of zero-shot classification in the presence of unlabeled data. we leverage the graph structure of the unlabeled data and introduce zlap, a method based on label propagation (lp) that utilizes geodesic distances for classification. we tailor lp to graphs containing both text and image features and further propose an efficient method for performing inductive inference based on a dual solution and a sparsification step. we perform extensive experiments to evaluate the effectiveness of our method on 14 common datasets and show that zlap outperforms the latest related works. code: https://github.com/vladan-stojnic/zlap",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04072",
        "authors": [
            "vladan stojni\u0107",
            "yannis kalantidis",
            "giorgos tolias"
        ]
    },
    {
        "id": "2404.04073",
        "title": "newton's method for nonlinear mappings into vector bundles",
        "abstract": "we consider newton's method for finding zeros of mappings from a manifold $\\mathcal{x}$ into a vector bundle $\\mathcal{e}$. in this setting a connection on $\\mathcal{e}$ is required to render the newton equation well defined, and a retraction on $\\mathcal{x}$ is needed to compute a newton update. we discuss local convergence in terms of suitable differentiability concepts, using a banach space variant of a riemannian distance. we also carry over an affine covariant damping strategy to our setting. finally, we discuss two simple applications of our approach, namely, finding fixed points of vector fields and stationary points of functionals.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04073",
        "authors": [
            "laura weigl",
            "anton schiela"
        ]
    },
    {
        "id": "2404.04079",
        "title": "self-sensing feedback control of an electrohydraulic robotic shoulder",
        "abstract": "the human shoulder, with its glenohumeral joint, tendons, ligaments, and muscles, allows for the execution of complex tasks with precision and efficiency. however, current robotic shoulder designs lack the compliance and compactness inherent in their biological counterparts. a major limitation of these designs is their reliance on external sensors like rotary encoders, which restrict mechanical joint design and introduce bulk to the system. to address this constraint, we present a bio-inspired antagonistic robotic shoulder with two degrees of freedom powered by self-sensing hydraulically amplified self-healing electrostatic actuators. our artificial muscle design decouples the high-voltage electrostatic actuation from the pair of low-voltage self-sensing electrodes. this approach allows for proprioceptive feedback control of trajectories in the task space while eliminating the necessity for any additional sensors. we assess the platform's efficacy by comparing it to a feedback control based on position data provided by a motion capture system. the study demonstrates closed-loop controllable robotic manipulators based on an inherent self-sensing capability of electrohydraulic actuators. the proposed architecture can serve as a basis for complex musculoskeletal joint arrangements.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04079",
        "authors": [
            "clemens c. christoph",
            "amirhossein kazemipour",
            "michel r. vogt",
            "yu zhang",
            "robert k. katzschmann"
        ]
    },
    {
        "id": "2404.04080",
        "title": "queue-aware network control algorithm with a high quantum computing   readiness-evaluated in discrete-time flow simulator for fat-pipe networks",
        "abstract": "the emerging technology of quantum computing has the potential to change the way how problems will be solved in the future. this work presents a centralized network control algorithm executable on already existing quantum computer which are based on the principle of quantum annealing like the d-wave advantage. we introduce a resource reoccupation algorithm for traffic engineering in wide-area networks. the proposed optimization algorithm changes traffic steering and resource allocation in case of overloaded transceivers. settings of active components like fiber amplifiers and transceivers are not changed for the reason of stability. this algorithm is beneficial in situations when the network traffic is fluctuating in time scales of seconds or spontaneous bursts occur. further, we developed a discrete-time flow simulator to study the algorithm's performance in wide-area networks. our network simulator considers backlog and loss modeling of buffered transmission lines. concurring flows are handled equally in case of a backlog.   this work provides an ilp-based network configuring algorithm that is applicable on quantum annealing computers. we showcase, that traffic losses can be reduced significantly by a factor of 2 if a resource reoccupation algorithm is applied in a network with bursty traffic. as resources are used more efficiently by reoccupation in heavy load situations, overprovisioning of networks can be reduced. thus, this new form of network operation leads toward a zero-margin network. we show that our newly introduced network simulator enables analyses of short-time effects like buffering within fat-pipe networks. as the calculation of network configurations in real-sized networks is typically time-consuming, quantum computing can enable the proposed network configuration algorithm for application in real-sized wide-area networks.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04080",
        "authors": [
            "arthur witt"
        ]
    },
    {
        "id": "2404.04087",
        "title": "field teams coordination for earthquake-damaged distribution system   energization",
        "abstract": "the re-energization of electrical distribution systems in a post-disaster scenario is of grave importance as most modern infrastructure systems rely heavily on the presence of electricity. this paper introduces a method to coordinate the field teams for the optimal energization of an electrical distribution system after an earthquake-induced blackout. the proposed method utilizes a markov decision process (mdp) to create an optimal energization strategy, which aims to minimize the expected time to energize each distribution system component. the travel duration of each team and the possible outcomes of the energization attempts are considered in the state transitions. the failure probabilities of the system components are computed using the fragility curves of structures and the peak ground acceleration (pga) values which are encoded to the mdp model via transition probabilities. furthermore, the proposed solution offers several methods to determine the non-optimal actions during the construction of the mdp and eliminate them in order to improve the run-time performance without sacrificing the optimality of the solution.",
        "doi": "10.1016/j.ress.2024.110050",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04087",
        "authors": [
            "i\u0307lker i\u015f\u0131k",
            "ebru aydin gol"
        ]
    },
    {
        "id": "2404.04089",
        "title": "a single shooting method with approximate fr\\'{e}chet derivative for   computing geodesics on the stiefel manifold",
        "abstract": "this paper shows how to use the shooting method, a classical numerical algorithm for solving boundary value problems, to compute the riemannian distance on the stiefel manifold $ \\mathrm{st}(n,p) $, the set of $ n \\times p $ matrices with orthonormal columns. the proposed method is a shooting method in the sense of the classical shooting methods for solving boundary value problems; see, e.g., stoer and bulirsch, 1991. the main feature is that we provide an approximate formula for the fr\\'{e}chet derivative of the geodesic involved in our shooting method. numerical experiments demonstrate the algorithms' accuracy and performance. comparisons with existing state-of-the-art algorithms for solving the same problem show that our method is competitive and even beats several algorithms in many cases.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04089",
        "authors": [
            "marco sutti"
        ]
    },
    {
        "id": "2404.04093",
        "title": "from stpa to safe behavior models",
        "abstract": "model checking is a proven approach for checking whether the behavior model of a safety-critical system fulfills safety properties that are stated as ltl formulas.we propose rules for generating such ltl formulas automatically based on the result of the risk analysis technique system-theoretic process analysis (stpa). additionally, we propose a synthesis of a safe behavior model from these generated ltl formulas. to also cover liveness properties in the model, we extend stpa with desired control actions. we demonstrate our approach on an example system using sccharts for the behavior model. the resulting model is not necessarily complete but provides a good foundation that already covers safety and liveness properties.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04093",
        "authors": [
            "jette petzold",
            "reinhard von hanxleden"
        ]
    },
    {
        "id": "2404.04095",
        "title": "dynamic prompt optimizing for text-to-image generation",
        "abstract": "text-to-image generative models, specifically those based on diffusion models like imagen and stable diffusion, have made substantial advancements. recently, there has been a surge of interest in the delicate refinement of text prompts. users assign weights or alter the injection time steps of certain words in the text prompts to improve the quality of generated images. however, the success of fine-control prompts depends on the accuracy of the text prompts and the careful selection of weights and time steps, which requires significant manual intervention. to address this, we introduce the \\textbf{p}rompt \\textbf{a}uto-\\textbf{e}diting (pae) method. besides refining the original prompts for image generation, we further employ an online reinforcement learning strategy to explore the weights and injection time steps of each word, leading to the dynamic fine-control prompts. the reward function during training encourages the model to consider aesthetic score, semantic consistency, and user preferences. experimental results demonstrate that our proposed method effectively improves the original prompts, generating visually more appealing images while maintaining semantic alignment. code is available at https://github.com/mowenyii/pae.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04095",
        "authors": [
            "wenyi mo",
            "tianyu zhang",
            "yalong bai",
            "bing su",
            "ji-rong wen",
            "qing yang"
        ]
    },
    {
        "id": "2404.04096",
        "title": "machine learning-aided cooperative localization under dense urban   environment",
        "abstract": "future wireless network technology provides automobiles with the connectivity feature to consolidate the concept of vehicular networks that collaborate on conducting cooperative driving tasks. the full potential of connected vehicles, which promises road safety and quality driving experience, can be leveraged if machine learning models guarantee the robustness in performing core functions including localization and controls. location awareness, in particular, lends itself to the deployment of location-specific services and the improvement of the operation performance. the localization entails direct communication to the network infrastructure, and the resulting centralized positioning solutions readily become intractable as the network scales up. as an alternative to the centralized solutions, this article addresses decentralized principle of vehicular localization reinforced by machine learning techniques in dense urban environments with frequent inaccessibility to reliable measurement. as such, the collaboration of multiple vehicles enhances the positioning performance of machine learning approaches. a virtual testbed is developed to validate this machine learning model for real-map vehicular networks. numerical results demonstrate universal feasibility of cooperative localization, in particular, for dense urban area configurations.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04096",
        "authors": [
            "hoon lee",
            "hong ki kim",
            "seung hyun oh",
            "sang hyun lee"
        ]
    },
    {
        "id": "2404.04098",
        "title": "you can use but cannot recognize: preserving visual privacy in deep   neural networks",
        "abstract": "image data have been extensively used in deep neural network (dnn) tasks in various scenarios, e.g., autonomous driving and medical image analysis, which incurs significant privacy concerns. existing privacy protection techniques are unable to efficiently protect such data. for example, differential privacy (dp) that is an emerging technique protects data with strong privacy guarantee cannot effectively protect visual features of exposed image dataset. in this paper, we propose a novel privacy-preserving framework visualmixer that protects the training data of visual dnn tasks by pixel shuffling, while not injecting any noises. visualmixer utilizes a new privacy metric called visual feature entropy (vfe) to effectively quantify the visual features of an image from both biological and machine vision aspects. in visualmixer, we devise a task-agnostic image obfuscation method to protect the visual privacy of data for dnn training and inference. for each image, it determines regions for pixel shuffling in the image and the sizes of these regions according to the desired vfe. it shuffles pixels both in the spatial domain and in the chromatic channel space in the regions without injecting noises so that it can prevent visual features from being discerned and recognized, while incurring negligible accuracy loss. extensive experiments on real-world datasets demonstrate that visualmixer can effectively preserve the visual privacy with negligible accuracy loss, i.e., at average 2.35 percentage points of model accuracy loss, and almost no performance degradation on model training.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04098",
        "authors": [
            "qiushi li",
            "yan zhang",
            "ju ren",
            "qi li",
            "yaoxue zhang"
        ]
    },
    {
        "id": "2404.04100",
        "title": "choreovis: planning and assessing formations in dance choreographies",
        "abstract": "sports visualization has developed into an active research field over the last decades. many approaches focus on analyzing movement data recorded from unstructured situations, such as soccer. for the analysis of choreographed activities like formation dancing, however, the goal differs, as dancers follow specific formations in coordinated movement trajectories. to date, little work exists on how visual analytics methods can support such choreographed performances. to fill this gap, we introduce a new visual approach for planning and assessing dance choreographies. in terms of planning choreographies, we contribute a web application with interactive authoring tools and views for the dancers' positions and orientations, movement trajectories, poses, dance floor utilization, and movement distances. for assessing dancers' real-world movement trajectories, extracted by manual bounding box annotations, we developed a timeline showing aggregated trajectory deviations and a dance floor view for detailed trajectory comparison. our approach was developed and evaluated in collaboration with dance instructors, showing that introducing visual analytics into this domain promises improvements in training efficiency for the future.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04100",
        "authors": [
            "samuel beck",
            "nina doerr",
            "kuno kurzhals",
            "alexander riedlinger",
            "fabian schmierer",
            "michael sedlmair",
            "steffen koch"
        ]
    },
    {
        "id": "2404.04101",
        "title": "generative ai in the wild: prospects, challenges, and strategies",
        "abstract": "propelled by their remarkable capabilities to generate novel and engaging content, generative artificial intelligence (genai) technologies are disrupting traditional workflows in many industries. while prior research has examined genai from a techno-centric perspective, there is still a lack of understanding about how users perceive and utilize genai in real-world scenarios. to bridge this gap, we conducted semi-structured interviews with (n=18) genai users in creative industries, investigating the human-genai co-creation process within a holistic lua (learning, using and assessing) framework. our study uncovered an intriguingly complex landscape: prospects-genai greatly fosters the co-creation between human expertise and genai capabilities, profoundly transforming creative workflows; challenges-meanwhile, users face substantial uncertainties and complexities arising from resource availability, tool usability, and regulatory compliance; strategies-in response, users actively devise various strategies to overcome many of such challenges. our study reveals key implications for the design of future genai tools.",
        "doi": "10.1145/3613904.3642160",
        "created": "2024-04-03",
        "url": "https://arxiv.org/abs/2404.04101",
        "authors": [
            "yuan sun",
            "eunchae jang",
            "fenglong ma",
            "ting wang"
        ]
    },
    {
        "id": "2404.04102",
        "title": "robust preference optimization with provable noise tolerance for llms",
        "abstract": "the preference alignment aims to enable large language models (llms) to generate responses that conform to human values, which is essential for developing general ai systems. ranking-based methods -- a promising class of alignment approaches -- learn human preferences from datasets containing response pairs by optimizing the log-likelihood margins between preferred and dis-preferred responses. however, due to the inherent differences in annotators' preferences, ranking labels of comparisons for response pairs are unavoidably noisy. this seriously hurts the reliability of existing ranking-based methods. to address this problem, we propose a provably noise-tolerant preference alignment method, namely robust preference optimization (ropo). to the best of our knowledge, ropo is the first preference alignment method with noise-tolerance guarantees. the key idea of ropo is to dynamically assign conservative gradient weights to response pairs with high label uncertainty, based on the log-likelihood margins between the responses. by effectively suppressing the gradients of noisy samples, our weighting strategy ensures that the expected risk has the same gradient direction independent of the presence and proportion of noise. experiments on three open-ended text generation tasks with four base models ranging in size from 2.8b to 13b demonstrate that ropo significantly outperforms existing ranking-based methods.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04102",
        "authors": [
            "xize liang",
            "chao chen",
            "jie wang",
            "yue wu",
            "zhihang fu",
            "zhihao shi",
            "feng wu",
            "jieping ye"
        ]
    },
    {
        "id": "2404.04103",
        "title": "improving factual accuracy of neural table-to-text output by addressing   input problems in totto",
        "abstract": "neural table-to-text models tend to hallucinate, producing texts that contain factual errors. we investigate whether such errors in the output can be traced back to problems with the input. we manually annotated 1,837 texts generated by multiple models in the politics domain of the totto dataset. we identify the input problems that are responsible for many output errors and show that fixing these inputs reduces factual errors by between 52% and 76% (depending on the model). in addition, we observe that models struggle in processing tabular inputs that are structured in a non-standard way, particularly when the input lacks distinct row and column values or when the column headers are not correctly mapped to corresponding values.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04103",
        "authors": [
            "barkavi sundararajan",
            "somayajulu sripada",
            "ehud reiter"
        ]
    },
    {
        "id": "2404.04104",
        "title": "3d facial expressions through analysis-by-neural-synthesis",
        "abstract": "while existing methods for 3d face reconstruction from in-the-wild images excel at recovering the overall face shape, they commonly miss subtle, extreme, asymmetric, or rarely observed expressions. we improve upon these methods with smirk (spatial modeling for image-based reconstruction of kinesics), which faithfully reconstructs expressive 3d faces from images. we identify two key limitations in existing methods: shortcomings in their self-supervised training formulation, and a lack of expression diversity in the training images. for training, most methods employ differentiable rendering to compare a predicted face mesh with the input image, along with a plethora of additional loss functions. this differentiable rendering loss not only has to provide supervision to optimize for 3d face geometry, camera, albedo, and lighting, which is an ill-posed optimization problem, but the domain gap between rendering and input image further hinders the learning process. instead, smirk replaces the differentiable rendering with a neural rendering module that, given the rendered predicted mesh geometry, and sparsely sampled pixels of the input image, generates a face image. as the neural rendering gets color information from sampled image pixels, supervising with neural rendering-based reconstruction loss can focus solely on the geometry. further, it enables us to generate images of the input identity with varying expressions while training. these are then utilized as input to the reconstruction model and used as supervision with ground truth geometry. this effectively augments the training data and enhances the generalization for diverse expressions. our qualitative, quantitative and particularly our perceptual evaluations demonstrate that smirk achieves the new state-of-the art performance on accurate expression reconstruction. project webpage: https://georgeretsi.github.io/smirk/.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04104",
        "authors": [
            "george retsinas",
            "panagiotis p. filntisis",
            "radek danecek",
            "victoria f. abrevaya",
            "anastasios roussos",
            "timo bolkart",
            "petros maragos"
        ]
    },
    {
        "id": "2404.04106",
        "title": "intervention-assisted policy gradient methods for online stochastic   queuing network optimization: technical report",
        "abstract": "deep reinforcement learning (drl) offers a powerful approach to training neural network control policies for stochastic queuing networks (sqn). however, traditional drl methods rely on offline simulations or static datasets, limiting their real-world application in sqn control. this work proposes online deep reinforcement learning-based controls (odrlc) as an alternative, where an intelligent agent interacts directly with a real environment and learns an optimal control policy from these online interactions. sqns present a challenge for odrlc due to the unbounded nature of the queues within the network resulting in an unbounded state-space. an unbounded state-space is particularly challenging for neural network policies as neural networks are notoriously poor at extrapolating to unseen states. to address this challenge, we propose an intervention-assisted framework that leverages strategic interventions from known stable policies to ensure the queue sizes remain bounded. this framework combines the learning power of neural networks with the guaranteed stability of classical control policies for sqns. we introduce a method to design these intervention-assisted policies to ensure strong stability of the network. furthermore, we extend foundational drl theorems for intervention-assisted policies and develop two practical algorithms specifically for odrlc of sqns. finally, we demonstrate through experiments that our proposed algorithms outperform both classical control approaches and prior odrlc algorithms.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04106",
        "authors": [
            "jerrod wigmore",
            "brooke shrader",
            "eytan modiano"
        ]
    },
    {
        "id": "2404.04108",
        "title": "large language models as oracles for instantiating ontologies with   domain-specific knowledge",
        "abstract": "background. endowing intelligent systems with semantic data commonly requires designing and instantiating ontologies with domain-specific knowledge. especially in the early phases, those activities are typically performed manually by human experts possibly leveraging on their own experience. the resulting process is therefore time-consuming, error-prone, and often biased by the personal background of the ontology designer. objective. to mitigate that issue, we propose a novel domain-independent approach to automatically instantiate ontologies with domain-specific knowledge, by leveraging on large language models (llms) as oracles. method. starting from (i) an initial schema composed by inter-related classes andproperties and (ii) a set of query templates, our method queries the llm multi- ple times, and generates instances for both classes and properties from its replies. thus, the ontology is automatically filled with domain-specific knowledge, compliant to the initial schema. as a result, the ontology is quickly and automatically enriched with manifold instances, which experts may consider to keep, adjust, discard, or complement according to their own needs and expertise. contribution. we formalise our method in general way and instantiate it over various llms, as well as on a concrete case study. we report experiments rooted in the nutritional domain where an ontology of food meals and their ingredients is semi-automatically instantiated from scratch, starting from a categorisation of meals and their relationships. there, we analyse the quality of the generated ontologies and compare ontologies attained by exploiting different llms. finally, we provide a swot analysis of the proposed method.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04108",
        "authors": [
            "giovanni ciatto",
            "andrea agiollo",
            "matteo magnini",
            "andrea omicini"
        ]
    },
    {
        "id": "2404.04111",
        "title": "the unreasonable effectiveness of early discarding after one epoch in   neural network hyperparameter optimization",
        "abstract": "to reach high performance with deep learning, hyperparameter optimization (hpo) is essential. this process is usually time-consuming due to costly evaluations of neural networks. early discarding techniques limit the resources granted to unpromising candidates by observing the empirical learning curves and canceling neural network training as soon as the lack of competitiveness of a candidate becomes evident. despite two decades of research, little is understood about the trade-off between the aggressiveness of discarding and the loss of predictive performance. our paper studies this trade-off for several commonly used discarding techniques such as successive halving and learning curve extrapolation. our surprising finding is that these commonly used techniques offer minimal to no added value compared to the simple strategy of discarding after a constant number of epochs of training. the chosen number of epochs depends mostly on the available compute budget. we call this approach i-epoch (i being the constant number of epochs with which neural networks are trained) and suggest to assess the quality of early discarding techniques by comparing how their pareto-front (in consumed training epochs and predictive performance) complement the pareto-front of i-epoch.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04111",
        "authors": [
            "romain egele",
            "felix mohr",
            "tom viering",
            "prasanna balaprakash"
        ]
    },
    {
        "id": "2404.04113",
        "title": "bear: a unified framework for evaluating relational knowledge in causal   and masked language models",
        "abstract": "knowledge probing assesses to which degree a language model (lm) has successfully learned relational knowledge during pre-training. probing is an inexpensive way to compare lms of different sizes and training configurations. however, previous approaches rely on the objective function used in pre-training lms and are thus applicable only to masked or causal lms. as a result, comparing different types of lms becomes impossible. to address this, we propose an approach that uses an lm's inherent ability to estimate the log-likelihood of any given textual statement. we carefully design an evaluation dataset of 7,731 instances (40,916 in a larger variant) from which we produce alternative statements for each relational fact, one of which is correct. we then evaluate whether an lm correctly assigns the highest log-likelihood to the correct statement. our experimental evaluation of 22 common lms shows that our proposed framework, bear, can effectively probe for knowledge across different lm types. we release the bear datasets and an open-source framework that implements the probing approach to the research community to facilitate the evaluation and development of lms.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04113",
        "authors": [
            "jacek wiland",
            "max ploner",
            "alan akbik"
        ]
    },
    {
        "id": "2404.04118",
        "title": "gnnbench: fair and productive benchmarking for single-gpu gnn system",
        "abstract": "we hypothesize that the absence of a standardized benchmark has allowed several fundamental pitfalls in gnn system design and evaluation that the community has overlooked. in this work, we propose gnnbench, a plug-and-play benchmarking platform focused on system innovation. gnnbench presents a new protocol to exchange their captive tensor data, supports custom classes in system apis, and allows automatic integration of the same system module to many deep learning frameworks, such as pytorch and tensorflow. to demonstrate the importance of such a benchmark framework, we integrated several gnn systems. our results show that integration with gnnbench helped us identify several measurement issues that deserve attention from the community.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04118",
        "authors": [
            "yidong gong",
            "pradeep kumar"
        ]
    },
    {
        "id": "2404.04120",
        "title": "cross-modality gait recognition: bridging lidar and camera modalities   for human identification",
        "abstract": "current gait recognition research mainly focuses on identifying pedestrians captured by the same type of sensor, neglecting the fact that individuals may be captured by different sensors in order to adapt to various environments. a more practical approach should involve cross-modality matching across different sensors. hence, this paper focuses on investigating the problem of cross-modality gait recognition, with the objective of accurately identifying pedestrians across diverse vision sensors. we present crossgait inspired by the feature alignment strategy, capable of cross retrieving diverse data modalities. specifically, we investigate the cross-modality recognition task by initially extracting features within each modality and subsequently aligning these features across modalities. to further enhance the cross-modality performance, we propose a prototypical modality-shared attention module that learns modality-shared features from two modality-specific features. additionally, we design a cross-modality feature adapter that transforms the learned modality-specific features into a unified feature space. extensive experiments conducted on the sustech1k dataset demonstrate the effectiveness of crossgait: (1) it exhibits promising cross-modality ability in retrieving pedestrians across various modalities from different sensors in diverse scenes, and (2) crossgait not only learns modality-shared features for cross-modality gait recognition but also maintains modality-specific features for single-modality recognition.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.04120",
        "authors": [
            "rui wang",
            "chuanfu shen",
            "manuel j. marin-jimenez",
            "george q. huang",
            "shiqi yu"
        ]
    },
    {
        "id": "2404.04123",
        "title": "designing robots to help women",
        "abstract": "robots are being designed to help people in an increasing variety of settings--but seemingly little attention has been given so far to the specific needs of women, who represent roughly half of the world's population but are highly underrepresented in robotics. here we used a speculative prototyping approach to explore this expansive design space: first, we identified some potential challenges of interest, including crimes and illnesses that disproportionately affect women, as well as potential opportunities for designers, which were visualized in five sketches. then, one of the sketched scenarios was further explored by developing a prototype, of a robotic helper drone equipped with computer vision to detect hidden cameras that could be used to spy on women. while object detection introduced some errors, hidden cameras were identified with a reasonable accuracy of 80\\% (intersection over union (iou) score: 0.40). our aim is that the identified challenges and opportunities could help spark discussion and inspire designers, toward realizing a safer, more inclusive future through responsible use of technology.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04123",
        "authors": [
            "martin cooney",
            "lena klas\u00e9n",
            "fernando alonso-fernandez"
        ]
    },
    {
        "id": "2404.04124",
        "title": "an objective improvement approach to solving discounted payoff games",
        "abstract": "while discounted payoff games and classic games that reduce to them, like parity and mean-payoff games, are symmetric, their solutions are not. we have taken a fresh view on the properties that optimal solutions need to have, and devised a novel way to converge to them, which is entirely symmetric. we achieve this by building a constraint system that uses every edge to define an inequation, and update the objective function by taking a single outgoing edge for each vertex into account. these edges loosely represent strategies of both players, where the objective function intuitively asks to make the inequation to these edges sharp, leading to an `error' or 0. for co-optimal strategies, and only for them, this can be achieved, and while we have not found them, we step-wise improve the error by improving the solution for a given objective function or by improving the objective function for a given solution. this also challenges the gospel that methods for solving payoff games are either based on strategy improvement or on value iteration.",
        "doi": "",
        "created": "2024-04-04",
        "url": "https://arxiv.org/abs/2404.04124",
        "authors": [
            "daniele dell'erba",
            "arthur dumas",
            "sven schewe"
        ]
    },
    {
        "id": "2404.04126",
        "title": "generalizable temperature nowcasting with physics-constrained rnns for   predictive maintenance of wind turbine components",
        "abstract": "machine learning plays an important role in the operation of current wind energy production systems. one central application is predictive maintenance to increase efficiency and lower electricity costs by reducing downtimes. integrating physics-based knowledge in neural networks to enforce their physical plausibilty is a promising method to improve current approaches, but incomplete system information often impedes their application in real world scenarios. we describe a simple and efficient way for physics-constrained deep learning-based predictive maintenance for wind turbine gearbox bearings with partial system knowledge. the approach is based on temperature nowcasting constrained by physics, where unknown system coefficients are treated as learnable neural network parameters. results show improved generalization performance to unseen environments compared to a baseline neural network, which is especially important in low data scenarios often encountered in real-world applications.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04126",
        "authors": [
            "johannes exenberger",
            "matteo di salvo",
            "thomas hirsch",
            "franz wotawa",
            "gerald schweiger"
        ]
    },
    {
        "id": "2404.04127",
        "title": "on the feasibility of cubesats application sandboxing for space missions",
        "abstract": "this paper details our journey in designing and selecting a suitable application sandboxing mechanism for a satellite under development, with a focus on small satellites. central to our study is the development of selection criteria for sandboxing and assessing its appropriateness for our satellite payload. we also test our approach on two already operational satellites, suchai and salsat, to validate its effectiveness. these experiments highlight the practicality and efficiency of our chosen sandboxing method for real-world space systems. our results provide insights and highlight the challenges involved in integrating application sandboxing in the space sector.",
        "doi": "10.14722/spacesec.2024.23033",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04127",
        "authors": [
            "gabriele marra",
            "ulysse planta",
            "philipp w\u00fcstenberg",
            "ali abbasi"
        ]
    },
    {
        "id": "2404.04129",
        "title": "smart contract languages: a comparative analysis",
        "abstract": "decentralized blockchain platforms support the secure exchange of assets among users without relying on trusted third parties. these exchanges are programmed with smart contracts, computer programs directly executed by blockchain nodes. multiple smart contract languages are available nowadays to developers, each with its own distinctive features, strengths, and weaknesses. in this paper, we examine the smart contract languages used in six major blockchain platforms: ethereum, solana, cardano, algorand, aptos, and tezos. starting with a high-level overview of their design choices, we provide a comprehensive assessment that focuses on programming style, security, code readability, and usability, drawing on an original benchmark that encompasses a common set of use cases across all the smart contract languages under examination.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04129",
        "authors": [
            "massimo bartoletti",
            "lorenzo benetollo",
            "michele bugliesi",
            "silvia crafa",
            "giacomo dal sasso",
            "roberto pettinau",
            "andrea pinna",
            "mattia piras",
            "sabina rossi",
            "stefano salis",
            "alvise span\u00f2",
            "viacheslav tkachenko",
            "roberto tonelli",
            "roberto zunino"
        ]
    },
    {
        "id": "2404.04130",
        "title": "a posteriori error analysis of a space-time hybridizable discontinuous   galerkin method for the advection-diffusion problem",
        "abstract": "we present and analyze an a posteriori error estimator for a space-time hybridizable discontinuous galerkin discretization of the time-dependent advection-diffusion problem. the residual-based error estimator is proven to be reliable and locally efficient. in the reliability analysis we combine a peclet-robust coercivity type result and a saturation assumption, while local efficiency analysis is based on using bubble functions. the analysis considers both local space and time adaptivity and is verified by numerical simulations on problems which include boundary and interior layers.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04130",
        "authors": [
            "yuan wang",
            "sander rhebergen"
        ]
    },
    {
        "id": "2404.04132",
        "title": "binsym: binary-level symbolic execution using formal descriptions of   instruction semantics",
        "abstract": "binsym is a framework for symbolic program analysis of software in binary form. contrary to prior work, it operates directly on binary code instructions and does not require lifting them to an intermediate representation (ir). this is achieved by formulating the symbolic semantics on top of a formal description of binary code instruction semantics. by building on existing formal descriptions, binsym eliminates the manual effort required by prior work to implement transformations to an ir, thereby reducing the margin for errors. furthermore, binsym's symbolic semantics can be directly related to the binary code, which improves symbolic execution speed by reducing solver query complexity.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04132",
        "authors": [
            "s\u00f6ren tempel",
            "tobias brandt",
            "christoph l\u00fcth",
            "rolf drechsler"
        ]
    },
    {
        "id": "2404.04139",
        "title": "precision guided approach to mitigate data poisoning attacks in   federated learning",
        "abstract": "federated learning (fl) is a collaborative learning paradigm enabling participants to collectively train a shared machine learning model while preserving the privacy of their sensitive data. nevertheless, the inherent decentralized and data-opaque characteristics of fl render its susceptibility to data poisoning attacks. these attacks introduce malformed or malicious inputs during local model training, subsequently influencing the global model and resulting in erroneous predictions. current fl defense strategies against data poisoning attacks either involve a trade-off between accuracy and robustness or necessitate the presence of a uniformly distributed root dataset at the server. to overcome these limitations, we present fedzz, which harnesses a zone-based deviating update (zbdu) mechanism to effectively counter data poisoning attacks in fl. further, we introduce a precision-guided methodology that actively characterizes these client clusters (zones), which in turn aids in recognizing and discarding malicious updates at the server. our evaluation of fedzz across two widely recognized datasets: cifar10 and emnist, demonstrate its efficacy in mitigating data poisoning attacks, surpassing the performance of prevailing state-of-the-art methodologies in both single and multi-client attack scenarios and varying attack volumes. notably, fedzz also functions as a robust client selection strategy, even in highly non-iid and attack-free scenarios. moreover, in the face of escalating poisoning rates, the model accuracy attained by fedzz displays superior resilience compared to existing techniques. for instance, when confronted with a 50% presence of malicious clients, fedzz sustains an accuracy of 67.43%, while the accuracy of the second-best solution, fl-defender, diminishes to 43.36%.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04139",
        "authors": [
            "k naveen kumar",
            "c krishna mohan",
            "aravind machiry"
        ]
    },
    {
        "id": "2404.04140",
        "title": "improving detection in aerial images by capturing inter-object   relationships",
        "abstract": "in many image domains, the spatial distribution of objects in a scene exhibits meaningful patterns governed by their semantic relationships. in most modern detection pipelines, however, the detection proposals are processed independently, overlooking the underlying relationships between objects. in this work, we introduce a transformer-based approach to capture these inter-object relationships to refine classification and regression outcomes for detected objects. building on two-stage detectors, we tokenize the region of interest (roi) proposals to be processed by a transformer encoder. specific spatial and geometric relations are incorporated into the attention weights and adaptively modulated and regularized. experimental results demonstrate that the proposed method achieves consistent performance improvement on three benchmarks including dota-v1.0, dota-v1.5, and hrsc 2016, especially ranking first on both dota-v1.5 and hrsc 2016. specifically, our new method has an increase of 1.59 map on dota-v1.0, 4.88 map on dota-v1.5, and 2.1 map on hrsc 2016, respectively, compared to the baselines.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04140",
        "authors": [
            "botao ren",
            "botian xu",
            "yifan pu",
            "jingyi wang",
            "zhidong deng"
        ]
    },
    {
        "id": "2404.04145",
        "title": "a robust approach with numerical demonstrations for the inverse   scattering problem using a carleman contraction map",
        "abstract": "this paper addresses the inverse scattering problem in the domain omega. the input data, measured outside omega, involve the waves generated by the interaction of plane waves with various directions and unknown scatterers fully occluded inside omega. the output of this problem is the spatially dielectric constant of these scatterers. our approach to solving this problem consists of two primary stages. initially, we eliminate the unknown dielectric constant from the governing equation, resulting in a system of partial differential equations. subsequently, we develop the carleman contraction mapping method to effectively tackle this system. it is noteworthy to highlight this method's robustness. it does not request a precise initial guess of the true solution, and its computational cost is not expensive. some numerical examples are presented.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04145",
        "authors": [
            "phuong m. nguyen",
            "loc h. nguyen"
        ]
    },
    {
        "id": "2404.04155",
        "title": "marsseg: mars surface semantic segmentation with multi-level extractor   and connector",
        "abstract": "the segmentation and interpretation of the martian surface play a pivotal role in mars exploration, providing essential data for the trajectory planning and obstacle avoidance of rovers. however, the complex topography, similar surface features, and the lack of extensive annotated data pose significant challenges to the high-precision semantic segmentation of the martian surface. to address these challenges, we propose a novel encoder-decoder based mars segmentation network, termed marsseg. specifically, we employ an encoder-decoder structure with a minimized number of down-sampling layers to preserve local details. to facilitate a high-level semantic understanding across the shadow multi-level feature maps, we introduce a feature enhancement connection layer situated between the encoder and decoder. this layer incorporates mini atrous spatial pyramid pooling (mini-aspp), polarized self-attention (psa), and strip pyramid pooling module (sppm). the mini-aspp and psa are specifically designed for shadow feature enhancement, thereby enabling the expression of local details and small objects. conversely, the sppm is employed for deep feature enhancement, facilitating the extraction of high-level semantic category-related information. experimental results derived from the mars-seg and ai4mars datasets substantiate that the proposed marsseg outperforms other state-of-the-art methods in segmentation performance, validating the efficacy of each proposed component.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04155",
        "authors": [
            "junbo li",
            "keyan chen",
            "gengju tian",
            "lu li",
            "zhenwei shi"
        ]
    },
    {
        "id": "2404.04156",
        "title": "torque-minimizing control allocation for overactuated quadrupedal   locomotion",
        "abstract": "in this paper, we improve upon a method for optimal control of quadrupedal robots which utilizes a full-order model of the system. the original method utilizes offline nonlinear optimal control to synthesize a control scheme which exponentially orbitally stabilizes the closed-loop system. however, it is not able to handle the overactuated phases which frequently occur during quadrupedal locomotion as a result of the multi-contact nature of the system. we propose a modified method, which handles overactuated gait phases in a way that utilizes the full range of available actuators to minimize torque expenditure without requiring output trajectories to be modified. it is shown that the system under the proposed controller exhibits the same properties, i.e. exponential orbital stability, with the same or lower point-wise torque magnitude. a simulation study demonstrates that the reduction in torque may in certain cases be substantial.",
        "doi": "10.1016/j.ifacol.2023.10.419",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04156",
        "authors": [
            "mads erlend b\u00f8e lys\u00f8",
            "esten ingar gr\u00f8tli",
            "kristin ytterstad pettersen"
        ]
    },
    {
        "id": "2404.04157",
        "title": "on the order of accuracy of finite-volume schemes on unstructured meshes",
        "abstract": "we consider finite-volume schemes for linear hyperbolic systems with constant coefficients on unstructured meshes. under the stability assumption, they exhibit the convergence rate between $p$ and $p+1$ where $p$ is the order of the truncation error. our goal is to explain this effect. the central point of our study is that the truncation error on $(p+1)$-th order polynomials has zero average over the mesh period. this condition is verified for schemes with a polynomial reconstruction, multislope finite-volume methods, 1-exact edge-based schemes, and the flux correction method. we prove that this condition is necessary and, under additional assumptions, sufficient for the $(p+1)$-th order convergence. furthermore, we apply the multislope method to a high-reynolds number flow and explain its accuracy.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04157",
        "authors": [
            "pavel bakhvalov",
            "mikhail surnachev"
        ]
    },
    {
        "id": "2404.04158",
        "title": "hardness of circuit and monotone diameters of polytopes",
        "abstract": "the circuit diameter of polytopes was introduced by borgwardt, finhold and hemmecke as a fundamental tool for the study of circuit augmentation schemes for linear programming and for estimating combinatorial diameters. determining the complexity of computing the circuit diameter of polytopes was posed as an open problem by sanit\\`a as well as by kafer, and was recently reiterated by borgwardt, grewe, kafer, lee and sanit\\`a.   in this paper, we solve this problem by showing that computing the circuit diameter of a polytope given in halfspace-description is strongly np-hard. to prove this result, we show that computing the combinatorial diameter of the perfect matching polytope of a bipartite graph is np-hard. this complements a result by sanit\\`a (focs 2018) on the np-hardness of computing the diameter of fractional matching polytopes and implies the new result that computing the diameter of a $\\{0,1\\}$-polytope is strongly np-hard, which may be of independent interest. in our second main result, we give a precise graph-theoretic description of the monotone diameter of perfect matching polytopes and use this description to prove that computing the monotone (circuit) diameter of a given input polytope is strongly np-hard as well.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04158",
        "authors": [
            "christian n\u00f6bel",
            "raphael steiner"
        ]
    },
    {
        "id": "2404.04159",
        "title": "noisy label processing for classification: a survey",
        "abstract": "in recent years, deep neural networks (dnns) have gained remarkable achievement in computer vision tasks, and the success of dnns often depends greatly on the richness of data. however, the acquisition process of data and high-quality ground truth requires a lot of manpower and money. in the long, tedious process of data annotation, annotators are prone to make mistakes, resulting in incorrect labels of images, i.e., noisy labels. the emergence of noisy labels is inevitable. moreover, since research shows that dnns can easily fit noisy labels, the existence of noisy labels will cause significant damage to the model training process. therefore, it is crucial to combat noisy labels for computer vision tasks, especially for classification tasks. in this survey, we first comprehensively review the evolution of different deep learning approaches for noisy label combating in the image classification task. in addition, we also review different noise patterns that have been proposed to design robust algorithms. furthermore, we explore the inner pattern of real-world label noise and propose an algorithm to generate a synthetic label noise pattern guided by real-world data. we test the algorithm on the well-known real-world dataset cifar-10n to form a new real-world data-guided synthetic benchmark and evaluate some typical noise-robust methods on the benchmark.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04159",
        "authors": [
            "mengting li",
            "chuang zhu"
        ]
    },
    {
        "id": "2404.04162",
        "title": "wireless resource optimization in hybrid semantic/bit communication   networks",
        "abstract": "recently, semantic communication (semcom) has shown great potential in significant resource savings and efficient information exchanges, thus naturally introducing a novel and practical cellular network paradigm where two modes of semcom and conventional bit communication (bitcom) coexist. nevertheless, the involved wireless resource management becomes rather complicated and challenging, given the unique background knowledge matching and time-consuming semantic coding requirements in semcom. to this end, this paper jointly investigates user association (ua), mode selection (ms), and bandwidth allocation (ba) problems in a hybrid semantic/bit communication network (hsb-net). concretely, we first identify a unified performance metric of message throughput for both semcom and bitcom links. next, we specially develop a knowledge matching-aware two-stage tandem packet queuing model and theoretically derive the average packet loss ratio and queuing latency. combined with practical constraints, we then formulate a joint optimization problem for ua, ms, and ba to maximize the overall message throughput of hsb-net. afterward, we propose an optimal resource management strategy by utilizing a lagrange primal-dual transformation method and a preference list-based heuristic algorithm with polynomial-time complexity. numerical results not only demonstrate the accuracy of our analytical queuing model, but also validate the performance superiority of our proposed strategy compared with different benchmarks.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04162",
        "authors": [
            "le xia",
            "yao sun",
            "dusit niyato",
            "lan zhang",
            "muhammad ali imran"
        ]
    },
    {
        "id": "2404.04163",
        "title": "dwell in the beginning: how language models embed long documents for   dense retrieval",
        "abstract": "this study investigates the existence of positional biases in transformer-based models for text representation learning, particularly in the context of web document retrieval. we build on previous research that demonstrated loss of information in the middle of input sequences for causal language models, extending it to the domain of representation learning. we examine positional biases at various stages of training for an encoder-decoder model, including language model pre-training, contrastive pre-training, and contrastive fine-tuning. experiments with the ms-marco document collection reveal that after contrastive pre-training the model already generates embeddings that better capture early contents of the input, with fine-tuning further aggravating this effect.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04163",
        "authors": [
            "jo\u00e3o coelho",
            "bruno martins",
            "jo\u00e3o magalh\u00e3es",
            "jamie callan",
            "chenyan xiong"
        ]
    },
    {
        "id": "2404.04169",
        "title": "do sentence transformers learn quasi-geospatial concepts from general   text?",
        "abstract": "sentence transformers are language models designed to perform semantic search. this study investigates the capacity of sentence transformers, fine-tuned on general question-answering datasets for asymmetric semantic search, to associate descriptions of human-generated routes across great britain with queries often used to describe hiking experiences. we find that sentence transformers have some zero-shot capabilities to understand quasi-geospatial concepts, such as route types and difficulty, suggesting their potential utility for routing recommendation systems.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04169",
        "authors": [
            "ilya ilyankou",
            "aldo lipani",
            "stefano cavazzi",
            "xiaowei gao",
            "james haworth"
        ]
    },
    {
        "id": "2404.04170",
        "title": "stability analysis of adaptive model predictive control using the circle   and tsypkin criteria",
        "abstract": "absolute stability is a technique for analyzing the stability of lur'e systems, which arise in diverse applications, such as oscillators with nonlinear damping or nonlinear stiffness. a special class of lur'e systems consists of self-excited systems (ses), in which bounded oscillations arise from constant inputs. in many cases, ses can be stabilized by linear controllers, which motivates the present work, where the goal is to evaluate the effectiveness of adaptive model predictive control for lur'e systems. in particular, the present paper considers predictive cost adaptive control (pcac), which is equivalent to a linear, time-variant (ltv) controller. a closed-loop lur'e system comprised of the positive feedback interconnection of the lur'e system and the pcac-based controller can thus be derived at each step. in this work, the circle and tsypkin criteria are used to evaluate the absolute stability of the closed-loop lur'e system, where the adaptive controller is viewed as instantaneously linear time-invariant. when the controller converges, the absolute stability criteria guarantee global asymptotic stability of the asymptotic closed-loop dynamics.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04170",
        "authors": [
            "juan a. paredes",
            "dennis s. bernstein"
        ]
    },
    {
        "id": "2404.04173",
        "title": "h3dfact: heterogeneous 3d integrated cim for factorization with   holographic perceptual representations",
        "abstract": "disentangling attributes of various sensory signals is central to human-like perception and reasoning and a critical task for higher-order cognitive and neuro-symbolic ai systems. an elegant approach to represent this intricate factorization is via high-dimensional holographic vectors drawing on brain-inspired vector symbolic architectures. however, holographic factorization involves iterative computation with high-dimensional matrix-vector multiplications and suffers from non-convergence problems.   in this paper, we present h3dfact, a heterogeneous 3d integrated in-memory compute engine capable of efficiently factorizing high-dimensional holographic representations. h3dfact exploits the computation-in-superposition capability of holographic vectors and the intrinsic stochasticity associated with memristive-based 3d compute-in-memory. evaluated on large-scale factorization and perceptual problems, h3dfact demonstrates superior capability in factorization accuracy and operational capacity by up to five orders of magnitude, with 5.5x compute density, 1.2x energy efficiency improvements, and 5.9x less silicon footprint compared to iso-capacity 2d designs.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04173",
        "authors": [
            "zishen wan",
            "che-kai liu",
            "mohamed ibrahim",
            "hanchen yang",
            "samuel spetalnick",
            "tushar krishna",
            "arijit raychowdhury"
        ]
    },
    {
        "id": "2404.04179",
        "title": "scaresnet: a resnet variant optimized for tiny object detection in   transmission and distribution towers",
        "abstract": "traditional deep learning-based object detection networks often resize images during the data preprocessing stage to achieve a uniform size and scale in the feature map. resizing is done to facilitate model propagation and fully connected classification. however, resizing inevitably leads to object deformation and loss of valuable information in the images. this drawback becomes particularly pronounced for tiny objects like distribution towers with linear shapes and few pixels. to address this issue, we propose abandoning the resizing operation. instead, we introduce positional-encoding multi-head criss-cross attention. this allows the model to capture contextual information and learn from multiple representation subspaces, effectively enriching the semantics of distribution towers. additionally, we enhance spatial pyramid pooling by reshaping three pooled feature maps into a new unified one while also reducing the computational burden. this approach allows images of different sizes and scales to generate feature maps with uniform dimensions and can be employed in feature map propagation. our scaresnet incorporates these aforementioned improvements into the backbone network resnet. we evaluated our scaresnet using the electric transmission and distribution infrastructure imagery dataset from duke university. without any additional tricks, we employed various object detection models with gaussian receptive field based label assignment as the baseline. when incorporating the scaresnet into the baseline model, we achieved a 2.1% improvement in maps. this demonstrates the advantages of our scaresnet in detecting transmission and distribution towers and its value in tiny object detection. the source code is available at https://github.com/lisavilalee/scaresnet_mmdet.",
        "doi": "10.1109/lgrs.2023.3315376",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04179",
        "authors": [
            "weile li",
            "muqing shi",
            "zhonghua hong"
        ]
    },
    {
        "id": "2404.04182",
        "title": "zak-otfs for integration of sensing and communication",
        "abstract": "the zak-otfs input/output (i/o) relation is predictable and non-fading when the delay and doppler periods are greater than the effective channel delay and doppler spreads, a condition which we refer to as the crystallization condition. the filter taps can simply be read off from the response to a single zak-otfs point (impulse) pulsone waveform, and the i/o relation can be reconstructed for a sampled system that operates under finite duration and bandwidth constraints. predictability opens up the possibility of a model-free mode of operation. the time-domain realization of a zak-otfs point pulsone is a pulse train modulated by a tone, hence the name, pulsone. the peak-to-average power ratio (papr) of a pulsone is about $15$ db, and we describe a general method for constructing a spread pulsone for which the time-domain realization has a papr of about 6db. we construct the spread pulsone by applying a type of discrete spreading filter to a zak-otfs point pulsone. the self-ambiguity function of the point pulsone is supported on the period lattice ${\\lambda}_{p}$, and by applying a discrete chirp filter, we obtain a spread pulsone with a self-ambiguity function that is supported on a rotated lattice ${\\lambda^*}$. we show that if the channel satisfies the crystallization conditions with respect to ${\\lambda^*}$ then the effective dd domain filter taps can simply be read off from the cross-ambiguity between the channel response to the spread pulsone and the transmitted spread pulsone. if, in addition, the channel satisfies the crystallization conditions with respect to the period lattice ${\\lambda}_{p}$, then in an otfs frame consisting of a spread pilot pulsone and point data pulsones, after cancelling the received signal corresponding to the spread pulsone, we can recover the channel response to any data pulsone.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04182",
        "authors": [
            "muhammad ubadah",
            "saif khan mohammed",
            "ronny hadani",
            "shachar kons",
            "ananthanarayanan chockalingam",
            "robert calderbank"
        ]
    },
    {
        "id": "2404.04183",
        "title": "racs and sadl: towards robust smr in the wide-area network",
        "abstract": "consensus algorithms deployed in the crash fault tolerant setting chose a leader-based architecture in order to achieve the lowest latency possible. however, when deployed in the wide area they face two key robustness challenges. first, they lose liveness when the network is unreliable because they rely on timeouts to find a leader. second, they cannot have a high replication factor because of the high load imposed on the leader-replica making it a bottleneck. this effectively limits the replication factor allowed, for a given level of throughput, thus lowering the fault tolerance threshold.   in this paper, we propose racs and sadl, a modular state machine replication algorithm that addresses these two robustness challenges. to achieve robustness under adversarial network conditions, we propose racs, a novel crash fault-tolerant consensus algorithm. racs consists of two modes of operations: synchronous and asynchronous, that always ensure liveness. racs leverages the synchronous network to minimize the communication cost to o(n) and matches the lower bound of o(n2) at adversarial-case executions. to avoid the leader bottleneck and to allow higher replication factor, without sacrificing the throughput, we then propose sadl, a novel consensus-agnostic asynchronous dissemination layer. sadl separates client command dissemination from the critical path of consensus and distributes the overhead evenly among all the replicas. the combination of racs and sadl (sadl-racs) provides a robust and high-performing state machine replication system. we implement and evaluate racs and sadl-racs in a wide-area deployment running on amazon ec2.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04183",
        "authors": [
            "pasindu tennage",
            "antoine desjardins",
            "lefteris kokoris-kogias"
        ]
    },
    {
        "id": "2404.04186",
        "title": "probabilistically informed robot object search with multiple regions",
        "abstract": "the increasing use of autonomous robot systems in hazardous environments underscores the need for efficient search and rescue operations. despite significant advancements, existing literature on object search often falls short in overcoming the difficulty of long planning horizons and dealing with sensor limitations, such as noise. this study introduces a novel approach that formulates the search problem as a belief markov decision processes with options (bmdp-o) to make monte carlo tree search (mcts) a viable tool for overcoming these challenges in large scale environments. the proposed formulation incorporates sequences of actions (options) to move between regions of interest, enabling the algorithm to efficiently scale to large environments. this approach also enables the use of customizable fields of view, for use with multiple types of sensors. experimental results demonstrate the superiority of this approach in large environments when compared to the problem without options and alternative tools such as receding horizon planners. given compute time for the proposed formulation is relatively high, a further approximated \"lite\" formulation is proposed. the lite formulation finds objects in a comparable number of steps with faster computation.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04186",
        "authors": [
            "matthew collins",
            "jared j. beard",
            "nicholas ohi",
            "yu gu"
        ]
    },
    {
        "id": "2404.04188",
        "title": "reliable feature selection for adversarially robust cyber-attack   detection",
        "abstract": "the growing cybersecurity threats make it essential to use high-quality data to train machine learning (ml) models for network traffic analysis, without noisy or missing data. by selecting the most relevant features for cyber-attack detection, it is possible to improve both the robustness and computational efficiency of the models used in a cybersecurity system. this work presents a feature selection and consensus process that combines multiple methods and applies them to several network datasets. two different feature sets were selected and were used to train multiple ml models with regular and adversarial training. finally, an adversarial evasion robustness benchmark was performed to analyze the reliability of the different feature sets and their impact on the susceptibility of the models to adversarial examples. by using an improved dataset with more data diversity, selecting the best time-related features and a more specific feature set, and performing adversarial training, the ml models were able to achieve a better adversarially robust generalization. the robustness of the models was significantly improved without their generalization to regular traffic flows being affected, without increases of false alarms, and without requiring too many computational resources, which enables a reliable detection of suspicious activity and perturbed traffic flows in enterprise computer networks.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04188",
        "authors": [
            "jo\u00e3o vitorino",
            "miguel silva",
            "eva maia",
            "isabel pra\u00e7a"
        ]
    },
    {
        "id": "2404.04189",
        "title": "are we up to the challenge? an analysis of the fcc broadband data   collection fixed internet availability challenges",
        "abstract": "in 2021, the broadband equity, access, and deployment (bead) program allocated $42.45 billion to enhance high-speed internet access across the united states. as part of this funding initiative, the federal communications commission (fcc) developed a national coverage map to guide the allocation of bead funds. this map was the key determinant to direct bead investments to areas in need of broadband infrastructure improvements. the fcc encouraged public participation in refining this coverage map through the submission of \"challenges\" to either locations on the map or the status of broadband at any location on the map. these challenges allowed citizens and organizations to report discrepancies between the map's data and actual broadband availability, ensuring a more equitable distribution of funds. in this paper, we present a study analyzing the nature and distribution of these challenges across different access technologies and geographic areas. among several other insights, we observe, for example, that the majority of challenges (about 58%) were submitted against terrestrial fixed wireless technologies as well as that the state of nebraska had the strongest engagement in the challenge process with more than 75% of its broadband-serviceable locations having submitted at least one challenge.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04189",
        "authors": [
            "jonatas marques",
            "alexis schrubbe",
            "nicole p. marwell",
            "nick feamster"
        ]
    },
    {
        "id": "2404.04193",
        "title": "tooleenet: tool affordance 6d pose estimation",
        "abstract": "the exploration of robotic dexterous hands utilizing tools has recently attracted considerable attention. a significant challenge in this field is the precise awareness of a tool's pose when grasped, as occlusion by the hand often degrades the quality of the estimation. additionally, the tool's overall pose often fails to accurately represent the contact interaction, thereby limiting the effectiveness of vision-guided, contact-dependent activities. to overcome this limitation, we present the innovative toolee dataset, which, to the best of our knowledge, is the first to feature affordance segmentation of a tool's end-effector (ee) along with its defined 6d pose based on its usage. furthermore, we propose the tooleenet framework for accurate 6d pose estimation of the tool's ee. this framework begins by segmenting the tool's ee from raw rgbd data, then uses a diffusion model-based pose estimator for 6d pose estimation at a category-specific level. addressing the issue of symmetry in pose estimation, we introduce a symmetry-aware pose representation that enhances the consistency of pose estimation. our approach excels in this field, demonstrating high levels of precision and generalization. furthermore, it shows great promise for application in contact-based manipulation scenarios. all data and codes are available on the project website: https://yuyangtu.github.io/projecttooleenet.html",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04193",
        "authors": [
            "yunlong wang",
            "lei zhang",
            "yuyang tu",
            "hui zhang",
            "kaixin bai",
            "zhaopeng chen",
            "jianwei zhang"
        ]
    },
    {
        "id": "2404.04194",
        "title": "a newton method for solving locally definite multiparameter eigenvalue   problems by multiindex",
        "abstract": "we present a new approach to compute eigenvalues and eigenvectors of locally definite multiparameter eigenvalue problems by its signed multiindex. the method has the interpretation of a semismooth newton method applied to certain functions that have a unique zero. we can therefore show local quadratic convergence, and for certain extreme eigenvalues even global linear convergence of the method. local definiteness is a weaker condition than right and left definiteness, which is often considered for multiparameter eigenvalue problems. these conditions are naturally satisfied for multiparameter sturm-liouville problems that arise when separation of variables can be applied to multidimensional boundary eigenvalue problems.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04194",
        "authors": [
            "henrik eisenmann"
        ]
    },
    {
        "id": "2404.04197",
        "title": "convex mpc and thrust allocation with deadband for spacecraft rendezvous",
        "abstract": "this paper delves into a rendezvous scenario involving a chaser and a target spacecraft, focusing on the application of model predictive control (mpc) to design a controller capable of guiding the chaser toward the target. the operational principle of spacecraft thrusters, requiring a minimum activation time that leads to the existence of a control deadband, introduces mixed-integer constraints into the optimization, posing a considerable computational challenge due to the exponential complexity on the number of integer constraints. we address this complexity by presenting two solver algorithms that efficiently approximate the optimal solution in significantly less time than standard solvers, making them well-suited for real-time applications.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04197",
        "authors": [
            "pedro taborda",
            "hugo matias",
            "daniel silvestre",
            "pedro louren\u00e7o"
        ]
    },
    {
        "id": "2404.04199",
        "title": "exploring probabilistic models for semi-supervised learning",
        "abstract": "this thesis studies advanced probabilistic models, including both their theoretical foundations and practical applications, for different semi-supervised learning (ssl) tasks. the proposed probabilistic methods are able to improve the safety of ai systems in real applications by providing reliable uncertainty estimates quickly, and at the same time, achieve competitive performance compared to their deterministic counterparts. the experimental results indicate that the methods proposed in the thesis have great value in safety-critical areas, such as the autonomous driving or medical imaging analysis domain, and pave the way for the future discovery of highly effective and efficient probabilistic approaches in the ssl sector.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04199",
        "authors": [
            "jianfeng wang"
        ]
    },
    {
        "id": "2404.04201",
        "title": "v-star: learning visibly pushdown grammars from program inputs",
        "abstract": "accurate description of program inputs remains a critical challenge in the field of programming languages. active learning, as a well-established field, achieves exact learning for regular languages. we offer an innovative grammar inference tool, v-star, based on the active learning of visibly pushdown automata. v-star deduces nesting structures of program input languages from sample inputs, employing a novel inference mechanism based on nested patterns. this mechanism identifies token boundaries and converts languages such as xml documents into vpls. we then adapted angluin's l-star, an exact learning algorithm, for vpa learning, which improves the precision of our tool. our evaluation demonstrates that v-star effectively and efficiently learns a variety of practical grammars, including s-expressions, json, and xml, and outperforms other state-of-the-art tools.",
        "doi": "10.1145/3656458",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04201",
        "authors": [
            "xiaodong jia",
            "gang tan"
        ]
    },
    {
        "id": "2404.04202",
        "title": "deep-learning segmentation of small volumes in ct images for   radiotherapy treatment planning",
        "abstract": "our understanding of organs at risk is progressing to include physical small tissues such as coronary arteries and the radiosensitivities of many small organs and tissues are high. therefore, the accurate segmentation of small volumes in external radiotherapy is crucial to protect them from over-irradiation. moreover, with the development of the particle therapy and on-board imaging, the treatment becomes more accurate and precise. the purpose of this work is to optimize organ segmentation algorithms for small organs. we used 50 three-dimensional (3-d) computed tomography (ct) head and neck images from structseg2019 challenge to develop a general-purpose v-net model to segment 20 organs in the head and neck region. we applied specific strategies to improve the segmentation accuracy of the small volumes in this anatomical region, i.e., the lens of the eye. then, we used 17 additional head images from osf healthcare to validate the robustness of the v net model optimized for small-volume segmentation. with the study of the structseg2019 images, we found that the optimization of the image normalization range and classification threshold yielded a segmentation improvement of the lens of the eye of approximately 50%, compared to the use of the v-net not optimized for small volumes. we used the optimized model to segment 17 images acquired using heterogeneous protocols. we obtained comparable dice coefficient values for the clinical and structseg2019 images (0.61 plus/minus 0.07 and 0.58 plus/minus 0.10 for the left and right lens of the eye, respectively)",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04202",
        "authors": [
            "jianxin zhou",
            "kadishe fejza",
            "massimiliano salvatori",
            "daniele della latta",
            "gregory m. hermann",
            "angela di fulvio"
        ]
    },
    {
        "id": "2404.04204",
        "title": "social skill training with large language models",
        "abstract": "people rely on social skills like conflict resolution to communicate effectively and to thrive in both work and personal life. however, practice environments for social skills are typically out of reach for most people. how can we make social skill training more available, accessible, and inviting? drawing upon interdisciplinary research from communication and psychology, this perspective paper identifies social skill barriers to enter specialized fields. then we present a solution that leverages large language models for social skill training via a generic framework. our ai partner, ai mentor framework merges experiential learning with realistic practice and tailored feedback. this work ultimately calls for cross-disciplinary innovation to address the broader implications for workforce development and social equality.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04204",
        "authors": [
            "diyi yang",
            "caleb ziems",
            "william held",
            "omar shaikh",
            "michael s. bernstein",
            "john mitchell"
        ]
    },
    {
        "id": "2404.04205",
        "title": "enhancing iot intelligence: a transformer-based reinforcement learning   methodology",
        "abstract": "the proliferation of the internet of things (iot) has led to an explosion of data generated by interconnected devices, presenting both opportunities and challenges for intelligent decision-making in complex environments. traditional reinforcement learning (rl) approaches often struggle to fully harness this data due to their limited ability to process and interpret the intricate patterns and dependencies inherent in iot applications. this paper introduces a novel framework that integrates transformer architectures with proximal policy optimization (ppo) to address these challenges. by leveraging the self-attention mechanism of transformers, our approach enhances rl agents' capacity for understanding and acting within dynamic iot environments, leading to improved decision-making processes. we demonstrate the effectiveness of our method across various iot scenarios, from smart home automation to industrial control systems, showing marked improvements in decision-making efficiency and adaptability. our contributions include a detailed exploration of the transformer's role in processing heterogeneous iot data, a comprehensive evaluation of the framework's performance in diverse environments, and a benchmark against traditional rl methods. the results indicate significant advancements in enabling rl agents to navigate the complexities of iot ecosystems, highlighting the potential of our approach to revolutionize intelligent automation and decision-making in the iot landscape.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04205",
        "authors": [
            "gaith rjoub",
            "saidul islam",
            "jamal bentahar",
            "mohammed amin almaiah",
            "rana alrawashdeh"
        ]
    },
    {
        "id": "2404.04211",
        "title": "robust gaussian splatting",
        "abstract": "in this paper, we address common error sources for 3d gaussian splatting (3dgs) including blur, imperfect camera poses, and color inconsistencies, with the goal of improving its robustness for practical applications like reconstructions from handheld phone captures. our main contribution involves modeling motion blur as a gaussian distribution over camera poses, allowing us to address both camera pose refinement and motion blur correction in a unified way. additionally, we propose mechanisms for defocus blur compensation and for addressing color in-consistencies caused by ambient light, shadows, or due to camera-related factors like varying white balancing settings. our proposed solutions integrate in a seamless way with the 3dgs formulation while maintaining its benefits in terms of training efficiency and rendering speed. we experimentally validate our contributions on relevant benchmark datasets including scannet++ and deblur-nerf, obtaining state-of-the-art results and thus consistent improvements over relevant baselines.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04211",
        "authors": [
            "fran\u00e7ois darmon",
            "lorenzo porzi",
            "samuel rota-bul\u00f2",
            "peter kontschieder"
        ]
    },
    {
        "id": "2404.04212",
        "title": "unlocking parameter-efficient fine-tuning for low-resource language   translation",
        "abstract": "parameter-efficient fine-tuning (peft) methods are increasingly vital in adapting large-scale pre-trained language models for diverse tasks, offering a balance between adaptability and computational efficiency. they are important in low-resource language (lrl) neural machine translation (nmt) to enhance translation accuracy with minimal resources. however, their practical effectiveness varies significantly across different languages. we conducted comprehensive empirical experiments with varying lrl domains and sizes to evaluate the performance of 8 peft methods with in total of 15 architectures using the sacrebleu score. we showed that 6 peft architectures outperform the baseline for both in-domain and out-domain tests and the houlsby+inversion adapter has the best performance overall, proving the effectiveness of peft methods.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04212",
        "authors": [
            "tong su",
            "xin peng",
            "sarubi thillainathan",
            "david guzm\u00e1n",
            "surangika ranathunga",
            "en-shiun annie lee"
        ]
    },
    {
        "id": "2404.04218",
        "title": "simplifying explicit subtyping coercions in a polymorphic calculus with   effects",
        "abstract": "algebraic effect handlers are becoming increasingly popular way of structuring and reasoning about effectful computations, and their performance is often a concern. one of the proposed approaches towards efficient compilation is tracking effect information through explicit subtyping coercions. however, in the presence of polymorphism, these coercions are compiled to additional arguments of compiled functions, incurring significant overhead.   in this paper, we present a polymorphic effectful calculus, identify simplification phases needed to reduce the number of unnecessary constraints, and prove they preserve the semantics. in addition, we implement the simplification algorithm in the eff language, and evaluate its performance on a number of benchmarks. though we do not prove optimality of presented simplifications, the results show that the algorithm eliminates all the coercions, resulting in a code as efficient as manually monomorphised one.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04218",
        "authors": [
            "filip koprivec",
            "matija pretnar"
        ]
    },
    {
        "id": "2404.04219",
        "title": "continual policy distillation of reinforcement learning-based   controllers for soft robotic in-hand manipulation",
        "abstract": "dexterous manipulation, often facilitated by multi-fingered robotic hands, holds solid impact for real-world applications. soft robotic hands, due to their compliant nature, offer flexibility and adaptability during object grasping and manipulation. yet, benefits come with challenges, particularly in the control development for finger coordination. reinforcement learning (rl) can be employed to train object-specific in-hand manipulation policies, but limiting adaptability and generalizability. we introduce a continual policy distillation (cpd) framework to acquire a versatile controller for in-hand manipulation, to rotate different objects in shape and size within a four-fingered soft gripper. the framework leverages policy distillation (pd) to transfer knowledge from expert policies to a continually evolving student policy network. exemplar-based rehearsal methods are then integrated to mitigate catastrophic forgetting and enhance generalization. the performance of the cpd framework over various replay strategies demonstrates its effectiveness in consolidating knowledge from multiple experts and achieving versatile and adaptive behaviours for in-hand manipulation tasks.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04219",
        "authors": [
            "lanpei li",
            "enrico donato",
            "vincenzo lomonaco",
            "egidio falotico"
        ]
    },
    {
        "id": "2404.04220",
        "title": "multi-modal perception for soft robotic interactions using generative   models",
        "abstract": "perception is essential for the active interaction of physical agents with the external environment. the integration of multiple sensory modalities, such as touch and vision, enhances this perceptual process, creating a more comprehensive and robust understanding of the world. such fusion is particularly useful for highly deformable bodies such as soft robots. developing a compact, yet comprehensive state representation from multi-sensory inputs can pave the way for the development of complex control strategies. this paper introduces a perception model that harmonizes data from diverse modalities to build a holistic state representation and assimilate essential information. the model relies on the causality between sensory input and robotic actions, employing a generative model to efficiently compress fused information and predict the next observation. we present, for the first time, a study on how touch can be predicted from vision and proprioception on soft robots, the importance of the cross-modal generation and why this is essential for soft robotic interactions in unstructured environments.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04220",
        "authors": [
            "enrico donato",
            "egidio falotico",
            "thomas george thuruthel"
        ]
    },
    {
        "id": "2404.04221",
        "title": "how lexical is bilingual lexicon induction?",
        "abstract": "in contemporary machine learning approaches to bilingual lexicon induction (bli), a model learns a mapping between the embedding spaces of a language pair. recently, retrieve-and-rank approach to bli has achieved state of the art results on the task. however, the problem remains challenging in low-resource settings, due to the paucity of data. the task is complicated by factors such as lexical variation across languages. we argue that the incorporation of additional lexical information into the recent retrieve-and-rank approach should improve lexicon induction. we demonstrate the efficacy of our proposed approach on xling, improving over the previous state of the art by an average of 2\\% across all language pairs.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04221",
        "authors": [
            "harsh kohli",
            "helian feng",
            "nicholas dronen",
            "calvin mccarter",
            "sina moeini",
            "ali kebarighotbi"
        ]
    },
    {
        "id": "2404.04224",
        "title": "active causal learning for decoding chemical complexities with targeted   interventions",
        "abstract": "predicting and enhancing inherent properties based on molecular structures is paramount to design tasks in medicine, materials science, and environmental management. most of the current machine learning and deep learning approaches have become standard for predictions, but they face challenges when applied across different datasets due to reliance on correlations between molecular representation and target properties. these approaches typically depend on large datasets to capture the diversity within the chemical space, facilitating a more accurate approximation, interpolation, or extrapolation of the chemical behavior of molecules. in our research, we introduce an active learning approach that discerns underlying cause-effect relationships through strategic sampling with the use of a graph loss function. this method identifies the smallest subset of the dataset capable of encoding the most information representative of a much larger chemical space. the identified causal relations are then leveraged to conduct systematic interventions, optimizing the design task within a chemical space that the models have not encountered previously. while our implementation focused on the qm9 quantum-chemical dataset for a specific design task-finding molecules with a large dipole moment-our active causal learning approach, driven by intelligent sampling and interventions, holds potential for broader applications in molecular, materials design and discovery.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04224",
        "authors": [
            "zachary r. fox",
            "ayana ghosh"
        ]
    },
    {
        "id": "2404.04225",
        "title": "twins in rotational spectroscopy: does a rotational spectrum uniquely   identify a molecule?",
        "abstract": "rotational spectroscopy is the most accurate method for determining structures of molecules in the gas phase. it is often assumed that a rotational spectrum is a unique \"fingerprint\" of a molecule. the availability of large molecular databases and the development of artificial intelligence methods for spectroscopy makes the testing of this assumption timely. in this paper, we pose the determination of molecular structures from rotational spectra as an inverse problem. within this framework, we adopt a funnel-based approach to search for molecular twins, which are two or more molecules, which have similar rotational spectra but distinctly different molecular structures. we demonstrate that there are twins within standard levels of computational accuracy by generating rotational constants for many molecules from several large molecular databases, indicating the inverse problem is ill-posed. however, some twins can be distinguished by increasing the accuracy of the theoretical methods or by performing additional experiments.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04225",
        "authors": [
            "marcus schwarting",
            "nathan a. seifert",
            "michael j. davis",
            "ben blaiszik",
            "ian foster",
            "kirill prozument"
        ]
    },
    {
        "id": "2404.04231",
        "title": "image-text co-decomposition for text-supervised semantic segmentation",
        "abstract": "this paper addresses text-supervised semantic segmentation, aiming to learn a model capable of segmenting arbitrary visual concepts within images by using only image-text pairs without dense annotations. existing methods have demonstrated that contrastive learning on image-text pairs effectively aligns visual segments with the meanings of texts. we notice that there is a discrepancy between text alignment and semantic segmentation: a text often consists of multiple semantic concepts, whereas semantic segmentation strives to create semantically homogeneous segments. to address this issue, we propose a novel framework, image-text co-decomposition (code), where the paired image and text are jointly decomposed into a set of image regions and a set of word segments, respectively, and contrastive learning is developed to enforce region-word alignment. to work with a vision-language model, we present a prompt learning mechanism that derives an extra representation to highlight an image segment or a word segment of interest, with which more effective features can be extracted from that segment. comprehensive experimental results demonstrate that our method performs favorably against existing text-supervised semantic segmentation methods on six benchmark datasets.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04231",
        "authors": [
            "ji-jia wu",
            "andy chia-hao chang",
            "chieh-yu chuang",
            "chun-pei chen",
            "yu-lun liu",
            "min-hung chen",
            "hou-ning hu",
            "yung-yu chuang",
            "yen-yu lin"
        ]
    },
    {
        "id": "2404.04232",
        "title": "benchmarking and improving compositional generalization of multi-aspect   controllable text generation",
        "abstract": "compositional generalization, representing the model's ability to generate text with new attribute combinations obtained by recombining single attributes from the training data, is a crucial property for multi-aspect controllable text generation (mctg) methods. nonetheless, a comprehensive compositional generalization evaluation benchmark of mctg is still lacking. we propose compmctg, a benchmark encompassing diverse multi-aspect labeled datasets and a crafted three-dimensional evaluation protocol, to holistically evaluate the compositional generalization of mctg approaches. we observe that existing mctg works generally confront a noticeable performance drop in compositional testing. to mitigate this issue, we introduce meta-mctg, a training framework incorporating meta-learning, where we enable models to learn how to generalize by simulating compositional generalization scenarios in the training phase. we demonstrate the effectiveness of meta-mctg through achieving obvious improvement (by at most 3.64%) for compositional testing performance in 94.4% cases.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04232",
        "authors": [
            "tianqi zhong",
            "zhaoyi li",
            "quan wang",
            "linqi song",
            "ying wei",
            "defu lian",
            "zhendong mao"
        ]
    },
    {
        "id": "2404.04237",
        "title": "cleared for takeoff? compositional & conditional reasoning may be the   achilles heel to (flight-booking) language agents",
        "abstract": "the rapid progress of large language models (llms) has seen them excel and frequently surpass human performance on standard benchmarks. this has enabled many downstream applications, such as llm agents, to rely on their sophisticated reasoning to navigate complex task requirements. however, llms are known to unexpectedly falter in simple tasks and under seemingly straightforward circumstances - underscoring the need for better and more diverse evaluation setups to measure their true capabilities. to this end, we choose to study compositional and conditional reasoning, two cornerstones of human cognition, and introduce groundcocoa - a lexically diverse benchmark connecting these reasoning skills to the real-world problem of flight booking. our task involves aligning detailed user preferences with available flight options presented in a multiple-choice format. results indicate a significant disparity in performance among current state-of-the-art llms with even the best performing model, gpt-4 turbo, not exceeding 67% accuracy despite advanced prompting techniques.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04237",
        "authors": [
            "harsh kohli",
            "huan sun"
        ]
    },
    {
        "id": "2404.04240",
        "title": "dynamic conditional optimal transport through simulation-free flows",
        "abstract": "we study the geometry of conditional optimal transport (cot) and prove a dynamical formulation which generalizes the benamou-brenier theorem. with these tools, we propose a simulation-free flow-based method for conditional generative modeling. our method couples an arbitrary source distribution to a specified target distribution through a triangular cot plan. we build on the framework of flow matching to train a conditional generative model by approximating the geodesic path of measures induced by this cot plan. our theory and methods are applicable in the infinite-dimensional setting, making them well suited for inverse problems. empirically, we demonstrate our proposed method on two image-to-image translation tasks and an infinite-dimensional bayesian inverse problem.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04240",
        "authors": [
            "gavin kerrigan",
            "giosue migliorini",
            "padhraic smyth"
        ]
    },
    {
        "id": "2404.04241",
        "title": "modeling kinematic uncertainty of tendon-driven continuum robots via   mixture density networks",
        "abstract": "tendon-driven continuum robot kinematic models are frequently computationally expensive, inaccurate due to unmodeled effects, or both. in particular, unmodeled effects produce uncertainties that arise during the robot's operation that lead to variability in the resulting geometry. we propose a novel solution to these issues through the development of a gaussian mixture kinematic model. we train a mixture density network to output a gaussian mixture model representation of the robot geometry given the current tendon displacements. this model computes a probability distribution that is more representative of the true distribution of geometries at a given configuration than a model that outputs a single geometry, while also reducing the computation time. we demonstrate one use of this model through a trajectory optimization method that explicitly reasons about the workspace uncertainty to minimize the probability of collision.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04241",
        "authors": [
            "jordan thompson",
            "brian y. cho",
            "daniel s. brown",
            "alan kuntz"
        ]
    },
    {
        "id": "2404.04242",
        "title": "physical property understanding from language-embedded feature fields",
        "abstract": "can computers perceive the physical properties of objects solely through vision? research in cognitive science and vision science has shown that humans excel at identifying materials and estimating their physical properties based purely on visual appearance. in this paper, we present a novel approach for dense prediction of the physical properties of objects using a collection of images. inspired by how humans reason about physics through vision, we leverage large language models to propose candidate materials for each object. we then construct a language-embedded point cloud and estimate the physical properties of each 3d point using a zero-shot kernel regression approach. our method is accurate, annotation-free, and applicable to any object in the open world. experiments demonstrate the effectiveness of the proposed approach in various physical property reasoning tasks, such as estimating the mass of common objects, as well as other properties like friction and hardness.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04242",
        "authors": [
            "albert j. zhai",
            "yuan shen",
            "emily y. chen",
            "gloria x. wang",
            "xinlei wang",
            "sheng wang",
            "kaiyu guan",
            "shenlong wang"
        ]
    },
    {
        "id": "2404.04243",
        "title": "identity decoupling for multi-subject personalization of text-to-image   models",
        "abstract": "text-to-image diffusion models have shown remarkable success in generating a personalized subject based on a few reference images. however, current methods struggle with handling multiple subjects simultaneously, often resulting in mixed identities with combined attributes from different subjects. in this work, we present mudi, a novel framework that enables multi-subject personalization by effectively decoupling identities from multiple subjects. our main idea is to utilize segmented subjects generated by the segment anything model for both training and inference, as a form of data augmentation for training and initialization for the generation process. our experiments demonstrate that mudi can produce high-quality personalized images without identity mixing, even for highly similar subjects as shown in figure 1. in human evaluation, mudi shows twice as many successes for personalizing multiple subjects without identity mixing over existing baselines and is preferred over 70% compared to the strongest baseline. more results are available at https://mudi-t2i.github.io/.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04243",
        "authors": [
            "sangwon jang",
            "jaehyeong jo",
            "kimin lee",
            "sung ju hwang"
        ]
    },
    {
        "id": "2404.04244",
        "title": "diffop-net: a differential operator-based fully convolutional network   for unsupervised deformable image registration",
        "abstract": "existing unsupervised deformable image registration methods usually rely on metrics applied to the gradients of predicted displacement or velocity fields as a regularization term to ensure transformation smoothness, which potentially limits registration accuracy. in this study, we propose a novel approach to enhance unsupervised deformable image registration by introducing a new differential operator into the registration framework. this operator, acting on the velocity field and mapping it to a dual space, ensures the smoothness of the velocity field during optimization, facilitating accurate deformable registration. in addition, to tackle the challenge of capturing large deformations inside image pairs, we introduce a cross-coordinate attention module (cca) and embed it into a proposed fully convolutional networks (fcns)-based multi-resolution registration architecture. evaluation experiments are conducted on two magnetic resonance imaging (mri) datasets. compared to various state-of-the-art registration approaches, including a traditional algorithm and three representative unsupervised learning-based methods, our method achieves superior accuracies, maintaining desirable diffeomorphic properties, and exhibiting promising registration speed.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04244",
        "authors": [
            "jiong wu"
        ]
    },
    {
        "id": "2404.04245",
        "title": "evaluating adversarial robustness: a comparison of fgsm, carlini-wagner   attacks, and the role of distillation as defense mechanism",
        "abstract": "this technical report delves into an in-depth exploration of adversarial attacks specifically targeted at deep neural networks (dnns) utilized for image classification. the study also investigates defense mechanisms aimed at bolstering the robustness of machine learning models. the research focuses on comprehending the ramifications of two prominent attack methodologies: the fast gradient sign method (fgsm) and the carlini-wagner (cw) approach. these attacks are examined concerning three pre-trained image classifiers: resnext50_32x4d, densenet-201, and vgg-19, utilizing the tiny-imagenet dataset. furthermore, the study proposes the robustness of defensive distillation as a defense mechanism to counter fgsm and cw attacks. this defense mechanism is evaluated using the cifar-10 dataset, where cnn models, specifically resnet101 and resnext50_32x4d, serve as the teacher and student models, respectively. the proposed defensive distillation model exhibits effectiveness in thwarting attacks such as fgsm. however, it is noted to remain susceptible to more sophisticated techniques like the cw attack. the document presents a meticulous validation of the proposed scheme. it provides detailed and comprehensive results, elucidating the efficacy and limitations of the defense mechanisms employed. through rigorous experimentation and analysis, the study offers insights into the dynamics of adversarial attacks on dnns, as well as the effectiveness of defensive strategies in mitigating their impact.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04245",
        "authors": [
            "trilokesh ranjan sarkar",
            "nilanjan das",
            "pralay sankar maitra",
            "bijoy some",
            "ritwik saha",
            "orijita adhikary",
            "bishal bose",
            "jaydip sen"
        ]
    },
    {
        "id": "2404.04249",
        "title": "humanoid robots at work: where are we ?",
        "abstract": "launched by elon musk and its optimus, we are witnessing a new race in which many companies have already engaged. the objective it to put at work a new generation of humanoid robots in demanding industrial environments within 2 or 3 years. is this objective realistic ? the aim of this document and its main contributions is to provide some hints by covering the following topics: first an analysis of 12 companies based on eight criteria that will help us to distinguish companies based on their maturity and approach to the market; second as these humanoids are very complex systems we will provide an overview of the technological challenges to be addressed; third when humanoids are deployed at scale, operation and maintenance become critical and the we will explore what is new with these complex machines; finally pilots are the last step to test the feasibility of a new system before mass deployment. this is an important step to test the maturity of a product and the strategy of the humanoid supplier to address a market and two pragmatic approaches will be discussed.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04249",
        "authors": [
            "fabrice r. noreils"
        ]
    },
    {
        "id": "2404.04251",
        "title": "who evaluates the evaluations? objectively scoring text-to-image prompt   coherence metrics with t2iscorescore (ts2)",
        "abstract": "with advances in the quality of text-to-image (t2i) models has come interest in benchmarking their prompt faithfulness-the semantic coherence of generated images to the prompts they were conditioned on. a variety of t2i faithfulness metrics have been proposed, leveraging advances in cross-modal embeddings and vision-language models (vlms). however, these metrics are not rigorously compared and benchmarked, instead presented against few weak baselines by correlation to human likert scores over a set of easy-to-discriminate images.   we introduce t2iscorescore (ts2), a curated set of semantic error graphs containing a prompt and a set increasingly erroneous images. these allow us to rigorously judge whether a given prompt faithfulness metric can correctly order images with respect to their objective error count and significantly discriminate between different error nodes, using meta-metric scores derived from established statistical tests. surprisingly, we find that the state-of-the-art vlm-based metrics (e.g., tifa, dsg, llmscore, viescore) we tested fail to significantly outperform simple feature-based metrics like clipscore, particularly on a hard subset of naturally-occurring t2i model errors. ts2 will enable the development of better t2i prompt faithfulness metrics through more rigorous comparison of their conformity to expected orderings and separations under objective criteria.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04251",
        "authors": [
            "michael saxon",
            "fatima jahara",
            "mahsa khoshnoodi",
            "yujie lu",
            "aditya sharma",
            "william yang wang"
        ]
    },
    {
        "id": "2404.04253",
        "title": "growing q-networks: solving continuous control tasks with adaptive   control resolution",
        "abstract": "recent reinforcement learning approaches have shown surprisingly strong capabilities of bang-bang policies for solving continuous control benchmarks. the underlying coarse action space discretizations often yield favourable exploration characteristics while final performance does not visibly suffer in the absence of action penalization in line with optimal control theory. in robotics applications, smooth control signals are commonly preferred to reduce system wear and energy efficiency, but action costs can be detrimental to exploration during early training. in this work, we aim to bridge this performance gap by growing discrete action spaces from coarse to fine control resolution, taking advantage of recent results in decoupled q-learning to scale our approach to high-dimensional action spaces up to dim(a) = 38. our work indicates that an adaptive control resolution in combination with value decomposition yields simple critic-only algorithms that yield surprisingly strong performance on continuous control tasks.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04253",
        "authors": [
            "tim seyde",
            "peter werner",
            "wilko schwarting",
            "markus wulfmeier",
            "daniela rus"
        ]
    },
    {
        "id": "2404.04254",
        "title": "watermark-based detection and attribution of ai-generated content",
        "abstract": "several companies--such as google, microsoft, and openai--have deployed techniques to watermark ai-generated content to enable proactive detection. however, existing literature mainly focuses on user-agnostic detection. attribution aims to further trace back the user of a generative-ai service who generated a given content detected as ai-generated. despite its growing importance, attribution is largely unexplored. in this work, we aim to bridge this gap by providing the first systematic study on watermark-based, user-aware detection and attribution of ai-generated content. specifically, we theoretically study the detection and attribution performance via rigorous probabilistic analysis. moreover, we develop an efficient algorithm to select watermarks for the users to enhance attribution performance. both our theoretical and empirical results show that watermark-based detection and attribution inherit the accuracy and (non-)robustness properties of the watermarking method.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04254",
        "authors": [
            "zhengyuan jiang",
            "moyang guo",
            "yuepeng hu",
            "neil zhenqiang gong"
        ]
    },
    {
        "id": "2404.04256",
        "title": "sigma: siamese mamba network for multi-modal semantic segmentation",
        "abstract": "multi-modal semantic segmentation significantly enhances ai agents' perception and scene understanding, especially under adverse conditions like low-light or overexposed environments. leveraging additional modalities (x-modality) like thermal and depth alongside traditional rgb provides complementary information, enabling more robust and reliable segmentation. in this work, we introduce sigma, a siamese mamba network for multi-modal semantic segmentation, utilizing the selective structured state space model, mamba. unlike conventional methods that rely on cnns, with their limited local receptive fields, or vision transformers (vits), which offer global receptive fields at the cost of quadratic complexity, our model achieves global receptive fields coverage with linear complexity. by employing a siamese encoder and innovating a mamba fusion mechanism, we effectively select essential information from different modalities. a decoder is then developed to enhance the channel-wise modeling ability of the model. our method, sigma, is rigorously evaluated on both rgb-thermal and rgb-depth segmentation tasks, demonstrating its superiority and marking the first successful application of state space models (ssms) in multi-modal perception tasks. code is available at https://github.com/zifuwan/sigma.",
        "doi": "",
        "created": "2024-04-05",
        "url": "https://arxiv.org/abs/2404.04256",
        "authors": [
            "zifu wan",
            "yuhao wang",
            "silong yong",
            "pingping zhang",
            "simon stepputtis",
            "katia sycara",
            "yaqi xie"
        ]
    }
]